{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjaAr6kxJ7r9"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/workspace/circuits-benchmark\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from circuits_benchmark.utils.project_paths import detect_project_root\n",
    "print(detect_project_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  circuits-benchmark\t    project_template\n",
      "README.md   cluster_setup.egg-info  quick_experiments\n"
     ]
    }
   ],
   "source": [
    "# !rm /workspace/pyproject.toml\n",
    "! ls /workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/circuits-benchmark/tracr/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import importlib.util\n",
    "import importlib.machinery\n",
    "\n",
    "# Specify the directory with your local package\n",
    "local_directory = \"/workspace/circuits-benchmark\"\n",
    "\n",
    "# The package name\n",
    "package_name = \"tracr\"\n",
    "\n",
    "# Construct the full path to the package's __init__.py file\n",
    "package_init_file = f\"{local_directory}/{package_name}/__init__.py\"\n",
    "\n",
    "# Load the package from the specified file\n",
    "spec = importlib.util.spec_from_file_location(package_name, package_init_file)\n",
    "local_package = importlib.util.module_from_spec(spec)\n",
    "sys.modules[package_name] = local_package\n",
    "spec.loader.exec_module(local_package)\n",
    "\n",
    "# Now you can use the tracr package as usual\n",
    "import tracr\n",
    "\n",
    "# Example usage of tracr\n",
    "print(tracr.__file__)\n",
    "from tracr.compiler.compiling import TracrOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import circuits_benchmark.benchmark.cases.case_3 as case_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "/workspace/circuits-benchmark\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/pyproject.toml'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(PROJECT_ROOT)\n\u001b[1;32m      8\u001b[0m update_proj_root()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdetect_project_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/workspace/circuits-benchmark/circuits_benchmark/utils/project_paths.py:18\u001b[0m, in \u001b[0;36mdetect_project_root\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m PROJECT_ROOT\n\u001b[1;32m     17\u001b[0m current_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mcurdir)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyproject.toml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     19\u001b[0m   current_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_path, os\u001b[38;5;241m.\u001b[39mpardir))\n\u001b[1;32m     21\u001b[0m PROJECT_ROOT \u001b[38;5;241m=\u001b[39m current_path\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from circuits_benchmark.utils.project_paths import detect_project_root\n",
    "from circuits_benchmark.utils.project_paths import PROJECT_ROOT\n",
    "def update_proj_root():\n",
    "    global PROJECT_ROOT\n",
    "    print(PROJECT_ROOT)\n",
    "    PROJECT_ROOT = \"/workspace/circuits-benchmark\"\n",
    "    print(PROJECT_ROOT)\n",
    "update_proj_root()\n",
    "print(detect_project_root())\n",
    "\n",
    "# import os\n",
    "\n",
    "\n",
    "# PROJECT_ROOT: str | None = None\n",
    "\n",
    "\n",
    "# def detect_project_root() -> str:\n",
    "#   \"\"\"\n",
    "#   Detects the root of the project by looking for a known file in the project.\n",
    "#   :return: the path to the root of the project.\n",
    "#   \"\"\"\n",
    "#   global PROJECT_ROOT\n",
    "#   if PROJECT_ROOT is not None:\n",
    "#     # If the project root has already been detected, return it.\n",
    "#     return PROJECT_ROOT\n",
    "\n",
    "#   current_path = os.path.abspath(os.path.curdir)\n",
    "#   while not os.path.exists(os.path.join(current_path, \"pyproject.toml\")):\n",
    "#     print(current_path)\n",
    "#     current_path = os.path.abspath(os.path.join(current_path, os.pardir))\n",
    "\n",
    "#   PROJECT_ROOT = current_path\n",
    "\n",
    "#   return current_path\n",
    "\n",
    "# print(detect_project_root())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InFxPfHh7Shf",
    "outputId": "76b5529f-d9b2-4feb-ebbc-88d481b01baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n",
      "Cloning into 'InterpBench'...\n",
      "remote: Enumerating objects: 225, done.\u001b[K\n",
      "remote: Counting objects: 100% (221/221), done.\u001b[K\n",
      "remote: Compressing objects: 100% (205/205), done.\u001b[K\n",
      "remote: Total 225 (delta 71), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
      "Receiving objects: 100% (225/225), 385.59 KiB | 3.44 MiB/s, done.\n",
      "Resolving deltas: 100% (71/71), done.\n",
      "Filtering content: 100% (55/55), 82.13 MiB | 34.38 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git lfs install\n",
    "!git clone https://huggingface.co/cybershiptrooper/InterpBench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CG6rfeq2J-FR"
   },
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OP0i3Tse7yEh",
    "outputId": "da12e5fc-f122-4d39-85f8-482c77748e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ActivationsStore', 'Adam', 'Any', 'FINETUNING_PARAMETERS', 'HookedRootModule', 'L1Scheduler', 'LanguageModelSAERunnerConfig', 'SAETrainer', 'TrainSAEOutput', 'TrainStepOutput', 'TrainingSAE', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '__version__', '_log_feature_sparsity', '_update_sae_lens_training_version', 'cast', 'contextlib', 'dataclass', 'get_lr_scheduler', 'run_evals', 'torch', 'tqdm', 'wandb']\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "from transformer_lens import HookedTransformerConfig, HookedTransformer\n",
    "from transformer_lens import HookedTransformer\n",
    "from circuits_benchmark.transformers.hooked_tracr_transformer import HookedTracrTransformer\n",
    "\n",
    "from tokenizers import Tokenizer, models, normalizers, pre_tokenizers, decoders, trainers\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "from sae_lens import LanguageModelSAERunnerConfig, SAETrainingRunner\n",
    "from sae_lens import SAEConfig, SAE, TrainingSAEConfig, TrainingSAE, ActivationsStore, CacheActivationsRunnerConfig, LanguageModelSAERunnerConfig\n",
    "from sae_lens.training.sae_trainer import SAETrainer\n",
    "\n",
    "import sae_lens\n",
    "print(dir(sae_lens.training.sae_trainer))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ouaNs_5kvQk1"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from safetensors.torch import save_file\n",
    "import wandb\n",
    "from sae_lens.sae import SAE_CFG_PATH, SAE_WEIGHTS_PATH, SPARSITY_PATH\n",
    "\n",
    "def save_checkpoint(\n",
    "        trainer: SAETrainer,\n",
    "        checkpoint_name: int | str,\n",
    "        wandb_aliases: list[str] | None = None,\n",
    "    ) -> str:\n",
    "        \"\"\" Lightly modified from https://github.com/jbloomAus/SAELens/blob/v3.5.0/sae_lens/sae_training_runner.py#L161C5-L210C31 \"\"\"\n",
    "\n",
    "        sae = trainer.sae\n",
    "        os.makedirs(trainer.cfg.checkpoint_path, exist_ok=True)\n",
    "        checkpoint_path = f\"{trainer.cfg.checkpoint_path}/{checkpoint_name}\"\n",
    "\n",
    "        os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "        path = f\"{checkpoint_path}\"\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        if sae.cfg.normalize_sae_decoder:\n",
    "            sae.set_decoder_norm_to_unit_norm()\n",
    "        sae.save_model(path)\n",
    "\n",
    "        # let's over write the cfg file with the trainer cfg, which is a super set of the original cfg.\n",
    "        # and should not cause issues but give us more info about SAEs we trained in SAE Lens.\n",
    "        config = trainer.cfg.to_dict()\n",
    "        with open(f\"{path}/cfg.json\", \"w\") as f:\n",
    "            json.dump(config, f)\n",
    "        if trainer.cfg.log_to_wandb:\n",
    "            print(f'saving {path}')\n",
    "            wandb.save(path)\n",
    "\n",
    "\n",
    "        log_feature_sparsities = {\"sparsity\": trainer.log_feature_sparsity}\n",
    "\n",
    "        log_feature_sparsity_path = f\"{path}/{SPARSITY_PATH}\"\n",
    "        save_file(log_feature_sparsities, log_feature_sparsity_path)\n",
    "\n",
    "        if trainer.cfg.log_to_wandb and os.path.exists(log_feature_sparsity_path):\n",
    "            model_artifact = wandb.Artifact(\n",
    "                f\"{sae.get_name()}\",\n",
    "                type=\"model\",\n",
    "                metadata=dict(trainer.cfg.__dict__),\n",
    "            )\n",
    "\n",
    "            model_artifact.add_file(f\"{path}/{SAE_WEIGHTS_PATH}\")\n",
    "            model_artifact.add_file(f\"{path}/{SAE_CFG_PATH}\")\n",
    "\n",
    "            wandb.log_artifact(model_artifact, aliases=wandb_aliases)\n",
    "\n",
    "            sparsity_artifact = wandb.Artifact(\n",
    "                f\"{sae.get_name()}_log_feature_sparsity\",\n",
    "                type=\"log_feature_sparsity\",\n",
    "                metadata=dict(trainer.cfg.__dict__),\n",
    "            )\n",
    "            sparsity_artifact.add_file(log_feature_sparsity_path)\n",
    "            wandb.log_artifact(sparsity_artifact)\n",
    "\n",
    "        return checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OtOpy8z6ALGU"
   },
   "outputs": [],
   "source": [
    "import circuits_benchmark.benchmark.cases.case_3 as case_3\n",
    "\n",
    "task = case_3.Case3()\n",
    "task_idx = task.get_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ytz3DejTAMwj",
    "outputId": "5f4a2b56-8149-4a0b-9ecb-7434dcd54401"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_name = f\"InterpBench/{task_idx}\"\n",
    "cfg_dict = pickle.load(open(f\"{dir_name}/ll_model_cfg.pkl\", \"rb\"))\n",
    "cfg = HookedTransformerConfig.from_dict(cfg_dict)\n",
    "model = HookedTransformer(cfg)\n",
    "weights = torch.load(f\"{dir_name}/ll_model.pth\")\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlB0DKXDt_V6"
   },
   "source": [
    "# Load and configure benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DT6AJSAdARcn",
    "outputId": "fd97e71f-cbe0-40af-972c-b4eb2bc7de60"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/circuits-benchmark\n",
      "Moving model to device:  cuda\n",
      "{'hook_embed': HookPoint(), 'hook_pos_embed': HookPoint(), 'blocks.0.attn.hook_k': HookPoint(), 'blocks.0.attn.hook_q': HookPoint(), 'blocks.0.attn.hook_v': HookPoint(), 'blocks.0.attn.hook_z': HookPoint(), 'blocks.0.attn.hook_attn_scores': HookPoint(), 'blocks.0.attn.hook_pattern': HookPoint(), 'blocks.0.attn.hook_result': HookPoint(), 'blocks.0.mlp.hook_pre': HookPoint(), 'blocks.0.mlp.hook_post': HookPoint(), 'blocks.0.hook_attn_in': HookPoint(), 'blocks.0.hook_q_input': HookPoint(), 'blocks.0.hook_k_input': HookPoint(), 'blocks.0.hook_v_input': HookPoint(), 'blocks.0.hook_mlp_in': HookPoint(), 'blocks.0.hook_attn_out': HookPoint(), 'blocks.0.hook_mlp_out': HookPoint(), 'blocks.0.hook_resid_pre': HookPoint(), 'blocks.0.hook_resid_mid': HookPoint(), 'blocks.0.hook_resid_post': HookPoint(), 'blocks.1.attn.hook_k': HookPoint(), 'blocks.1.attn.hook_q': HookPoint(), 'blocks.1.attn.hook_v': HookPoint(), 'blocks.1.attn.hook_z': HookPoint(), 'blocks.1.attn.hook_attn_scores': HookPoint(), 'blocks.1.attn.hook_pattern': HookPoint(), 'blocks.1.attn.hook_result': HookPoint(), 'blocks.1.mlp.hook_pre': HookPoint(), 'blocks.1.mlp.hook_post': HookPoint(), 'blocks.1.hook_attn_in': HookPoint(), 'blocks.1.hook_q_input': HookPoint(), 'blocks.1.hook_k_input': HookPoint(), 'blocks.1.hook_v_input': HookPoint(), 'blocks.1.hook_mlp_in': HookPoint(), 'blocks.1.hook_attn_out': HookPoint(), 'blocks.1.hook_mlp_out': HookPoint(), 'blocks.1.hook_resid_pre': HookPoint(), 'blocks.1.hook_resid_mid': HookPoint(), 'blocks.1.hook_resid_post': HookPoint()}\n",
      "dict_keys([TracrHLNode(name: blocks.0.mlp.hook_post,\n",
      " label: is_x_3,\n",
      " classes: 0,\n",
      " index: [:]\n",
      "), TracrHLNode(name: blocks.1.attn.hook_result,\n",
      " label: frac_prevs_1,\n",
      " classes: 0,\n",
      " index: [:, :, 0, :]\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/circuits-benchmark\n",
    "# load high level model\n",
    "from circuits_benchmark.utils.iit import make_iit_hl_model\n",
    "import circuits_benchmark.utils.iit.correspondence as correspondence\n",
    "from circuits_benchmark.utils.iit.dataset import get_unique_data\n",
    "import iit.model_pairs as mp\n",
    "from datasets import Dataset\n",
    "\n",
    "def make_model_pair(benchmark_case):\n",
    "    hl_model = benchmark_case.build_transformer_lens_model()\n",
    "    hl_model = make_iit_hl_model(hl_model, eval_mode=True)\n",
    "    tracr_output = benchmark_case.get_tracr_output()\n",
    "    hl_ll_corr = correspondence.TracrCorrespondence.from_output(\n",
    "            case=benchmark_case, tracr_output=tracr_output\n",
    "        )\n",
    "    model_pair = mp.StrictIITModelPair(hl_model, model, hl_ll_corr)\n",
    "    return model_pair, hl_model\n",
    "\n",
    "model_pair, hl_model = make_model_pair(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wXw8nhAeSzCg",
    "outputId": "e5b5b5d7-c7d7-4803-a311-520ae55b8d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['string_tokens', 'tokens', 'labels'],\n",
      "    num_rows: 1280\n",
      "})\n",
      "{'string_tokens': ['BOS', 'b', 'a', 'a', 'x'], 'tokens': [0, 3, 2, 2, 5], 'labels': \"['BOS', 0.0, 0.0, 0.0, 0.25]\"}\n"
     ]
    }
   ],
   "source": [
    "# Create dataset of case inputs\n",
    "dataset = get_unique_data(task, max_len=10_000)\n",
    "tokenized_data = hl_model.map_tracr_input_to_tl_input(dataset.data)\n",
    "\n",
    "# Convert PyTorch tensors to lists\n",
    "string_tokens_list = dataset.data.tolist()\n",
    "tokens_list = tokenized_data.tolist()\n",
    "labels_list = [str(label) for label in dataset.labels]\n",
    "\n",
    "# Create a dictionary from the lists\n",
    "data_dict = {\n",
    "    \"string_tokens\": string_tokens_list,\n",
    "    \"tokens\": tokens_list,\n",
    "    \"labels\": labels_list\n",
    "}\n",
    "\n",
    "# Create a Hugging Face dataset\n",
    "hf_dataset = Dataset.from_dict(data_dict)\n",
    "\n",
    "print(hf_dataset)\n",
    "print(hf_dataset[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KItWVrlgfx9v",
    "outputId": "5973470a-d801-48c8-9c68-c26e0b063744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 3)\n"
     ]
    }
   ],
   "source": [
    "print(hf_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TfEZgq7_bP08",
    "outputId": "fb85194c-5196-461c-a60c-8253d5b24118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [0, 2, 3, 4, 5]\n",
      "Decoded: BOS a b c x\n"
     ]
    }
   ],
   "source": [
    "# create tokenizer\n",
    "# Define your simple vocabulary\n",
    "vocab = {'BOS': 0, 'UNK': 1, 'a': 2, 'b': 3, 'c': 4, 'x': 5}\n",
    "# comes from task.get_vocab() and hl_model.map_tracr_input_to_tl_input\n",
    "\n",
    "# Create a Tokenizer with a WordLevel model\n",
    "tokenizer = Tokenizer(models.WordLevel(vocab=vocab, unk_token=\"UNK\"))\n",
    "\n",
    "# Set the normalizer, pre-tokenizer, and decoder\n",
    "tokenizer.normalizer = normalizers.Sequence([normalizers.Lowercase(), normalizers.StripAccents()])\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "# Convert to Hugging Face tokenizer\n",
    "hf_tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n",
    "\n",
    "# Add the special tokens to the Hugging Face tokenizer\n",
    "hf_tokenizer.add_special_tokens({\n",
    "    'unk_token': 'UNK',\n",
    "    'bos_token': 'BOS',\n",
    "    'cls_token': '[CLS]',\n",
    "    'sep_token': '[SEP]',\n",
    "    'pad_token': '[PAD]',\n",
    "    'mask_token': '[MASK]'\n",
    "})\n",
    "\n",
    "# Test the tokenizer\n",
    "encoded = hf_tokenizer.encode(\"BOS a b c x\")\n",
    "decoded = hf_tokenizer.decode(encoded)\n",
    "print(f\"Encoded: {encoded}\")\n",
    "print(f\"Decoded: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oShVxNlpvfyn"
   },
   "outputs": [],
   "source": [
    "model.tokenizer = hf_tokenizer #attach to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eilYaeGcLuMY",
    "outputId": "e3ae7db7-3487-4411-fe62-52bfe94b78fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [1.0000],\n",
      "         [0.5000],\n",
      "         [0.6667],\n",
      "         [0.5000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.2500]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.3333],\n",
      "         [0.2500]]], device='cuda:0') [list(['BOS', 0.0, 0.0, 0.0, 0.0]) list(['BOS', 0.0, 0.0, 0.0, 0.0])\n",
      " list(['BOS', 1.0, 0.5, 0.6666666666666666, 0.5])\n",
      " list(['BOS', 0.0, 0.0, 0.0, 0.25])\n",
      " list(['BOS', 0.0, 0.0, 0.3333333333333333, 0.25])]\n"
     ]
    }
   ],
   "source": [
    "_, cache = model.run_with_cache(tokenized_data)\n",
    "output = hl_model(tokenized_data) #TODO: why are these different calls?\n",
    "print(output[:5], dataset.labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w16J8LtAO4WU",
    "outputId": "817b52ed-d62d-4a0f-ef8f-d5bb159480c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActivationCache with keys ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.hook_q_input', 'blocks.0.hook_k_input', 'blocks.0.hook_v_input', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.attn.hook_result', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.hook_mlp_in', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.hook_q_input', 'blocks.1.hook_k_input', 'blocks.1.hook_v_input', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.attn.hook_result', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.hook_mlp_in', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post']\n"
     ]
    }
   ],
   "source": [
    "print(cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu8iSnvHNG38"
   },
   "source": [
    "# SAE-lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_by85gQ_g1w",
    "outputId": "a871622b-355a-46d3-826e-fa1730167e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content'\n",
      "/workspace/circuits-benchmark\n",
      "DEMO_InterpBench.ipynb  \u001b[0m\u001b[01;34mcircuits_benchmark\u001b[0m/  pytest.ini\n",
      "Dockerfile              \u001b[01;36miit\u001b[0m@                 \u001b[01;34msubmodules\u001b[0m/\n",
      "EXPERIMENTS.md          \u001b[01;32mmain.py\u001b[0m*             \u001b[01;36msubnetwork_probing\u001b[0m@\n",
      "LICENSE                 \u001b[01;34mmetadata\u001b[0m/            \u001b[01;36mtracr\u001b[0m@\n",
      "README.md               poetry.lock\n",
      "\u001b[01;36macdc\u001b[0m@                   pyproject.toml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "%pwd\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NTJJyQtOc4mG"
   },
   "outputs": [],
   "source": [
    "class RepeatActivationsStore(ActivationsStore):\n",
    "    def _get_next_dataset_tokens(self) -> torch.Tensor:\n",
    "        device = self.device\n",
    "        if not self.is_dataset_tokenized:\n",
    "            try:\n",
    "                s = next(self.iterable_dataset)[self.tokens_column]\n",
    "            except StopIteration:\n",
    "                #shuffle self.dataset and restart\n",
    "                self.iterable_dataset = iter(self.dataset)\n",
    "                s = next(self.iterable_dataset)[self.tokens_column]\n",
    "            tokens = (\n",
    "                self.model.to_tokens(\n",
    "                    s,\n",
    "                    truncate=False,\n",
    "                    move_to_device=True,\n",
    "                    prepend_bos=self.prepend_bos,\n",
    "                )\n",
    "                .squeeze(0)\n",
    "                .to(device)\n",
    "            )\n",
    "            assert (\n",
    "                len(tokens.shape) == 1\n",
    "            ), f\"tokens.shape should be 1D but was {tokens.shape}\"\n",
    "        else:\n",
    "            try:\n",
    "                s = next(self.iterable_dataset)[self.tokens_column]\n",
    "            except StopIteration:\n",
    "                #shuffle self.dataset and restart\n",
    "                self.iterable_dataset = iter(self.dataset)\n",
    "                s = next(self.iterable_dataset)[self.tokens_column]\n",
    "            tokens = torch.tensor(\n",
    "                s,\n",
    "                dtype=torch.long,\n",
    "                device=device,\n",
    "                requires_grad=False,\n",
    "            )\n",
    "            if (\n",
    "                not self.prepend_bos\n",
    "                and tokens[0] == self.model.tokenizer.bos_token_id  # type: ignore\n",
    "            ):\n",
    "                tokens = tokens[1:]\n",
    "        self.n_dataset_processed += 1\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cltcYcNv6Sb2"
   },
   "source": [
    "## Residual stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhrGtjCBNZM7",
    "outputId": "01fb8c7d-491b-474e-c479-395a3065d72e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 48-L1-0.1-LR-0.0003-Tokens-5.000e+06\n",
      "n_tokens_per_buffer (millions): 0.032\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.0064\n",
      "Total training steps: 10000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 5.0\n",
      "n_tokens_per_dead_feature_window (millions): 2.5\n",
      "We will reset the sparsity calculation 5 times.\n",
      "Number tokens in sparsity calculation window: 1.00e+06\n",
      "Using Ghost Grads.\n"
     ]
    }
   ],
   "source": [
    "L1_coeff = 1e-1\n",
    "training_tokens = 5_000_000\n",
    "runner_cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distribution)\n",
    "    model_name = \"case3\",\n",
    "    model_class_name = \"HookedTransformer\",\n",
    "    hook_name = \"blocks.1.hook_resid_pre\",\n",
    "    hook_eval = \"NOT_IN_USE\",\n",
    "    hook_layer = 1,\n",
    "    hook_head_index = None,\n",
    "    dataset_path = \"\",\n",
    "    dataset_trust_remote_code = False,\n",
    "    streaming = False,\n",
    "    is_dataset_tokenized = True,\n",
    "    context_size = 5,\n",
    "    use_cached_activations = False,\n",
    "    cached_activations_path = None,  # Defaults to \"activations/{dataset}/{model}/{full_hook_name}_{hook_head_index}\"\n",
    "\n",
    "    # SAE Parameters\n",
    "    d_in = model.cfg.d_model,\n",
    "    d_sae = None,\n",
    "    b_dec_init_method = \"geometric_median\",\n",
    "    expansion_factor = 4,\n",
    "    activation_fn = \"relu\",  # relu, tanh-relu\n",
    "    normalize_sae_decoder = True,\n",
    "    noise_scale = 0.0,\n",
    "    from_pretrained_path = None,\n",
    "    apply_b_dec_to_input = False,\n",
    "    decoder_orthogonal_init = False,\n",
    "    decoder_heuristic_init = False,\n",
    "    init_encoder_as_decoder_transpose = False,\n",
    "\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer = hf_dataset.shape[0],\n",
    "    training_tokens = training_tokens,\n",
    "    finetuning_tokens = 0,\n",
    "    store_batch_size_prompts = 5,\n",
    "    normalize_activations = \"none\",  # none, expected_average_only_in (Anthropic April Update), constant_norm_rescale (Anthropic Feb Update)\n",
    "\n",
    "    # Misc\n",
    "    device = device,\n",
    "    act_store_device = \"with_model\",  # will be set by post init if with_model\n",
    "    seed = 42,\n",
    "    dtype = \"float32\",  # type: ignore #\n",
    "    prepend_bos = False,\n",
    "\n",
    "    # Performance - see compilation section of lm_runner.py for info\n",
    "    autocast = False,  # autocast to autocast_dtype during training\n",
    "    autocast_lm = False,  # autocast lm during activation fetching\n",
    "    compile_llm = False,  # use torch.compile on the LLM\n",
    "    llm_compilation_mode = None,  # which torch.compile mode to use\n",
    "    compile_sae = False,  # use torch.compile on the SAE\n",
    "    sae_compilation_mode = None,\n",
    "\n",
    "    # Training Parameters\n",
    "\n",
    "    ## Batch size\n",
    "    train_batch_size_tokens = 5*100,\n",
    "\n",
    "    ## Adam\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.999,\n",
    "\n",
    "    ## Loss Function\n",
    "    mse_loss_normalization = None,\n",
    "    l1_coefficient = L1_coeff,\n",
    "    lp_norm = 1,\n",
    "    scale_sparsity_penalty_by_decoder_norm = False,\n",
    "    l1_warm_up_steps = 0,\n",
    "\n",
    "    ## Learning Rate Schedule\n",
    "    lr = 3e-4,\n",
    "    lr_scheduler_name = \"constant\",  # constant, cosineannealing, cosineannealingwarmrestarts\n",
    "    lr_warm_up_steps = 0,\n",
    "    lr_end = None,  # only used for cosine annealing, default is lr / 10\n",
    "    lr_decay_steps = 0,\n",
    "    n_restart_cycles = 1,  # used only for cosineannealingwarmrestarts\n",
    "\n",
    "    ## FineTuning\n",
    "    finetuning_method = None,  # scale, decoder or unrotated_decoder\n",
    "\n",
    "    # Resampling protocol args\n",
    "    use_ghost_grads = True,  # want to change this to true on some timeline.\n",
    "    feature_sampling_window = 2000,\n",
    "    dead_feature_window = 1000,  # unless this window is larger feature sampling,\n",
    "    dead_feature_threshold = 1e-8,\n",
    "\n",
    "    # Evals\n",
    "    n_eval_batches = 10,\n",
    "    eval_batch_size_prompts = None,  # useful if evals cause OOM\n",
    "\n",
    "    # WANDB\n",
    "    log_to_wandb = True,\n",
    "    log_activations_store_to_wandb = False,\n",
    "    log_optimizer_state_to_wandb = False,\n",
    "    wandb_project = \"benchmark_saes\",\n",
    "    wandb_id = None,\n",
    "    run_name = None,\n",
    "    wandb_entity = None,\n",
    "    wandb_log_frequency = 10,\n",
    "    eval_every_n_wandb_logs = 100000000000, # Make this a really big number; currently fails because it tries to compute CE loss.\n",
    "    # Misc\n",
    "    resume = False,\n",
    "    n_checkpoints = 5,\n",
    "    checkpoint_path = \"checkpoints\",\n",
    "    verbose = True,\n",
    "    model_kwargs = dict(),\n",
    "    model_from_pretrained_kwargs = dict(),\n",
    "    sae_lens_version = str(sae_lens.__version__),\n",
    "    sae_lens_training_version = str(sae_lens.__version__),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 814,
     "referenced_widgets": [
      "0f6a54a5242d4963959813217e192323",
      "3181d5a610e44d16a62010de88e34ea0",
      "a7a3ecba6fe84610b9d1626cd05f25df",
      "ed20c3fa79784d91870a84a098f04d33",
      "ccbc8b30e53545cfb311f2e6d49da4fc",
      "b7e63627055a42fd89d6e3dd2bfdfe42",
      "cdbfe0ae850443b1978bed6d0d7f2bbe",
      "bd9587b34348441da608ea83783adb63"
     ]
    },
    "id": "AMAR0c3xgL-F",
    "outputId": "b9d8cd42-b442-4693-a208-4e69157a6952"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/circuits-benchmark/wandb/run-20240628_174342-cytzimm1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evanhanders/benchmark_saes/runs/cytzimm1' target=\"_blank\">48-L1-0.1-LR-0.0003-Tokens-5.000e+06</a></strong> to <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/cytzimm1' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/cytzimm1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200| MSE Loss 0.078 | L1 0.394:   2%|â–‹                                   | 100000/5000000 [00:18<14:06, 5786.03it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:527\u001b[0m, in \u001b[0;36mActivationsStore.next_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;66;03m# Try to get the next batch\u001b[39;00m\n\u001b[0;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;66;03m# If the DataLoader is exhausted, create a new one\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:621\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m runner_cfg\u001b[38;5;241m.\u001b[39mlog_to_wandb:\n\u001b[1;32m      9\u001b[0m     wandb\u001b[38;5;241m.\u001b[39minit(\n\u001b[1;32m     10\u001b[0m         project\u001b[38;5;241m=\u001b[39mrunner_cfg\u001b[38;5;241m.\u001b[39mwandb_project,\n\u001b[1;32m     11\u001b[0m         config\u001b[38;5;241m=\u001b[39mcast(Any, runner_cfg),\n\u001b[1;32m     12\u001b[0m         name\u001b[38;5;241m=\u001b[39mrunner_cfg\u001b[38;5;241m.\u001b[39mrun_name,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mrunner_cfg\u001b[38;5;241m.\u001b[39mwandb_id,\n\u001b[1;32m     14\u001b[0m     )\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/sae_lens/training/sae_trainer.py:159\u001b[0m, in \u001b[0;36mSAETrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Train loop\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_training_tokens \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtotal_training_tokens:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# Do a training step.\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     layer_acts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msae\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_training_tokens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtrain_batch_size_tokens\n\u001b[1;32m    162\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_step(sae\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msae, sae_in\u001b[38;5;241m=\u001b[39mlayer_acts)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:530\u001b[0m, in \u001b[0;36mActivationsStore.next_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;66;03m# If the DataLoader is exhausted, create a new one\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:499\u001b[0m, in \u001b[0;36mActivationsStore.get_data_loader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_batch_size_tokens\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# 1. # create new buffer by mixing stored and new buffer\u001b[39;00m\n\u001b[1;32m    498\u001b[0m mixing_buffer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m--> 499\u001b[0m     [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_batches_in_buffer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_buffer],\n\u001b[1;32m    500\u001b[0m     dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    501\u001b[0m )\n\u001b[1;32m    503\u001b[0m mixing_buffer \u001b[38;5;241m=\u001b[39m mixing_buffer[torch\u001b[38;5;241m.\u001b[39mrandperm(mixing_buffer\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# 2.  put 50 % in storage\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:452\u001b[0m, in \u001b[0;36mActivationsStore.get_buffer\u001b[0;34m(self, n_batches_in_buffer)\u001b[0m\n\u001b[1;32m    444\u001b[0m new_buffer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    445\u001b[0m     (total_size, context_size, num_layers, d_in),\n\u001b[1;32m    446\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    448\u001b[0m )\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m refill_batch_idx_start \u001b[38;5;129;01min\u001b[39;00m refill_iterator:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;66;03m# move batch toks to gpu for model\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m     refill_batch_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    453\u001b[0m     refill_activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_activations(refill_batch_tokens)\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# move acts back to cpu\u001b[39;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:281\u001b[0m, in \u001b[0;36mActivationsStore.get_batch_tokens\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    278\u001b[0m current_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m batch_tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m batch_size:\n\u001b[0;32m--> 281\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_next_dataset_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     token_len \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# TODO: Fix this so that we are limiting how many tokens we get from the same context.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from typing import Any, cast\n",
    "\n",
    "model.tokenizer = hf_tokenizer\n",
    "store = RepeatActivationsStore.from_config(model, runner_cfg, dataset=hf_dataset)\n",
    "sae = TrainingSAE(runner_cfg)\n",
    "trainer = SAETrainer(model, sae, store, save_checkpoint, cfg = runner_cfg)\n",
    "\n",
    "if runner_cfg.log_to_wandb:\n",
    "    wandb.init(\n",
    "        project=runner_cfg.wandb_project,\n",
    "        config=cast(Any, runner_cfg),\n",
    "        name=runner_cfg.run_name,\n",
    "        id=runner_cfg.wandb_id,\n",
    "    )\n",
    "trainer.fit()\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8pv-bJG6hoS"
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UE9ua53A6hoc",
    "outputId": "160fa32b-6f72-4b48-f4cd-c37fef9ae281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 48-L1-0.1-LR-0.0003-Tokens-5.000e+06\n",
      "n_tokens_per_buffer (millions): 0.032\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.0064\n",
      "Total training steps: 10000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 5.0\n",
      "n_tokens_per_dead_feature_window (millions): 2.5\n",
      "We will reset the sparsity calculation 5 times.\n",
      "Number tokens in sparsity calculation window: 1.00e+06\n",
      "Using Ghost Grads.\n"
     ]
    }
   ],
   "source": [
    "L1_coeff = 1e-1\n",
    "training_tokens = 5_000_000\n",
    "runner_cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distribution)\n",
    "    model_name = \"case3\",\n",
    "    model_class_name = \"HookedTransformer\",\n",
    "    hook_name = \"blocks.0.hook_mlp_out\",\n",
    "    hook_eval = \"NOT_IN_USE\",\n",
    "    hook_layer = 0,\n",
    "    hook_head_index = None,\n",
    "    dataset_path = \"\",\n",
    "    dataset_trust_remote_code = False,\n",
    "    streaming = False,\n",
    "    is_dataset_tokenized = True,\n",
    "    context_size = 5,\n",
    "    use_cached_activations = False,\n",
    "    cached_activations_path = None,  # Defaults to \"activations/{dataset}/{model}/{full_hook_name}_{hook_head_index}\"\n",
    "\n",
    "    # SAE Parameters\n",
    "    d_in = model.cfg.d_model,\n",
    "    d_sae = None,\n",
    "    b_dec_init_method = \"geometric_median\",\n",
    "    expansion_factor = 4,\n",
    "    activation_fn = \"relu\",  # relu, tanh-relu\n",
    "    normalize_sae_decoder = True,\n",
    "    noise_scale = 0.0,\n",
    "    from_pretrained_path = None,\n",
    "    apply_b_dec_to_input = False,\n",
    "    decoder_orthogonal_init = False,\n",
    "    decoder_heuristic_init = False,\n",
    "    init_encoder_as_decoder_transpose = False,\n",
    "\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer = hf_dataset.shape[0],\n",
    "    training_tokens = training_tokens,\n",
    "    finetuning_tokens = 0,\n",
    "    store_batch_size_prompts = 5,\n",
    "    normalize_activations = \"none\",  # none, expected_average_only_in (Anthropic April Update), constant_norm_rescale (Anthropic Feb Update)\n",
    "\n",
    "    # Misc\n",
    "    device = device,\n",
    "    act_store_device = \"with_model\",  # will be set by post init if with_model\n",
    "    seed = 42,\n",
    "    dtype = \"float32\",  # type: ignore #\n",
    "    prepend_bos = False,\n",
    "\n",
    "    # Performance - see compilation section of lm_runner.py for info\n",
    "    autocast = False,  # autocast to autocast_dtype during training\n",
    "    autocast_lm = False,  # autocast lm during activation fetching\n",
    "    compile_llm = False,  # use torch.compile on the LLM\n",
    "    llm_compilation_mode = None,  # which torch.compile mode to use\n",
    "    compile_sae = False,  # use torch.compile on the SAE\n",
    "    sae_compilation_mode = None,\n",
    "\n",
    "    # Training Parameters\n",
    "\n",
    "    ## Batch size\n",
    "    train_batch_size_tokens = 5*100,\n",
    "\n",
    "    ## Adam\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.999,\n",
    "\n",
    "    ## Loss Function\n",
    "    mse_loss_normalization = None,\n",
    "    l1_coefficient = L1_coeff,\n",
    "    lp_norm = 1,\n",
    "    scale_sparsity_penalty_by_decoder_norm = False,\n",
    "    l1_warm_up_steps = 0,\n",
    "\n",
    "    ## Learning Rate Schedule\n",
    "    lr = 3e-4,\n",
    "    lr_scheduler_name = \"constant\",  # constant, cosineannealing, cosineannealingwarmrestarts\n",
    "    lr_warm_up_steps = 0,\n",
    "    lr_end = None,  # only used for cosine annealing, default is lr / 10\n",
    "    lr_decay_steps = 0,\n",
    "    n_restart_cycles = 1,  # used only for cosineannealingwarmrestarts\n",
    "\n",
    "    ## FineTuning\n",
    "    finetuning_method = None,  # scale, decoder or unrotated_decoder\n",
    "\n",
    "    # Resampling protocol args\n",
    "    use_ghost_grads = True,  # want to change this to true on some timeline.\n",
    "    feature_sampling_window = 2000,\n",
    "    dead_feature_window = 1000,  # unless this window is larger feature sampling,\n",
    "    dead_feature_threshold = 1e-8,\n",
    "\n",
    "    # Evals\n",
    "    n_eval_batches = 10,\n",
    "    eval_batch_size_prompts = None,  # useful if evals cause OOM\n",
    "\n",
    "    # WANDB\n",
    "    log_to_wandb = True,\n",
    "    log_activations_store_to_wandb = False,\n",
    "    log_optimizer_state_to_wandb = False,\n",
    "    wandb_project = \"benchmark_saes\",\n",
    "    wandb_id = None,\n",
    "    run_name = None,\n",
    "    wandb_entity = None,\n",
    "    wandb_log_frequency = 10,\n",
    "    eval_every_n_wandb_logs = 100000000000, # Make this a really big number; currently fails because it tries to compute CE loss.\n",
    "    # Misc\n",
    "    resume = False,\n",
    "    n_checkpoints = 5,\n",
    "    checkpoint_path = \"checkpoints\",\n",
    "    verbose = True,\n",
    "    model_kwargs = dict(),\n",
    "    model_from_pretrained_kwargs = dict(),\n",
    "    sae_lens_version = str(sae_lens.__version__),\n",
    "    sae_lens_training_version = str(sae_lens.__version__),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fFykBbfzCw9k"
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744,
     "referenced_widgets": [
      "21a5279ec677451ba58792e4854a2616",
      "8a20bc7d13734632abf89aba5de29b78",
      "8f8c44017f6c4e48b4afab8c576bb969",
      "777cdae240644161879a2bc28a8fa1f8",
      "8c5ac6c09c6548f8bc2371707b67ad26",
      "8a1aee4c93d54e8bb96ec57425b69fc2",
      "e8b78e2de79b4174977cdd22187942ba",
      "9c5bdaaefca648ae92a6ea23c36b6304"
     ]
    },
    "id": "LoziykTq6hoc",
    "outputId": "585b9f5e-eb8a-4f42-885c-beb09de1d96c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mevanhanders\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea33970bc314c50aef5e94d86c4b46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111437575891614, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/circuits-benchmark/wandb/run-20240628_172205-d33mtmwz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evanhanders/benchmark_saes/runs/d33mtmwz' target=\"_blank\">48-L1-0.1-LR-0.0003-Tokens-5.000e+06</a></strong> to <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/d33mtmwz' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/d33mtmwz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000| MSE Loss 0.014 | L1 0.095:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 1000000/5000000 [02:24<09:25, 7073.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving checkpoints/3zuzrmva/1000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000| MSE Loss 0.008 | L1 0.080:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 2000000/5000000 [04:45<06:50, 7304.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving checkpoints/3zuzrmva/2000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6000| MSE Loss 0.006 | L1 0.078:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 3000000/5000000 [07:09<04:42, 7078.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving checkpoints/3zuzrmva/3000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000| MSE Loss 0.006 | L1 0.080:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 4000000/5000000 [09:30<02:18, 7240.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving checkpoints/3zuzrmva/4000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000| MSE Loss 0.005 | L1 0.079: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000000/5000000 [11:55<00:00, 7107.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving checkpoints/3zuzrmva/final_5000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000| MSE Loss 0.005 | L1 0.079: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000000/5000000 [11:55<00:00, 6985.69it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.050 MB of 0.050 MB uploaded (0.008 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 13.6%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>details/current_learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>details/n_training_tokens</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>losses/ghost_grad_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>losses/l1_loss</td><td>â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>losses/mse_loss</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>losses/overall_loss</td><td>â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>metrics/explained_variance</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/explained_variance_std</td><td>â–ˆâ–‚â–â–â–â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>metrics/l0</td><td>â–ˆâ–†â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>â–ˆâ–â–‚â–ƒâ–ƒ</td></tr><tr><td>sparsity/below_1e-5</td><td>â–â–ˆâ–†â–…â–„</td></tr><tr><td>sparsity/below_1e-6</td><td>â–â–ˆâ–„â–‚â–</td></tr><tr><td>sparsity/dead_features</td><td>â–â–â–â–â–â–‚â–…â–…â–„â–…â–†â–†â–ˆâ–‡â–†â–‡â–†â–ˆâ–…â–„â–…â–…â–…â–†â–„â–ƒâ–‚â–‚â–„â–‚â–ƒâ–‚â–â–â–‚â–â–‚â–â–â–</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>â–â–â–â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–†â–‡â–†â–‡â–ˆâ–ˆâ–‡â–†â–†â–†â–‡â–‡â–ˆâ–†â–‡â–†â–†â–†â–†â–†â–†â–ƒâ–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>0.1</td></tr><tr><td>details/current_learning_rate</td><td>0.0003</td></tr><tr><td>details/n_training_tokens</td><td>5000000</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.0</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.00045</td></tr><tr><td>losses/l1_loss</td><td>0.79312</td></tr><tr><td>losses/mse_loss</td><td>0.00547</td></tr><tr><td>losses/overall_loss</td><td>0.08523</td></tr><tr><td>metrics/explained_variance</td><td>0.98813</td></tr><tr><td>metrics/explained_variance_std</td><td>0.01316</td></tr><tr><td>metrics/l0</td><td>2.858</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-3.2393</td></tr><tr><td>sparsity/below_1e-5</td><td>7</td></tr><tr><td>sparsity/below_1e-6</td><td>0</td></tr><tr><td>sparsity/dead_features</td><td>2</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>359.41669</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">48-L1-0.1-LR-0.0003-Tokens-5.000e+06</strong> at: <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/d33mtmwz' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/d33mtmwz</a><br/> View project at: <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a><br/>Synced 5 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240628_172205-d33mtmwz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Any, cast\n",
    "\n",
    "model.tokenizer = hf_tokenizer\n",
    "store = RepeatActivationsStore.from_config(model, runner_cfg, dataset=hf_dataset)\n",
    "sae = TrainingSAE(runner_cfg)\n",
    "trainer = SAETrainer(model, sae, store, save_checkpoint, cfg = runner_cfg)\n",
    "\n",
    "if runner_cfg.log_to_wandb:\n",
    "    wandb.init(\n",
    "        project=runner_cfg.wandb_project,\n",
    "        config=cast(Any, runner_cfg),\n",
    "        name=runner_cfg.run_name,\n",
    "        id=runner_cfg.wandb_id,\n",
    "    )\n",
    "trainer.fit()\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uKMyUW2v6xf1",
    "outputId": "4b94b55c-6f2b-4a38-882c-263770294595"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize the wandb API\n",
    "api = wandb.Api()\n",
    "\n",
    "\n",
    "\n",
    "# Get the artifact from the old run\n",
    "artifact = api.artifact('evanhanders/benchmark_saes/sae_case3_blocks.0.hook_mlp_out_48:latest')\n",
    "\n",
    "# Download the artifact to a specified directory\n",
    "artifact_mlp_out = artifact.download(\"./mlp_out_0\")\n",
    "\n",
    "\n",
    "artifact = api.artifact('evanhanders/benchmark_saes/sae_case3_blocks.1.hook_resid_pre_48:latest')\n",
    "\n",
    "# Download the artifact to a specified directory\n",
    "artifact_residual_1 = artifact.download(\"./hook_resid_pre_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ffqow8NZUl7b"
   },
   "outputs": [],
   "source": [
    "from sae_lens import SAE\n",
    "\n",
    "sae_mlp = SAE.load_from_pretrained(artifact_mlp_out, device=device)\n",
    "sae_residual = SAE.load_from_pretrained(artifact_residual_1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cfg.tokenizer_prepends_bos=False\n",
    "model.cfg.default_prepend_bos=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.Tensor(hf_dataset['tokens']).to(int)\n",
    "logits, cache = model.run_with_cache(tokens, prepend_bos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_mlp = sae_mlp.encode(cache[sae_mlp.cfg.hook_name])\n",
    "activations_resid_1 = sae_residual.encode(cache[sae_residual.cfg.hook_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top values shape: torch.Size([20, 48])\n",
      "Batch indices shape: torch.Size([20, 48])\n",
      "Context indices shape: torch.Size([20, 48])\n",
      "torch.Size([1280, 5, 48])\n"
     ]
    }
   ],
   "source": [
    "def get_top_k(activations, k=20):\n",
    "    # Reshape\n",
    "    batch, ctx, feat = activations.shape\n",
    "    reshaped = activations.view(batch * ctx, feat)\n",
    "    \n",
    "    # Get the top-k samples and their indices\n",
    "    top_samples = torch.topk(reshaped, dim=0, k=k)\n",
    "    top_values = top_samples.values\n",
    "    top_indices = top_samples.indices\n",
    "    \n",
    "    # print(top_indices)  # Print the shape of the top-k values\n",
    "    \n",
    "    # Compute the original batch and ctx positions\n",
    "    original_batch_indices = top_indices // ctx\n",
    "    original_ctx_indices = top_indices % ctx\n",
    "    \n",
    "    return top_values.cpu(), original_batch_indices.cpu(), original_ctx_indices.cpu()\n",
    "\n",
    "# Example usage\n",
    "top_values, batch_indices, ctx_indices = get_top_k(activations_mlp)\n",
    "print(\"Top values shape:\", top_values.shape)\n",
    "print(\"Batch indices shape:\", batch_indices.shape)\n",
    "print(\"Context indices shape:\", ctx_indices.shape)\n",
    "\n",
    "print(activations_mlp.shape)\n",
    "# print(batch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 16\n",
      "torch.Size([20]) torch.Size([20, 5])\n",
      "torch.Size([20])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>activation</th>\n",
       "      <th>tok_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOS b c b b</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOS b c a a</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS b c x c</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS b a c x</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOS b a a x</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOS b c b a</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOS b c x c</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOS b b b a</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOS b c x c</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BOS b c c a</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tokens     activation  tok_idx\n",
       "0  BOS b c b b     0.09        1   \n",
       "1  BOS b c a a     0.09        1   \n",
       "2  BOS b c x c     0.09        1   \n",
       "3  BOS b a c x     0.09        1   \n",
       "4  BOS b a a x     0.09        1   \n",
       "5  BOS b c b a     0.09        1   \n",
       "6  BOS b c x c     0.09        1   \n",
       "7  BOS b b b a     0.09        1   \n",
       "8  BOS b c x c     0.09        1   \n",
       "9  BOS b c c a     0.09        1   "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = 16\n",
    "k = 20\n",
    "\n",
    "#feat 1 fires on a sequence where the first 3 are x.\n",
    "#feat 2 fires on a b at position 1.\n",
    "#feat 6 fires on an x at position 4.\n",
    "#feat 7 fires weakly\n",
    "#feat 12 fires on x at position 1.\n",
    "#feat 16 fires on b at position 1.\n",
    "print(f'feature {feat}')\n",
    "\n",
    "activations = top_values[:,feat]\n",
    "best_tokens = tokens[batch_indices[:,feat]]\n",
    "print(ctx_indices[:,0].shape, best_tokens.shape)\n",
    "print(active_token.shape)\n",
    "\n",
    "active_idx = ctx_indices[:,feat]\n",
    "active_token = best_tokens[range(k), active_idx]\n",
    "active_tokens = hf_tokenizer.decode(active_token)\n",
    "full_strs = [hf_tokenizer.decode(t) for t in best_tokens]\n",
    "\n",
    "info = [\n",
    "    {\n",
    "        'tokens' : toks,\n",
    "        'activation' : act.item(),\n",
    "        'tok_idx' : idx.item(),\n",
    "    }\n",
    "    for act, idx, toks in zip(activations, active_idx, full_strs)\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(info)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea74199c583047b581b54448d3d3855f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Feature:', index=16, options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da933703a9c14394b6cf138da717866e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# Define the dropdown menu for 'feat'\n",
    "feat_dropdown = widgets.Dropdown(\n",
    "    options=range(sae_mlp.cfg.d_sae),\n",
    "    value=16,\n",
    "    description='Feature:',\n",
    ")\n",
    "\n",
    "# Function to update the DataFrame based on the selected feature\n",
    "def update_dataframe(feat):\n",
    "    k = 20\n",
    "    \n",
    "    print(f'feature {feat}')\n",
    "    \n",
    "    activations = top_values[:, feat]\n",
    "    best_tokens = tokens[batch_indices[:, feat]]\n",
    "    active_idx = ctx_indices[:, feat]\n",
    "    active_token = best_tokens[range(k), active_idx]\n",
    "    active_tokens = hf_tokenizer.decode(active_token)\n",
    "    full_strs = [hf_tokenizer.decode(t) for t in best_tokens]\n",
    "    \n",
    "    info = [\n",
    "        {\n",
    "            'tokens': toks,\n",
    "            'activation': act.item(),\n",
    "            'tok_idx': idx.item(),\n",
    "        }\n",
    "        for act, idx, toks in zip(activations, active_idx, full_strs)\n",
    "    ]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(info)\n",
    "    display(df.head(10))\n",
    "\n",
    "# Create an interactive output widget\n",
    "output = widgets.interactive_output(update_dataframe, {'feat': feat_dropdown})\n",
    "\n",
    "# Display the dropdown menu and output\n",
    "display(feat_dropdown, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP-0 features:\n",
    "1 - on tok 4 when 1-3 are all x\n",
    "2 - weak 'b' on tok 1\n",
    "6 - 'x' on pos 2\n",
    "7 - very weak, pos 4, when there are no x's?\n",
    "12 - 'x' on pos 1\n",
    "16 - weak 'b' on pos 1.\n",
    "18 - BOS\n",
    "19 - Strong fire on x on tok 4\n",
    "20 - weak c on tok 3\n",
    "21 - BOS\n",
    "22 - weak c on tok 2\n",
    "23 - weak 'x' on pos 4 or 2.\n",
    "26 - BOS\n",
    "28 - BOS\n",
    "30 - weak 'c' on tok 3\n",
    "33 - 'x' on tok 3.\n",
    "34 - 'x' on tok 1\n",
    "39 - 'b' on tok 3\n",
    "40 - 'x' on tok 2\n",
    "42 - 'x' on tok 3\n",
    "43 - BOS\n",
    "46 - 'c' on tok 1\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cltcYcNv6Sb2"
   ],
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f6a54a5242d4963959813217e192323": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3181d5a610e44d16a62010de88e34ea0",
       "IPY_MODEL_a7a3ecba6fe84610b9d1626cd05f25df"
      ],
      "layout": "IPY_MODEL_ed20c3fa79784d91870a84a098f04d33"
     }
    },
    "21a5279ec677451ba58792e4854a2616": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a20bc7d13734632abf89aba5de29b78",
       "IPY_MODEL_8f8c44017f6c4e48b4afab8c576bb969"
      ],
      "layout": "IPY_MODEL_777cdae240644161879a2bc28a8fa1f8"
     }
    },
    "3181d5a610e44d16a62010de88e34ea0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccbc8b30e53545cfb311f2e6d49da4fc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b7e63627055a42fd89d6e3dd2bfdfe42",
      "value": "0.056 MB of 0.056 MB uploaded (0.008 MB deduped)\r"
     }
    },
    "777cdae240644161879a2bc28a8fa1f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a1aee4c93d54e8bb96ec57425b69fc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a20bc7d13734632abf89aba5de29b78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c5ac6c09c6548f8bc2371707b67ad26",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8a1aee4c93d54e8bb96ec57425b69fc2",
      "value": "0.056 MB of 0.056 MB uploaded (0.008 MB deduped)\r"
     }
    },
    "8c5ac6c09c6548f8bc2371707b67ad26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f8c44017f6c4e48b4afab8c576bb969": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8b78e2de79b4174977cdd22187942ba",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9c5bdaaefca648ae92a6ea23c36b6304",
      "value": 1
     }
    },
    "9c5bdaaefca648ae92a6ea23c36b6304": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a7a3ecba6fe84610b9d1626cd05f25df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdbfe0ae850443b1978bed6d0d7f2bbe",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd9587b34348441da608ea83783adb63",
      "value": 1
     }
    },
    "b7e63627055a42fd89d6e3dd2bfdfe42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd9587b34348441da608ea83783adb63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ccbc8b30e53545cfb311f2e6d49da4fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdbfe0ae850443b1978bed6d0d7f2bbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8b78e2de79b4174977cdd22187942ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed20c3fa79784d91870a84a098f04d33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
