{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from iit.model_pairs.strict_iit_model_pair import StrictIITModelPair\n",
    "from iit.utils.iit_dataset import train_test_split\n",
    "from iit.utils.iit_dataset import IITDataset\n",
    "\n",
    "import circuits_benchmark.benchmark.cases.case_3 as case3\n",
    "import circuits_benchmark.benchmark.cases.case_4 as case4\n",
    "from circuits_benchmark.utils.ll_model_loader.ll_model_loader_factory import get_ll_model_loader\n",
    "from circuits_benchmark.utils.iit.iit_hl_model import IITHLModel\n",
    "from circuits_benchmark.transformers.hooked_tracr_transformer import HookedTracrTransformer\n",
    "from circuits_benchmark.benchmark.vocabs import TRACR_BOS, TRACR_PAD\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load cases from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Creating a SequenceMap with both inputs being the same SOp is discouraged. You should use a Map instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "#load cases\n",
    "cases = [case3.Case3(), case4.Case4()]\n",
    "corrs = []\n",
    "ll_models = []\n",
    "hl_models = []\n",
    "model_pairs = []\n",
    "for case in cases:\n",
    "    ll_model_loader = get_ll_model_loader(case, interp_bench=True)\n",
    "    corr, ll_model = ll_model_loader.load_ll_model_and_correspondence(device=device)\n",
    "    hl_model = case.get_hl_model()\n",
    "\n",
    "    if isinstance(hl_model, HookedTracrTransformer):\n",
    "        hl_model = IITHLModel(hl_model, eval_mode=True)\n",
    "\n",
    "    model_pair = case.build_model_pair(ll_model=ll_model, hl_model=hl_model)\n",
    "\n",
    "    corrs.append(corr)\n",
    "    ll_models.append(ll_model)\n",
    "    hl_models.append(hl_model)\n",
    "    model_pairs.append(model_pair)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate mixed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10\n"
     ]
    }
   ],
   "source": [
    "#find overall min and max sequence length (we'll have to pad some)\n",
    "min_seq_len = 100000\n",
    "max_seq_len = 0\n",
    "\n",
    "for case in cases:\n",
    "    if case.get_min_seq_len() < min_seq_len:\n",
    "        min_seq_len = case.get_min_seq_len()\n",
    "    if case.get_max_seq_len() > max_seq_len:\n",
    "        max_seq_len = case.get_max_seq_len()\n",
    "print(min_seq_len, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# find max vocab size (some tasks will just use a subset of vocab size)\n",
    "vocab_size = 0\n",
    "for case in cases:\n",
    "    if len(case.get_vocab()) > vocab_size:\n",
    "        vocab_size = len(case.get_vocab())\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320, 10000]\n"
     ]
    }
   ],
   "source": [
    "max_case_samples = 10_000\n",
    "case_samples = []\n",
    "for case in cases:\n",
    "    num_samples = min(max_case_samples, case.get_total_data_len())\n",
    "    case_samples.append(num_samples)\n",
    "print(case_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate clean and corrupted datasets\n",
    "clean_datasets = []\n",
    "corrupted_datasets = []\n",
    "masks = []\n",
    "for task_id, case, samples, hl_model in zip(range(len(cases)), cases, case_samples, hl_models):\n",
    "    dataset = case.get_clean_data(max_samples=samples)\n",
    "    encoder = hl_model.tracr_input_encoder    \n",
    "    # print(encoder.encoding_map)\n",
    "    def encode(tok):\n",
    "        return encoder.encoding_map[tok]\n",
    "\n",
    "\n",
    "    #Input\n",
    "    #put task_id after BOS token and pads after EOS.\n",
    "    inputs = dataset.inputs\n",
    "    str_tokens = [encoder.decode(inputs[i].tolist()) for i in range(inputs.shape[0])]\n",
    "    str_task_id = encoder.decode([task_id])\n",
    "    pads = [TRACR_PAD] * (max_seq_len - case.get_max_seq_len())\n",
    "    str_tokens = [str_task_id + [TRACR_BOS] + tokens[1:] + pads for tokens in str_tokens]\n",
    "    inputs = torch.tensor([list(map(encode, tokens)) for tokens in str_tokens])\n",
    "\n",
    "    #Target\n",
    "    #add 0 to beginning of seq and a bunch of 0s to end.\n",
    "    target = dataset.targets\n",
    "    label = torch.zeros((target.shape[0], 1, target.shape[2]), dtype=target.dtype)\n",
    "    pads = torch.zeros((target.shape[0], max_seq_len - case.get_max_seq_len(), target.shape[2]), dtype=target.dtype)\n",
    "    target = torch.cat((label, target, pads), dim=1)\n",
    "    dataset.inputs = inputs\n",
    "    dataset.targets = target\n",
    "    # print(clean_dataset.inputs.shape, dataset.inputs.shape)\n",
    "    # print(clean_dataset.targets.shape, dataset.targets.shape)\n",
    "    clean_datasets.append(dataset)\n",
    "\n",
    "    # if case.get_max_seq_len() < max_seq_len:\n",
    "    #     # pad sequences\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9920, 11]) torch.Size([10000, 11])\n"
     ]
    }
   ],
   "source": [
    "#make all datasets ~the same length by duplicating shorter datasets\n",
    "max_length = max([clean_dataset.inputs.shape[0] for clean_dataset in clean_datasets])\n",
    "\n",
    "for dset_list in [clean_datasets,]:\n",
    "    for dataset in dset_list:\n",
    "        if dataset.inputs.shape[0] < max_length:\n",
    "            num_dups = max_length // dataset.inputs.shape[0]\n",
    "            dataset.inputs = dataset.inputs.repeat(num_dups, 1)\n",
    "            dataset.targets = dataset.targets.repeat(num_dups, 1, 1)\n",
    "print(clean_datasets[0].inputs.shape, clean_datasets[1].inputs.shape)\n",
    "# print(corrupted_datasets[0].inputs.shape)#, corrupted_datasets[1].inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 2,  ..., 1, 1, 1],\n",
      "        [0, 0, 4,  ..., 1, 1, 1],\n",
      "        [0, 0, 5,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 5,  ..., 1, 1, 1],\n",
      "        [0, 0, 2,  ..., 1, 1, 1],\n",
      "        [0, 0, 3,  ..., 1, 1, 1]])\n",
      "torch.Size([19920, 11])\n",
      "torch.Size([19920, 11, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/qny1f95136l2lpppg_d78n6c0000gq/T/ipykernel_10159/284937192.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data = torch.tensor(data).to(int)\n",
      "/var/folders/ry/qny1f95136l2lpppg_d78n6c0000gq/T/ipykernel_10159/284937192.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.targets = torch.tensor(targets)\n"
     ]
    }
   ],
   "source": [
    "#smush datasets together into one big dataset, then shuffle\n",
    "datasets = []\n",
    "for dset_list in [clean_datasets,]:\n",
    "    print(dset_list[0].inputs)\n",
    "    inputs = torch.cat([dset.inputs for dset in dset_list], dim=0)\n",
    "    targets = torch.cat([dset.targets for dset in dset_list], dim=0)\n",
    "\n",
    "    # shuffle dataset contents, keeping inputs and targets in sync\n",
    "    indices = torch.randperm(inputs.shape[0])\n",
    "    inputs = inputs[indices]\n",
    "    targets = targets[indices]\n",
    "\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, data, targets):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                data (list or numpy array): List or array of input data.\n",
    "                targets (list or numpy array): List or array of target data.\n",
    "            \"\"\"\n",
    "            self.data = torch.tensor(data).to(int)\n",
    "            self.targets = torch.tensor(targets)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                idx (int): Index\n",
    "            Returns:\n",
    "                tuple: (input tensor, target tensor)\n",
    "            \"\"\"\n",
    "            return self.data[idx], self.targets[idx]\n",
    "\n",
    "    decorated_dset = CustomDataset(\n",
    "        data = inputs,\n",
    "        targets = targets,\n",
    "    )\n",
    "    print(decorated_dset.data.shape)\n",
    "    print(decorated_dset.targets.shape)\n",
    "\n",
    "    train_dataset, test_dataset = train_test_split(\n",
    "        decorated_dset, test_size=0.2, random_state=42\n",
    "    )\n",
    "    train_set = IITDataset(train_dataset, train_dataset, seed=0)\n",
    "    test_set = IITDataset(test_dataset, test_dataset, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test making a loader works\n",
    "loader = train_set.make_loader(batch_size=32, num_workers=0)\n",
    "for b, s in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Polysemantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 4, 3, 3, 3, 1, 1, 1, 1, 1])\n",
      "tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "tensor([[[False],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [False],\n",
      "         [False],\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]]])\n"
     ]
    }
   ],
   "source": [
    "from poly_hl_model import PolyHLModel\n",
    "\n",
    "model = PolyHLModel(hl_models, corrs, cases)\n",
    "\n",
    "input, target = train_dataset[4]\n",
    "output, cache = model.run_with_cache(input[None,:])\n",
    "print(input)\n",
    "# print(hl_models[0](input[1:6]))\n",
    "print(output[:1])\n",
    "print(target)\n",
    "print(model.mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import LL model and build model pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    }
   ],
   "source": [
    "import transformer_lens as tl\n",
    "\n",
    "D_MODEL = max(model.d_models)\n",
    "N_CTX = model.n_ctx\n",
    "N_LAYERS = model.n_layers\n",
    "N_HEADS = model.n_heads\n",
    "D_VOCAB = max([hl_model.cfg.d_vocab for hl_model in model.hl_models])\n",
    "\n",
    "#Want to specify this somewhere central, e.g., iit.tasks.ioi but iit.tasks.parens\n",
    "ll_cfg = tl.HookedTransformerConfig(\n",
    "        n_layers = N_LAYERS,\n",
    "        d_model = D_MODEL,\n",
    "        n_ctx = N_CTX,\n",
    "        d_head = D_MODEL // N_HEADS,\n",
    "        d_vocab = D_VOCAB,\n",
    "        act_fn = \"relu\",\n",
    ")\n",
    "\n",
    "class SingleOutputHookedTransformer(tl.HookedTransformer):\n",
    "    def forward(self, x):\n",
    "        output = super().forward(x)\n",
    "        return output[:,:,:1]\n",
    "\n",
    "ll_model = SingleOutputHookedTransformer(ll_cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "training_args = {\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 0.0001,\n",
    "    \"num_workers\": 0,\n",
    "    \"use_single_loss\": True,\n",
    "    \"behavior_weight\": 0.25,\n",
    "    \"iit_weight\": 0.5,\n",
    "    \"strict_weight\": 0.25,\n",
    "    \"clip_grad_norm\": False, #or float = 1.0\n",
    "    \"early_stop\" : True,\n",
    "    \"lr_scheduler\": torch.optim.lr_scheduler.LinearLR,\n",
    "    \"scheduler_kwargs\": dict(start_factor=1, end_factor=0, total_iters=n_epochs),\n",
    "    \"scheduler_val_metric\": [\"val/accuracy\", \"val/IIA\"], #for ReduceLRonPlateau\n",
    "    \"scheduler_mode\": \"max\", #for ReduceLRonPlateau\n",
    "}\n",
    "model_pair = StrictIITModelPair(hl_model=model, ll_model=ll_model, corr=model.corr, training_args=training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args={'batch_size': 256, 'lr': 0.001, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 100}, 'clip_grad_norm': False, 'seed': 0, 'detach_while_caching': True, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 0.5, 'behavior_weight': 0.25, 'strict_weight': 0.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678560791e4840719840f3e6d0d05afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.90e-04, train/iit_loss: 0.0495, train/behavior_loss: 0.0205, train/strict_loss: 0.0051, val/iit_loss: 0.0487, val/IIA: 27.00%, val/accuracy: 29.57%, val/strict_accuracy: 29.57%\n",
      "Epoch 2: lr: 9.80e-04, train/iit_loss: 0.0219, train/behavior_loss: 0.0050, train/strict_loss: 0.0012, val/iit_loss: 0.0515, val/IIA: 31.91%, val/accuracy: 41.93%, val/strict_accuracy: 41.93%\n",
      "Epoch 3: lr: 9.70e-04, train/iit_loss: 0.0183, train/behavior_loss: 0.0026, train/strict_loss: 0.0006, val/iit_loss: 0.0320, val/IIA: 46.52%, val/accuracy: 60.13%, val/strict_accuracy: 60.13%\n",
      "Epoch 4: lr: 9.60e-04, train/iit_loss: 0.0171, train/behavior_loss: 0.0018, train/strict_loss: 0.0004, val/iit_loss: 0.0305, val/IIA: 40.53%, val/accuracy: 57.51%, val/strict_accuracy: 57.51%\n",
      "Epoch 5: lr: 9.50e-04, train/iit_loss: 0.0162, train/behavior_loss: 0.0016, train/strict_loss: 0.0004, val/iit_loss: 0.0233, val/IIA: 57.10%, val/accuracy: 71.05%, val/strict_accuracy: 71.05%\n",
      "Epoch 6: lr: 9.40e-04, train/iit_loss: 0.0157, train/behavior_loss: 0.0012, train/strict_loss: 0.0003, val/iit_loss: 0.0346, val/IIA: 53.16%, val/accuracy: 65.77%, val/strict_accuracy: 65.77%\n",
      "Epoch 7: lr: 9.30e-04, train/iit_loss: 0.0119, train/behavior_loss: 0.0009, train/strict_loss: 0.0002, val/iit_loss: 0.0384, val/IIA: 53.89%, val/accuracy: 79.77%, val/strict_accuracy: 79.77%\n",
      "Epoch 8: lr: 9.20e-04, train/iit_loss: 0.0149, train/behavior_loss: 0.0011, train/strict_loss: 0.0003, val/iit_loss: 0.0138, val/IIA: 52.56%, val/accuracy: 64.27%, val/strict_accuracy: 64.27%\n",
      "Epoch 9: lr: 9.10e-04, train/iit_loss: 0.0139, train/behavior_loss: 0.0008, train/strict_loss: 0.0002, val/iit_loss: 0.0284, val/IIA: 46.34%, val/accuracy: 54.43%, val/strict_accuracy: 54.43%\n",
      "Epoch 10: lr: 9.00e-04, train/iit_loss: 0.0139, train/behavior_loss: 0.0009, train/strict_loss: 0.0002, val/iit_loss: 0.0230, val/IIA: 49.98%, val/accuracy: 60.36%, val/strict_accuracy: 60.36%\n",
      "Epoch 11: lr: 8.90e-04, train/iit_loss: 0.0108, train/behavior_loss: 0.0009, train/strict_loss: 0.0002, val/iit_loss: 0.0194, val/IIA: 65.79%, val/accuracy: 75.69%, val/strict_accuracy: 75.69%\n",
      "Epoch 12: lr: 8.80e-04, train/iit_loss: 0.0113, train/behavior_loss: 0.0008, train/strict_loss: 0.0002, val/iit_loss: 0.0135, val/IIA: 49.54%, val/accuracy: 56.63%, val/strict_accuracy: 56.63%\n",
      "Epoch 13: lr: 8.70e-04, train/iit_loss: 0.0119, train/behavior_loss: 0.0009, train/strict_loss: 0.0002, val/iit_loss: 0.0190, val/IIA: 56.86%, val/accuracy: 67.66%, val/strict_accuracy: 67.66%\n",
      "Epoch 14: lr: 8.60e-04, train/iit_loss: 0.0131, train/behavior_loss: 0.0010, train/strict_loss: 0.0002, val/iit_loss: 0.0134, val/IIA: 63.90%, val/accuracy: 69.35%, val/strict_accuracy: 69.35%\n",
      "Epoch 15: lr: 8.50e-04, train/iit_loss: 0.0097, train/behavior_loss: 0.0006, train/strict_loss: 0.0002, val/iit_loss: 0.0268, val/IIA: 61.94%, val/accuracy: 78.80%, val/strict_accuracy: 78.80%\n",
      "Epoch 16: lr: 8.40e-04, train/iit_loss: 0.0121, train/behavior_loss: 0.0008, train/strict_loss: 0.0002, val/iit_loss: 0.0197, val/IIA: 52.01%, val/accuracy: 66.86%, val/strict_accuracy: 66.86%\n",
      "Epoch 17: lr: 8.30e-04, train/iit_loss: 0.0108, train/behavior_loss: 0.0008, train/strict_loss: 0.0002, val/iit_loss: 0.0210, val/IIA: 68.36%, val/accuracy: 75.09%, val/strict_accuracy: 75.09%\n",
      "Epoch 18: lr: 8.20e-04, train/iit_loss: 0.0109, train/behavior_loss: 0.0008, train/strict_loss: 0.0002, val/iit_loss: 0.0145, val/IIA: 62.73%, val/accuracy: 74.99%, val/strict_accuracy: 74.99%\n",
      "Epoch 19: lr: 8.10e-04, train/iit_loss: 0.0101, train/behavior_loss: 0.0006, train/strict_loss: 0.0002, val/iit_loss: 0.0162, val/IIA: 63.68%, val/accuracy: 75.14%, val/strict_accuracy: 75.14%\n",
      "Epoch 20: lr: 8.00e-04, train/iit_loss: 0.0072, train/behavior_loss: 0.0004, train/strict_loss: 0.0001, val/iit_loss: 0.0190, val/IIA: 62.33%, val/accuracy: 73.88%, val/strict_accuracy: 73.88%\n",
      "Epoch 21: lr: 7.90e-04, train/iit_loss: 0.0105, train/behavior_loss: 0.0006, train/strict_loss: 0.0001, val/iit_loss: 0.0223, val/IIA: 62.63%, val/accuracy: 81.59%, val/strict_accuracy: 81.59%\n",
      "Epoch 22: lr: 7.80e-04, train/iit_loss: 0.0090, train/behavior_loss: 0.0006, train/strict_loss: 0.0001, val/iit_loss: 0.0199, val/IIA: 56.45%, val/accuracy: 72.55%, val/strict_accuracy: 72.55%\n",
      "Epoch 23: lr: 7.70e-04, train/iit_loss: 0.0109, train/behavior_loss: 0.0008, train/strict_loss: 0.0002, val/iit_loss: 0.0226, val/IIA: 66.26%, val/accuracy: 79.97%, val/strict_accuracy: 79.97%\n",
      "Epoch 24: lr: 7.60e-04, train/iit_loss: 0.0088, train/behavior_loss: 0.0006, train/strict_loss: 0.0002, val/iit_loss: 0.0141, val/IIA: 76.81%, val/accuracy: 91.60%, val/strict_accuracy: 91.60%\n",
      "Epoch 25: lr: 7.50e-04, train/iit_loss: 0.0073, train/behavior_loss: 0.0004, train/strict_loss: 0.0001, val/iit_loss: 0.0108, val/IIA: 64.52%, val/accuracy: 77.25%, val/strict_accuracy: 77.25%\n",
      "Epoch 26: lr: 7.40e-04, train/iit_loss: 0.0100, train/behavior_loss: 0.0006, train/strict_loss: 0.0001, val/iit_loss: 0.0152, val/IIA: 53.51%, val/accuracy: 70.65%, val/strict_accuracy: 70.65%\n",
      "Epoch 27: lr: 7.30e-04, train/iit_loss: 0.0129, train/behavior_loss: 0.0008, train/strict_loss: 0.0002, val/iit_loss: 0.0148, val/IIA: 60.58%, val/accuracy: 68.65%, val/strict_accuracy: 68.65%\n",
      "Epoch 28: lr: 7.20e-04, train/iit_loss: 0.0105, train/behavior_loss: 0.0006, train/strict_loss: 0.0002, val/iit_loss: 0.0161, val/IIA: 63.64%, val/accuracy: 70.18%, val/strict_accuracy: 70.18%\n",
      "Epoch 29: lr: 7.10e-04, train/iit_loss: 0.0111, train/behavior_loss: 0.0007, train/strict_loss: 0.0002, val/iit_loss: 0.0187, val/IIA: 62.75%, val/accuracy: 73.83%, val/strict_accuracy: 73.83%\n",
      "Epoch 30: lr: 7.00e-04, train/iit_loss: 0.0110, train/behavior_loss: 0.0007, train/strict_loss: 0.0002, val/iit_loss: 0.0146, val/IIA: 60.55%, val/accuracy: 67.55%, val/strict_accuracy: 67.55%\n",
      "Epoch 31: lr: 6.90e-04, train/iit_loss: 0.0091, train/behavior_loss: 0.0006, train/strict_loss: 0.0001, val/iit_loss: 0.0223, val/IIA: 48.10%, val/accuracy: 54.28%, val/strict_accuracy: 54.28%\n",
      "Epoch 32: lr: 6.80e-04, train/iit_loss: 0.0078, train/behavior_loss: 0.0005, train/strict_loss: 0.0001, val/iit_loss: 0.0263, val/IIA: 67.71%, val/accuracy: 81.57%, val/strict_accuracy: 81.57%\n",
      "Epoch 33: lr: 6.70e-04, train/iit_loss: 0.0105, train/behavior_loss: 0.0006, train/strict_loss: 0.0002, val/iit_loss: 0.0200, val/IIA: 67.85%, val/accuracy: 77.66%, val/strict_accuracy: 77.66%\n",
      "Epoch 34: lr: 6.60e-04, train/iit_loss: 0.0103, train/behavior_loss: 0.0006, train/strict_loss: 0.0002, val/iit_loss: 0.0212, val/IIA: 68.63%, val/accuracy: 81.77%, val/strict_accuracy: 81.77%\n",
      "Epoch 35: lr: 6.50e-04, train/iit_loss: 0.0113, train/behavior_loss: 0.0007, train/strict_loss: 0.0002, val/iit_loss: 0.0192, val/IIA: 68.89%, val/accuracy: 79.69%, val/strict_accuracy: 79.69%\n",
      "Epoch 36: lr: 6.40e-04, train/iit_loss: 0.0084, train/behavior_loss: 0.0004, train/strict_loss: 0.0001, val/iit_loss: 0.0240, val/IIA: 74.16%, val/accuracy: 92.09%, val/strict_accuracy: 92.09%\n",
      "Epoch 37: lr: 6.30e-04, train/iit_loss: 0.0091, train/behavior_loss: 0.0005, train/strict_loss: 0.0001, val/iit_loss: 0.0231, val/IIA: 70.88%, val/accuracy: 87.44%, val/strict_accuracy: 87.44%\n",
      "Epoch 38: lr: 6.20e-04, train/iit_loss: 0.0086, train/behavior_loss: 0.0005, train/strict_loss: 0.0001, val/iit_loss: 0.0275, val/IIA: 60.47%, val/accuracy: 68.47%, val/strict_accuracy: 68.47%\n",
      "Epoch 39: lr: 6.10e-04, train/iit_loss: 0.0084, train/behavior_loss: 0.0006, train/strict_loss: 0.0001, val/iit_loss: 0.0292, val/IIA: 73.43%, val/accuracy: 94.30%, val/strict_accuracy: 94.30%\n",
      "Epoch 40: lr: 6.00e-04, train/iit_loss: 0.0108, train/behavior_loss: 0.0006, train/strict_loss: 0.0001, val/iit_loss: 0.0186, val/IIA: 63.05%, val/accuracy: 75.93%, val/strict_accuracy: 75.93%\n",
      "Epoch 41: lr: 5.90e-04, train/iit_loss: 0.0088, train/behavior_loss: 0.0005, train/strict_loss: 0.0001, val/iit_loss: 0.0153, val/IIA: 72.44%, val/accuracy: 89.48%, val/strict_accuracy: 89.48%\n",
      "Epoch 42: lr: 5.80e-04, train/iit_loss: 0.0111, train/behavior_loss: 0.0008, train/strict_loss: 0.0002, val/iit_loss: 0.0179, val/IIA: 80.84%, val/accuracy: 94.78%, val/strict_accuracy: 94.78%\n",
      "Epoch 43: lr: 5.70e-04, train/iit_loss: 0.0107, train/behavior_loss: 0.0006, train/strict_loss: 0.0001, val/iit_loss: 0.0140, val/IIA: 60.71%, val/accuracy: 71.69%, val/strict_accuracy: 71.69%\n",
      "Epoch 44: lr: 5.60e-04, train/iit_loss: 0.0101, train/behavior_loss: 0.0006, train/strict_loss: 0.0001, val/iit_loss: 0.0149, val/IIA: 65.47%, val/accuracy: 82.24%, val/strict_accuracy: 82.24%\n",
      "Epoch 45: lr: 5.50e-04, train/iit_loss: 0.0100, train/behavior_loss: 0.0005, train/strict_loss: 0.0001, val/iit_loss: 0.0124, val/IIA: 72.76%, val/accuracy: 79.45%, val/strict_accuracy: 79.45%\n",
      "Epoch 46: lr: 5.40e-04, train/iit_loss: 0.0101, train/behavior_loss: 0.0005, train/strict_loss: 0.0001, val/iit_loss: 0.0166, val/IIA: 63.48%, val/accuracy: 71.25%, val/strict_accuracy: 71.25%\n",
      "Epoch 47: lr: 5.30e-04, train/iit_loss: 0.0075, train/behavior_loss: 0.0004, train/strict_loss: 0.0001, val/iit_loss: 0.0376, val/IIA: 74.78%, val/accuracy: 87.82%, val/strict_accuracy: 87.82%\n",
      "Epoch 48: lr: 5.20e-04, train/iit_loss: 0.0080, train/behavior_loss: 0.0004, train/strict_loss: 0.0001, val/iit_loss: 0.0185, val/IIA: 72.56%, val/accuracy: 87.11%, val/strict_accuracy: 87.11%\n",
      "Epoch 49: lr: 5.10e-04, train/iit_loss: 0.0092, train/behavior_loss: 0.0004, train/strict_loss: 0.0001, val/iit_loss: 0.0220, val/IIA: 67.95%, val/accuracy: 85.83%, val/strict_accuracy: 85.83%\n",
      "Epoch 50: lr: 5.00e-04, train/iit_loss: 0.0097, train/behavior_loss: 0.0005, train/strict_loss: 0.0001, val/iit_loss: 0.0166, val/IIA: 75.08%, val/accuracy: 88.61%, val/strict_accuracy: 88.61%\n",
      "Epoch 51: lr: 4.90e-04, train/iit_loss: 0.0068, train/behavior_loss: 0.0003, train/strict_loss: 0.0001, val/iit_loss: 0.0177, val/IIA: 72.04%, val/accuracy: 87.77%, val/strict_accuracy: 87.77%\n"
     ]
    }
   ],
   "source": [
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
