{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aadb87f4-0900-402d-bcb9-80d8ab780d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08091f5a-0c98-4367-80e3-7611a4f5d626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n",
      "All tests passed!\n",
      "check: [ 0 0 ]  BOS ( ) ) ) ) ) ) ( ) ( ) PAD\n",
      "check: [ 0 0 ]  BOS ( ( ) ( ) ( ) ( ( ( ) PAD\n",
      "check: [ 1 1 ]  BOS ( ( ) ( ( ( ) ( ) ) ) PAD\n",
      "check: [ 0 0 ]  BOS ( ) ) ) ( ( ( ( ( ) ) PAD\n",
      "check: [ 0 0 ]  BOS ( ) ) ) ( ( ( ) ( ( ) PAD\n",
      "check: [ 1 1 ]  BOS ( ( ) ( ) ( ) ( ( ) ) PAD\n",
      "check: [ 0 0 ]  BOS ( ) ) ) ) ) ) ) ) ) ) PAD\n",
      "check: [ 0 0 ]  BOS ( ( ) ( ( ( ) ) ( ( ( PAD\n",
      "check: [ 0 0 ]  BOS ( ) ) ) ( ( ) ) ) ( ) PAD\n",
      "check: [ 0 0 ]  BOS ( ( ( ) ( ( ( ) ) ( ) PAD\n",
      "check: [ 1 1 ]  BOS ( ( ( ) ) ( ) ( ( ) ) PAD\n",
      "check: [ 0 0 ]  BOS ( ) ) ) ( ( ( ) ) ( ( PAD\n",
      "check: [ 1 1 ]  BOS ) ( ( ( ) ( ) ) ( ( ( PAD\n",
      "check: [ 1 1 ]  BOS ) ) ( ( ) ( ( ( ) ( ) PAD\n",
      "check: [ 1 1 ]  BOS ) ( ) ( ( ( ( ( ) ) ) PAD\n",
      "check: [ 0 0 ]  BOS ) ) ) ) ) ) ) ) ) ) ) PAD\n",
      "check: [ 0 0 ]  BOS ) ) ) ) ) ) ) ) ( ) ) PAD\n",
      "check: [ 1 1 ]  BOS ) ( ( ) ( ( ( ( ( ( ( PAD\n",
      "check: [ 0 0 ]  BOS ) ) ) ) ) ) ) ) ) ( ) PAD\n",
      "check: [ 0 0 ]  BOS ) ) ) ) ) ) ) ) ) ) ( PAD\n",
      "check: [ 1 1 ]  BOS ) ) ( ( ( ( ( ( ( ( ( PAD\n",
      "check: [ 0 0 ]  BOS ) ) ) ) ) ( ) ) ) ) ) PAD\n",
      "check: [ 1 1 ]  BOS ) ) ( ( ) ( ( ( ) ( ( PAD\n",
      "check: [ 0 0 ]  BOS ) ) ) ) ( ) ( ) ) ) ) PAD\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from paren_checker import HighLevelParensBalanceChecker, BalancedParensDataset, LeftGreaterParensDataset, TwoTaskParensDataset\n",
    "from paren_checker import test_HL_parens_balancer_components, test_HL_parens_gtr_components\n",
    "test_HL_parens_balancer_components()\n",
    "test_HL_parens_gtr_components()\n",
    "balance_checker = HighLevelParensBalanceChecker()\n",
    "dset = TwoTaskParensDataset(\n",
    "        N_samples = 24,\n",
    "        n_ctx = 13, #accounts for a BOS and a PAD and a token marker\n",
    "        seed = 42\n",
    "    )\n",
    "\n",
    "for item in dset.get_dataset():\n",
    "    output = balance_checker(t.Tensor(item['tokens'])[None,:])\n",
    "    hl_output = balance_checker(t.Tensor(item['tokens'])[None,:])\n",
    "    # print(hl_output)\n",
    "    print('check: [', output[0].int().item(), item['labels'], '] ', ''.join(item['str_tokens']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c5b0b-abee-4cf4-a17f-73868919b479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "HookedTransformer(\n",
      "  (embed): Embed()\n",
      "  (hook_embed): HookPoint()\n",
      "  (pos_embed): PosEmbed()\n",
      "  (hook_pos_embed): HookPoint()\n",
      "  (blocks): ModuleList(\n",
      "    (0-2): 3 x TransformerBlock(\n",
      "      (ln1): LayerNorm(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (ln2): LayerNorm(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (hook_k): HookPoint()\n",
      "        (hook_q): HookPoint()\n",
      "        (hook_v): HookPoint()\n",
      "        (hook_z): HookPoint()\n",
      "        (hook_attn_scores): HookPoint()\n",
      "        (hook_pattern): HookPoint()\n",
      "        (hook_result): HookPoint()\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (hook_pre): HookPoint()\n",
      "        (hook_post): HookPoint()\n",
      "      )\n",
      "      (hook_attn_in): HookPoint()\n",
      "      (hook_q_input): HookPoint()\n",
      "      (hook_k_input): HookPoint()\n",
      "      (hook_v_input): HookPoint()\n",
      "      (hook_mlp_in): HookPoint()\n",
      "      (hook_attn_out): HookPoint()\n",
      "      (hook_mlp_out): HookPoint()\n",
      "      (hook_resid_pre): HookPoint()\n",
      "      (hook_resid_mid): HookPoint()\n",
      "      (hook_resid_post): HookPoint()\n",
      "    )\n",
      "  )\n",
      "  (ln_final): LayerNorm(\n",
      "    (hook_scale): HookPoint()\n",
      "    (hook_normalized): HookPoint()\n",
      "  )\n",
      "  (unembed): Unembed()\n",
      ")\n",
      "\n",
      "Correspondence:\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "left_parens_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "right_parens_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "mlp0_hook {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp1_hook {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "horizon_lookback_hook {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "output_check_hook {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "\n",
      "Unused:\n",
      "LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)\n",
      "LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None)\n",
      "LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None)\n",
      "LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None)\n",
      "LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None)\n",
      "LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None)\n",
      "LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None)\n",
      "LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None)\n"
     ]
    }
   ],
   "source": [
    "from paren_checker import get_LL_parens_model_and_correspondence\n",
    "ll_model, corr, unused_nodes = get_LL_parens_model_and_correspondence()\n",
    "print(\"Model:\")\n",
    "print(ll_model)\n",
    "print(\"\\nCorrespondence:\")\n",
    "for k, i in corr.items():\n",
    "    print(k, i)\n",
    "print(\"\\nUnused:\")\n",
    "for n in unused_nodes:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad087a-b145-48f4-ab2c-75ecc6f7b2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 4)\n"
     ]
    }
   ],
   "source": [
    "dset = TwoTaskParensDataset(\n",
    "        N_samples = 20_000,\n",
    "        n_ctx = 23, #accounts for a BOS, task_id, and a PAD\n",
    "        seed = 42\n",
    "    )\n",
    "# dset = LeftGreaterParensDataset(\n",
    "#         N_samples = 10_000,\n",
    "#         n_ctx = 23, #accounts for a BOS, task_id, and a PAD\n",
    "#         seed = 42\n",
    "#     )\n",
    "# dset = BalancedParensDataset(\n",
    "#         N_samples = 10_000,\n",
    "#         n_ctx = 23, #accounts for a BOS, task_id, and a PAD\n",
    "#         seed = 42\n",
    "#     )\n",
    "dataset = dset.get_dataset()\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8849e1c-0a95-4b12-97d3-8c94278adb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01540efd6adb44c584b06daf819f6a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Epoch 1/200:   0%|          | 0/200 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 22\u001b[0m\n\u001b[1;32m      6\u001b[0m ll_model, corr, unused_nodes \u001b[38;5;241m=\u001b[39m get_LL_parens_model_and_correspondence(n_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m23\u001b[39m)\n\u001b[1;32m      8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ModelTrainerSIIT(\n\u001b[1;32m      9\u001b[0m     ll_model\u001b[38;5;241m=\u001b[39mll_model,\n\u001b[1;32m     10\u001b[0m     hl_model\u001b[38;5;241m=\u001b[39mbalance_checker,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/circuits-benchmark-saes/quick-experiments/siit_utils.py:319\u001b[0m, in \u001b[0;36mModelTrainerSIIT.train\u001b[0;34m(self, epochs, use_wandb, lr, **optim_kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_IIA\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(iia\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    317\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_siit_wrong\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(siit_wrong\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m--> 319\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    322\u001b[0m train_progress_bar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, iia\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miia\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/circuits_bench/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/circuits_bench/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/circuits_bench/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from siit_utils import ModelTrainerSIIT\n",
    "from paren_checker import paren_checker_loss_fn as loss_fn\n",
    "\n",
    "t.manual_seed(150)\n",
    "ll_model, corr, unused_nodes = get_LL_parens_model_and_correspondence(n_ctx = 23)\n",
    "\n",
    "trainer = ModelTrainerSIIT(\n",
    "    ll_model=ll_model,\n",
    "    hl_model=balance_checker,\n",
    "    dataset=dataset,\n",
    "    corr=corr,\n",
    "    unused_nodes=unused_nodes,\n",
    "    loss_fn=loss_fn,\n",
    "    baseline_weight = 1,\n",
    "    iit_weight = 1,\n",
    "    siit_weight = 1,\n",
    "    batch_size = 128,\n",
    "    device = 'cpu'\n",
    ")\n",
    "\n",
    "results = trainer.train(epochs=200, lr=1e-4, weight_decay = 1e-3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a51fc16-d9fe-497b-bb03-88490768679b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.semilogy(results['train_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "77d0dac6-6c3e-4a0b-8716-42d5b01cb3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "steps = np.arange(len(np.array(results['test_siit_wrong'])))\n",
    "plt.figure()\n",
    "plt.semilogy(steps, np.array(results['test_siit_wrong']))\n",
    "plt.xlim(0, steps.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f6f419e-938c-4f75-b9d7-f6cc712322b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "steps = np.arange(len(np.array(results['test_IIA'])))\n",
    "plt.figure()\n",
    "plt.semilogy(steps, 1 - np.array(results['test_IIA']))\n",
    "plt.xlim(0, steps.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61f9b230-1fc9-47d9-b7dc-70aea22b25db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "Method: zero\n",
      "Errors: 1001/2000, Ablated Err: 1001/2000\n",
      "\n",
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "Method: mean\n",
      "Errors: 1001/2000, Ablated Err: 1001/2000\n",
      "\n",
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 0.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
      "        0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 1., 0.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 1., 0., 1., 0.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor([-1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504,\n",
      "        -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504, -1.5504],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>) tensor([0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
      "        1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.])\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "tensor(1.) tensor(1, dtype=torch.int32)\n",
      "Method: shuffle\n",
      "Errors: 1001/2000, Ablated Err: 1001/2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from siit_utils import make_post_ablation_hook\n",
    "\n",
    "for method in ['zero', 'mean', 'shuffle']:\n",
    "    tot = 0\n",
    "    errors = 0\n",
    "    ablated_errors = 0\n",
    "    for b in trainer.test_dataloaders[0]:\n",
    "        tokens, labels = b\n",
    "        logits, cache = ll_model.run_with_cache(tokens)\n",
    "        output_labels = t.round(t.sigmoid(logits)[:,-1,-1])\n",
    "        print(logits[:,0,-1], labels)\n",
    "        sumdiff = (labels.cuda() != output_labels.float()).sum().item()\n",
    "        for err in range(sumdiff):\n",
    "            print(labels.cpu()[labels.cpu() != output_labels.float().cpu()][err], tokens[labels.cpu() != output_labels.float().cpu()][err, 1])\n",
    "    \n",
    "        hooks = []\n",
    "        for node in unused_nodes:\n",
    "            hooks.append((node.name, make_post_ablation_hook(ll_node=node, ll_cache=cache, method=method)))\n",
    "        ablated_logits = ll_model.run_with_hooks(tokens, fwd_hooks=hooks)\n",
    "        \n",
    "        ablated_labels = t.round(t.sigmoid(ablated_logits)[:,-1,-1])\n",
    "        ablated_sumdiff = (labels.cuda() != ablated_labels.float()).sum().item()\n",
    "    \n",
    "        errors += sumdiff\n",
    "        ablated_errors += ablated_sumdiff\n",
    "        tot += labels.numel()\n",
    "    print(f'Method: {method}')\n",
    "    print(f'Errors: {errors}/{tot}, Ablated Err: {ablated_errors}/{tot}\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4175b6e-6308-455d-bff9-5cece1ab0b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add lines to save model to huggingface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed4627-f8eb-4ccc-be69-35beb1138f07",
   "metadata": {},
   "source": [
    "# Take a peek at the attention pattern on the important heads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42cce14-255f-43a2-b427-3149481a8475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c580dbba-f101-4bf4-a1ea-15f9a50b801d",
   "metadata": {},
   "source": [
    "# SAEs -- vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51bb0308-b17b-405a-95fb-d7d0895b5197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Encoded: [3, 0, 1, 0, 1, 2, 2, 2]\n",
      "Decoded: BOS ( ) ( ) PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "from paren_checker import create_paren_checker_tokenizer\n",
    "tokenizer = create_paren_checker_tokenizer()\n",
    "ll_model.tokenizer = tokenizer #attach to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc6b5b5f-8485-4cc6-8f0b-0f2f3c1a72cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_head_index 0\n",
      "d_in 8\n",
      "wandb_project benchmark_saes\n",
      "Run name: 32-L1-0.2-LR-0.0003-Tokens-1.000e+08\n",
      "n_tokens_per_buffer (millions): 0.00336\n",
      "Lower bound: n_contexts_per_buffer (millions): 8e-05\n",
      "Total training steps: 9300\n",
      "Total wandb updates: 930\n",
      "n_tokens_per_feature_sampling_window (millions): 903.168\n",
      "n_tokens_per_dead_feature_window (millions): 451.584\n",
      "We will reset the sparsity calculation 4 times.\n",
      "Number tokens in sparsity calculation window: 2.15e+07\n",
      "Using Ghost Grads.\n"
     ]
    }
   ],
   "source": [
    "from sae_utils import make_sae_lens_config\n",
    "sae_lens_cfg = make_sae_lens_config(\n",
    "    model=ll_model,\n",
    "    hook_name=\"blocks.0.attn.hook_z\", \n",
    "    hook_layer=0, \n",
    "    l1_coefficient=0.2,\n",
    "    l1_warm_up_steps = 0,\n",
    "    hook_head_index=0, \n",
    "    context_size=ll_model.cfg.n_ctx,\n",
    "    d_in=ll_model.cfg.d_head,\n",
    "    device = 'cuda',\n",
    "    checkpoint_path = f\"$HOME/persistent-storage/tracr_saes/parens_sae_checkpoints\",\n",
    "    wandb_project =  \"benchmark_saes\",\n",
    "    training_tokens = 100_000_000,\n",
    "    batch_size = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eacc2c33-2a8d-446b-8fb3-8e5e7cc1f3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mevanhanders\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/quick-experiments/wandb/run-20240711_185327-w66x2lqo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evanhanders/benchmark_saes/runs/w66x2lqo' target=\"_blank\">32-L1-0.2-LR-0.0003-Tokens-1.000e+08</a></strong> to <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/w66x2lqo' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/w66x2lqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SAE:   0%|                                                                         | 0/100000000 [00:00<?, ?it/s]/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:254: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yield torch.tensor(\n",
      "1800| MSE Loss 0.044 | L1 0.141:  19%|██████▊                            | 19353600/100000000 [01:35<06:37, 202837.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/dccr8n2y/20009472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3700| MSE Loss 0.033 | L1 0.127:  40%|█████████████▉                     | 39782400/100000000 [03:23<05:16, 190404.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/dccr8n2y/40008192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5500| MSE Loss 0.033 | L1 0.142:  59%|████████████████████▋              | 59136000/100000000 [05:01<03:23, 201183.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/dccr8n2y/60006912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7400| MSE Loss 0.028 | L1 0.145:  80%|███████████████████████████▊       | 79564800/100000000 [06:48<01:50, 184838.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/dccr8n2y/80005632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9300| MSE Loss 0.033 | L1 0.151: 100%|██████████████████████████████████▉| 99993600/100000000 [08:32<00:00, 198136.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/dccr8n2y/final_100004352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9300| MSE Loss 0.033 | L1 0.151: 100%|██████████████████████████████████▉| 99993600/100000000 [08:33<00:00, 194713.44it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.037 MB of 0.037 MB uploaded (0.009 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 17.4%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/current_learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▅▃▃▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/explained_variance</td><td>▁▅▆▇██▇▇▇▇████████▇██▇██████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>█▅▅▂▁▁▂▂▃▂▂▂▂▁▁▁▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▁▁▂▂▂▂</td></tr><tr><td>metrics/l0</td><td>█▆▄▃▃▃▃▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▄▂▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁▂▅█</td></tr><tr><td>sparsity/below_1e-6</td><td>▁▁██</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁█▁▁▁█</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▁▁▂▃▁▁▂▃▄▂▃▃▅▅▃▃▄▅▅▄▃▅▅▆▅▆▅▆▅▃▄▇▇█▆▅▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>0.2</td></tr><tr><td>details/current_learning_rate</td><td>0.0003</td></tr><tr><td>details/n_training_tokens</td><td>99993600</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.0</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.00414</td></tr><tr><td>losses/l1_loss</td><td>0.75696</td></tr><tr><td>losses/mse_loss</td><td>0.03315</td></tr><tr><td>losses/overall_loss</td><td>0.18868</td></tr><tr><td>metrics/explained_variance</td><td>0.84839</td></tr><tr><td>metrics/explained_variance_std</td><td>0.22962</td></tr><tr><td>metrics/l0</td><td>3.1625</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-3.54624</td></tr><tr><td>sparsity/below_1e-5</td><td>13</td></tr><tr><td>sparsity/below_1e-6</td><td>1</td></tr><tr><td>sparsity/dead_features</td><td>0</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>163.84375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">32-L1-0.2-LR-0.0003-Tokens-1.000e+08</strong> at: <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/w66x2lqo' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/w66x2lqo</a><br/> View project at: <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a><br/>Synced 5 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240711_185327-w66x2lqo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sae_utils import train_sae\n",
    "\n",
    "#I need to be able to tell the SAE to ignore certain tokens during training.\n",
    "sae, store = train_sae(ll_model, sae_lens_cfg, dataset, batch_size=256)#, ignore_tokens=[])#2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13048231-5087-43d3-928d-84b862df9e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12938/718347451.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t.tensor(dataset['tokens']).int(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1ec3ebfadc41f686d91362c41849c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/381 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens torch.Size([97472, 42])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4093824, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sae_utils import make_token_df\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_activations_sum = t.zeros(sae.cfg.d_sae).to(sae.device)\n",
    "input_tokens_list = []\n",
    "learned_activations = []\n",
    "extras_list = []\n",
    "extra_hook = 'left_paren_hook'\n",
    "extra_name = 'left_parens'\n",
    "\n",
    "t_dataset = TensorDataset(\n",
    "    t.tensor(dataset['tokens']).int(), \n",
    "    t.tensor(dataset['labels']).float()\n",
    ")\n",
    "dataloader  = DataLoader(t_dataset, batch_size=256, shuffle = False)\n",
    "\n",
    "#go through the training dataset and get max activations for each feature\n",
    "total_inputs = 0\n",
    "for batch in tqdm(dataloader):\n",
    "    tokens, labels = batch\n",
    "    total_inputs += tokens.numel()\n",
    "    logits, cache = ll_model.run_with_cache(tokens)\n",
    "    sae_in = cache[sae.cfg.hook_name]\n",
    "    if sae.cfg.hook_head_index is not None:\n",
    "        sae_in = sae_in[:,:,sae.cfg.hook_head_index,:] #I think this is how attn head indexing works...\n",
    "    activations = sae.encode(sae_in)\n",
    "    # print(activations.shape, labels.shape, tokens.shape, tokens.numel())\n",
    "    activations[t.isin(tokens.int(), t.Tensor([2, 3]).int())] = 0\n",
    "\n",
    "    # For sparsity calculation\n",
    "    n_new_activations = (activations > 0).sum(dim=(0,1)) #sum over batch and ctx\n",
    "    n_activations_sum = n_activations_sum + n_new_activations\n",
    "\n",
    "    # Save tokens and activations\n",
    "    input_tokens_list.append(tokens.cpu())\n",
    "    learned_activations.append(activations.to(t.float16).cpu().reshape(-1, sae.cfg.d_sae))\n",
    "\n",
    "    #HL output\n",
    "    hl_output, hl_cache = balance_checker.run_with_cache(tokens)\n",
    "    extra = hl_cache[extra_hook]\n",
    "    extras_list.append(extra.cpu())\n",
    "\n",
    "    # if total_inputs > 100_000:\n",
    "    #     break\n",
    "sparsity = n_activations_sum / total_inputs\n",
    "tokens = t.cat(input_tokens_list).to(int)\n",
    "extras = t.cat(extras_list).to(int)\n",
    "token_df = make_token_df(ll_model, tokens, len_prefix=ll_model.cfg.n_ctx, \n",
    "                         extra_token_labels={extra_name : extras})\n",
    "learned_activations = t.cat(learned_activations).to(t.float16)\n",
    "token_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a00cb9d1-c7ed-41a9-ace9-ee83ce9661bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8f8a148f23465480955f64a4413629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Feature:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498f432e550840b78da23c5b62f92f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformer_lens import utils\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def update_dataframe(feature_id):\n",
    "    token_df[\"activation\"] = utils.to_numpy(learned_activations[:,feature_id])\n",
    "    df = token_df[['str_tokens','prefix', 'suffix',  'context', 'activation', extra_name]]\n",
    "    df = df.sort_values(\"activation\", ascending=False).head(100)\n",
    "    # display(df[df['activation'] > 0].style.background_gradient(\"coolwarm\"))\n",
    "    unique = df[['str_tokens', 'prefix', 'activation', extra_name]].drop_duplicates()\n",
    "    display(unique[unique['activation'] > 0].head(100).style.background_gradient(\"coolwarm\"))\n",
    "\n",
    "# Define the dropdown menu for 'feat'\n",
    "feat_dropdown = widgets.Dropdown(\n",
    "    options=range(sae.cfg.d_sae),\n",
    "    value=0,\n",
    "    description='Feature:',\n",
    ")\n",
    "\n",
    "# Create an interactive output widget\n",
    "output = widgets.interactive_output(\n",
    "    update_dataframe, \n",
    "    {\n",
    "        'feature_id': feat_dropdown,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the dropdown menu and output\n",
    "display(feat_dropdown, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c383c1-d5a0-45a7-a328-83261f98f6db",
   "metadata": {},
   "source": [
    "sae for attn 0 head 0:\n",
    "\n",
    "TBD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7216dd9-1741-41dc-aa50-74aef1dd1b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_in 64\n",
      "wandb_project benchmark_saes\n",
      "Run name: 256-L1-0.2-LR-0.0003-Tokens-1.000e+08\n",
      "n_tokens_per_buffer (millions): 0.00336\n",
      "Lower bound: n_contexts_per_buffer (millions): 8e-05\n",
      "Total training steps: 9300\n",
      "Total wandb updates: 930\n",
      "n_tokens_per_feature_sampling_window (millions): 903.168\n",
      "n_tokens_per_dead_feature_window (millions): 451.584\n",
      "We will reset the sparsity calculation 4 times.\n",
      "Number tokens in sparsity calculation window: 2.15e+07\n",
      "Using Ghost Grads.\n"
     ]
    }
   ],
   "source": [
    "from sae_utils import make_sae_lens_config\n",
    "sae_lens_cfg = make_sae_lens_config(\n",
    "    model=ll_model, \n",
    "    hook_name=\"blocks.0.mlp.hook_post\", \n",
    "    hook_layer=0, \n",
    "    l1_coefficient=0.2,\n",
    "    l1_warm_up_steps = 0,\n",
    "    context_size=ll_model.cfg.n_ctx,\n",
    "    d_in=ll_model.cfg.d_mlp,\n",
    "    device = 'cuda',\n",
    "    checkpoint_path = f\"$HOME/persistent-storage/tracr_saes/parens_sae_checkpoints\",\n",
    "    wandb_project =  \"benchmark_saes\",\n",
    "    training_tokens = 100_000_000,\n",
    "    batch_size = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ab00b93-9307-482f-89fb-42286e694da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/quick-experiments/wandb/run-20240711_203830-wzwdcw5r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evanhanders/benchmark_saes/runs/wzwdcw5r' target=\"_blank\">256-L1-0.2-LR-0.0003-Tokens-1.000e+08</a></strong> to <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/wzwdcw5r' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/wzwdcw5r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SAE:   0%|                                                                         | 0/100000000 [00:00<?, ?it/s]/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:254: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yield torch.tensor(\n",
      "1800| MSE Loss 0.214 | L1 0.991:  19%|██████▊                            | 19353600/100000000 [01:44<07:40, 175175.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/1ct4tqbi/20009472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3700| MSE Loss 0.196 | L1 0.907:  40%|█████████████▉                     | 39782400/100000000 [03:37<05:34, 179809.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/1ct4tqbi/40008192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5500| MSE Loss 0.245 | L1 0.811:  59%|████████████████████▋              | 59136000/100000000 [05:23<03:54, 174439.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/1ct4tqbi/60006912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7400| MSE Loss 0.189 | L1 1.034:  80%|███████████████████████████▊       | 79564800/100000000 [07:17<01:53, 179617.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/1ct4tqbi/80005632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9300| MSE Loss 0.121 | L1 0.773: 100%|██████████████████████████████████▉| 99993600/100000000 [09:08<00:00, 182530.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/1ct4tqbi/final_100004352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9300| MSE Loss 0.121 | L1 0.773: 100%|██████████████████████████████████▉| 99993600/100000000 [09:08<00:00, 182207.75it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.662 MB of 0.662 MB uploaded (0.009 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 1.3%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/current_learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▃▂▂▂▂▂▁▂▁▁▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/explained_variance</td><td>▁▆▇▇████▇█████████▇█████████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>█▂▂▂▂▁▁▁▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>metrics/l0</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▂▁▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁▇██</td></tr><tr><td>sparsity/below_1e-6</td><td>▁██▅</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▃▁▁▁▁█▁▁▁▁▃▁▁▃▁▁▁▁▃▃▃▁▁▃▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▂▂▃▅▃▃▃▆█▄▄▄▅▆▄▄▅▆█▅▅▅▅▆▅▅▆▆█▆▇▆▅▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>0.2</td></tr><tr><td>details/current_learning_rate</td><td>0.0003</td></tr><tr><td>details/n_training_tokens</td><td>99993600</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.0</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.00189</td></tr><tr><td>losses/l1_loss</td><td>3.86355</td></tr><tr><td>losses/mse_loss</td><td>0.12071</td></tr><tr><td>losses/overall_loss</td><td>0.89531</td></tr><tr><td>metrics/explained_variance</td><td>0.97582</td></tr><tr><td>metrics/explained_variance_std</td><td>0.02435</td></tr><tr><td>metrics/l0</td><td>12.69821</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-2.80084</td></tr><tr><td>sparsity/below_1e-5</td><td>48</td></tr><tr><td>sparsity/below_1e-6</td><td>12</td></tr><tr><td>sparsity/dead_features</td><td>0</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>89.12109</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">256-L1-0.2-LR-0.0003-Tokens-1.000e+08</strong> at: <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/wzwdcw5r' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/wzwdcw5r</a><br/> View project at: <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a><br/>Synced 5 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240711_203830-wzwdcw5r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sae_utils import train_sae\n",
    "\n",
    "#I need to be able to tell the SAE to ignore certain tokens during training.\n",
    "sae, store = train_sae(ll_model, sae_lens_cfg, dataset)#, ignore_tokens=[])#2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a034e274-5923-4936-af0e-5613db407885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12938/3317634938.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t.tensor(dataset['tokens']).int(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa68ef470534b259422701031a605cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/381 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens torch.Size([97472, 42])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4093824, 9)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sae_utils import make_token_df\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "n_activations_sum = t.zeros(sae.cfg.d_sae).to(sae.device)\n",
    "input_tokens_list = []\n",
    "learned_activations = []\n",
    "extras_list = []\n",
    "extra_hook = 'elevation_hook'\n",
    "extra_name = 'elevation'\n",
    "\n",
    "t_dataset = TensorDataset(\n",
    "    t.tensor(dataset['tokens']).int(), \n",
    "    t.tensor(dataset['labels']).float()\n",
    ")\n",
    "dataloader  = DataLoader(t_dataset, batch_size=256, shuffle = False)\n",
    "\n",
    "#go through the training dataset and get max activations for each feature\n",
    "total_inputs = 0\n",
    "for batch in tqdm(dataloader):\n",
    "    tokens, labels = batch\n",
    "    total_inputs += tokens.numel()\n",
    "    logits, cache = ll_model.run_with_cache(tokens)\n",
    "    sae_in = cache[sae.cfg.hook_name]\n",
    "    if sae.cfg.hook_head_index is not None:\n",
    "        sae_in = sae_in[:,:,sae.cfg.hook_head_index,:] #I think this is how attn head indexing works...\n",
    "    activations = sae.encode(sae_in)\n",
    "    # print(activations.shape, labels.shape, tokens.shape, tokens.numel())\n",
    "    activations[t.isin(tokens.int(), t.Tensor([2, 3]).int())] = 0\n",
    "\n",
    "    # For sparsity calculation\n",
    "    n_new_activations = (activations > 0).sum(dim=(0,1)) #sum over batch and ctx\n",
    "    n_activations_sum = n_activations_sum + n_new_activations\n",
    "\n",
    "    # Save tokens and activations\n",
    "    input_tokens_list.append(tokens.cpu())\n",
    "    learned_activations.append(activations.to(t.float16).cpu().reshape(-1, sae.cfg.d_sae))\n",
    "\n",
    "    #HL output\n",
    "    hl_output, hl_cache = balance_checker.run_with_cache(tokens)\n",
    "    extra = hl_cache[extra_hook]\n",
    "    extras_list.append(extra.cpu())\n",
    "\n",
    "    # if total_inputs > 100_000:\n",
    "    #     break\n",
    "sparsity = n_activations_sum / total_inputs\n",
    "tokens = t.cat(input_tokens_list).to(int)\n",
    "extras = t.cat(extras_list).to(int)\n",
    "token_df = make_token_df(ll_model, tokens, len_prefix=ll_model.cfg.n_ctx, \n",
    "                         extra_token_labels={extra_name : extras})\n",
    "learned_activations = t.cat(learned_activations).to(t.float16)\n",
    "token_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ecfb13a-0839-435e-9bfc-24e940af966a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a3d2ea70f840bca8c98028048eec16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Feature:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2334e6ed4947446bae62826bd1a91849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformer_lens import utils\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def update_dataframe(feature_id):\n",
    "    token_df[\"activation\"] = utils.to_numpy(learned_activations[:,feature_id])\n",
    "    df = token_df[['str_tokens','prefix', 'suffix',  'context', 'activation', 'elevation']]\n",
    "    df = df.sort_values(\"activation\", ascending=False).head(100)\n",
    "    # display(df[df['activation'] > 0].style.background_gradient(\"coolwarm\"))\n",
    "    unique = df[['str_tokens', 'prefix', 'activation', 'elevation']].drop_duplicates()\n",
    "    display(unique[unique['activation'] > 0].head(100).style.background_gradient(\"coolwarm\"))\n",
    "\n",
    "# Define the dropdown menu for 'feat'\n",
    "feat_dropdown = widgets.Dropdown(\n",
    "    options=range(sae.cfg.d_sae),\n",
    "    value=0,\n",
    "    description='Feature:',\n",
    ")\n",
    "\n",
    "# Create an interactive output widget\n",
    "output = widgets.interactive_output(\n",
    "    update_dataframe, \n",
    "    {\n",
    "        'feature_id': feat_dropdown,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the dropdown menu and output\n",
    "display(feat_dropdown, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92cc1002-48b6-4b8a-b01c-0b8dd23d9cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.1\n"
     ]
    }
   ],
   "source": [
    "import sae_lens\n",
    "print(sae_lens.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd529f94-c986-44c1-a023-85f2096b13d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SAELens -- top-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a1643ea-ffec-44d1-909c-f6a48d37b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_fn topk\n",
      "activation_fn_kwargs {'k': 4}\n",
      "mse_loss_normalization None\n",
      "d_in 64\n",
      "wandb_project benchmark_saes\n",
      "Run name: 256-L1-0.1-LR-0.0003-Tokens-1.000e+08\n",
      "n_tokens_per_buffer (millions): 0.02688\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.00064\n",
      "Total training steps: 9300\n",
      "Total wandb updates: 930\n",
      "n_tokens_per_feature_sampling_window (millions): 903.168\n",
      "n_tokens_per_dead_feature_window (millions): 451.584\n",
      "We will reset the sparsity calculation 4 times.\n",
      "Number tokens in sparsity calculation window: 2.15e+07\n",
      "Using Ghost Grads.\n"
     ]
    }
   ],
   "source": [
    "from sae_utils import make_topk_sae_lens_config\n",
    "sae_lens_cfg = make_topk_sae_lens_config(\n",
    "    model=ll_model, \n",
    "    hook_name=\"blocks.0.mlp.hook_post\", \n",
    "    hook_layer=0, \n",
    "    k=4, #choose smallest value that achieves good mse loss.\n",
    "    context_size=ll_model.cfg.n_ctx,\n",
    "    d_in=ll_model.cfg.d_mlp,\n",
    "    device = 'cuda',\n",
    "    checkpoint_path = f\"$HOME/persistent-storage/tracr_saes/parens_sae_checkpoints\",\n",
    "    wandb_project =  \"benchmark_saes\",\n",
    "    training_tokens = 100_000_000,\n",
    "    batch_size = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fa44881-eeb0-4bdf-b692-4bd977c9b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the training dataset contains fewer samples (97472) than the number of samples required by your training configuration (100000000). This will result in multiple training epochs and some samples being used more than once.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wqc1tcgn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.273 MB of 0.273 MB uploaded (0.002 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/current_learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>█▆▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>▁▄▇██████████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>losses/mse_loss</td><td>█▆▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>█▆▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/explained_variance</td><td>▁▃▆▇▇▇▇▇▇███████████████████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>█▆▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l0</td><td>███████████████████████████████████▅▁▄█▅</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>▁█</td></tr><tr><td>sparsity/below_1e-5</td><td>█▁</td></tr><tr><td>sparsity/below_1e-6</td><td>█▁</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▅▃▁▁▁▃▁▁▁▁▁</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▂▄▅▆▇▇███▂▂▃▃▃▃▄▄▄▃▃▃▄▄▄▄▄▄▄▃▃▂▂▂▃▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>0.1</td></tr><tr><td>details/current_learning_rate</td><td>0.0003</td></tr><tr><td>details/n_training_tokens</td><td>45696000</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.0</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.0126</td></tr><tr><td>losses/l1_loss</td><td>8.73607</td></tr><tr><td>losses/mse_loss</td><td>0.8065</td></tr><tr><td>losses/overall_loss</td><td>1.6927</td></tr><tr><td>metrics/explained_variance</td><td>0.92588</td></tr><tr><td>metrics/explained_variance_std</td><td>0.06244</td></tr><tr><td>metrics/l0</td><td>4.0</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-4.18563</td></tr><tr><td>sparsity/below_1e-5</td><td>76</td></tr><tr><td>sparsity/below_1e-6</td><td>29</td></tr><tr><td>sparsity/dead_features</td><td>0</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>183.13281</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">256-topk-4-LR-0.0003-Tokens-1.000e+08</strong> at: <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/wqc1tcgn' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/wqc1tcgn</a><br/> View project at: <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a><br/>Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240711_220643-wqc1tcgn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wqc1tcgn). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3a67e8c4e74c67bf87b2a607dc274f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114499510990248, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/quick-experiments/wandb/run-20240711_221648-mh01kdsc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evanhanders/benchmark_saes/runs/mh01kdsc' target=\"_blank\">256-topk-4-LR-0.0003-Tokens-1.000e+08</a></strong> to <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/mh01kdsc' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/mh01kdsc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training SAE:   0%|                                                                         | 0/100000000 [00:00<?, ?it/s]\u001b[A\u001b[A/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:264: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yield torch.tensor(\n",
      "/opt/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2265: UserWarning: Run (25elroub) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "1200| MSE Loss 1.594 | L1 0.940:  13%|████▍                             | 12902400/100000000 [18:41<2:06:08, 11507.49it/s]\n",
      "\n",
      "\n",
      "100| MSE Loss 13.181 | L1 0.473:   0%|                                                      | 0/100000000 [00:11<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100| MSE Loss 13.181 | L1 0.473:   1%|▍                                    | 1075200/100000000 [00:11<18:06, 91024.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "100| MSE Loss 13.181 | L1 0.473:   1%|▍                                    | 1075200/100000000 [00:22<18:06, 91024.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "200| MSE Loss 6.829 | L1 0.650:   1%|▍                                     | 1075200/100000000 [00:23<18:06, 91024.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "200| MSE Loss 6.829 | L1 0.650:   2%|▊                                     | 2150400/100000000 [00:23<18:06, 90018.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "300| MSE Loss 4.432 | L1 0.649:   2%|▊                                     | 2150400/100000000 [00:35<18:06, 90018.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "300| MSE Loss 4.432 | L1 0.649:   3%|█▏                                    | 3225600/100000000 [00:35<18:00, 89562.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "300| MSE Loss 4.432 | L1 0.649:   3%|█▏                                    | 3225600/100000000 [00:46<18:00, 89562.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "400| MSE Loss 3.290 | L1 0.601:   3%|█▏                                    | 3225600/100000000 [00:48<18:00, 89562.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "400| MSE Loss 3.290 | L1 0.601:   4%|█▋                                    | 4300800/100000000 [00:48<18:05, 88198.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "500| MSE Loss 2.650 | L1 0.578:   4%|█▋                                    | 4300800/100000000 [01:01<18:05, 88198.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "500| MSE Loss 2.650 | L1 0.578:   5%|██                                    | 5376000/100000000 [01:01<18:16, 86288.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "500| MSE Loss 2.650 | L1 0.578:   5%|██                                    | 5376000/100000000 [01:12<18:16, 86288.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "600| MSE Loss 2.199 | L1 0.563:   5%|██                                    | 5376000/100000000 [01:12<18:16, 86288.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "600| MSE Loss 2.199 | L1 0.563:   6%|██▍                                   | 6451200/100000000 [01:12<17:32, 88884.25it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "700| MSE Loss 1.961 | L1 0.562:   6%|██▍                                   | 6451200/100000000 [01:25<17:32, 88884.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "700| MSE Loss 1.961 | L1 0.562:   8%|██▊                                   | 7526400/100000000 [01:25<17:32, 87889.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "700| MSE Loss 1.961 | L1 0.562:   8%|██▊                                   | 7526400/100000000 [01:37<17:32, 87889.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "800| MSE Loss 1.781 | L1 0.554:   8%|██▊                                   | 7526400/100000000 [01:37<17:32, 87889.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "800| MSE Loss 1.781 | L1 0.554:   9%|███▎                                  | 8601600/100000000 [01:37<17:23, 87551.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "900| MSE Loss 1.595 | L1 0.551:   9%|███▎                                  | 8601600/100000000 [01:50<17:23, 87551.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "900| MSE Loss 1.595 | L1 0.551:  10%|███▋                                  | 9676800/100000000 [01:50<17:32, 85839.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "900| MSE Loss 1.595 | L1 0.551:  10%|███▋                                  | 9676800/100000000 [02:02<17:32, 85839.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "1000| MSE Loss 1.508 | L1 0.548:  10%|███▌                                 | 9676800/100000000 [02:04<17:32, 85839.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "1000| MSE Loss 1.508 | L1 0.548:  11%|███▊                                | 10752000/100000000 [02:04<17:48, 83536.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1000| MSE Loss 1.508 | L1 0.548:  11%|███▊                                | 10752000/100000000 [02:17<17:48, 83536.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1100| MSE Loss 1.436 | L1 0.545:  11%|███▊                                | 10752000/100000000 [02:17<17:48, 83536.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1100| MSE Loss 1.436 | L1 0.545:  12%|████▎                               | 11827200/100000000 [02:17<17:48, 82523.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "1200| MSE Loss 1.305 | L1 0.537:  12%|████▎                               | 11827200/100000000 [02:31<17:48, 82523.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "1200| MSE Loss 1.305 | L1 0.537:  13%|████▋                               | 12902400/100000000 [02:31<17:53, 81164.34it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1200| MSE Loss 1.305 | L1 0.537:  13%|████▋                               | 12902400/100000000 [02:42<17:53, 81164.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "1300| MSE Loss 1.271 | L1 0.536:  13%|████▋                               | 12902400/100000000 [02:45<17:53, 81164.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "1300| MSE Loss 1.271 | L1 0.536:  14%|█████                               | 13977600/100000000 [02:45<17:54, 80071.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1300| MSE Loss 1.271 | L1 0.536:  14%|█████                               | 13977600/100000000 [02:57<17:54, 80071.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1400| MSE Loss 1.173 | L1 0.531:  14%|█████                               | 13977600/100000000 [02:57<17:54, 80071.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1400| MSE Loss 1.173 | L1 0.531:  15%|█████▍                              | 15052800/100000000 [02:57<17:19, 81751.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "1500| MSE Loss 1.117 | L1 0.520:  15%|█████▍                              | 15052800/100000000 [03:09<17:19, 81751.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "1500| MSE Loss 1.117 | L1 0.520:  16%|█████▊                              | 16128000/100000000 [03:09<16:39, 83910.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "1600| MSE Loss 1.074 | L1 0.523:  16%|█████▊                              | 16128000/100000000 [03:22<16:39, 83910.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "1600| MSE Loss 1.074 | L1 0.523:  17%|██████▏                             | 17203200/100000000 [03:22<16:28, 83782.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "1600| MSE Loss 1.074 | L1 0.523:  17%|██████▏                             | 17203200/100000000 [03:32<16:28, 83782.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "1700| MSE Loss 1.041 | L1 0.521:  17%|██████▏                             | 17203200/100000000 [03:35<16:28, 83782.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "1700| MSE Loss 1.041 | L1 0.521:  18%|██████▌                             | 18278400/100000000 [03:35<16:19, 83428.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "1800| MSE Loss 0.988 | L1 0.515:  18%|██████▌                             | 18278400/100000000 [03:47<16:19, 83428.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "1800| MSE Loss 0.988 | L1 0.515:  19%|██████▉                             | 19353600/100000000 [03:47<15:44, 85368.89it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n",
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/lob29g44/20009472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1800| MSE Loss 0.988 | L1 0.515:  19%|██████▉                             | 19353600/100000000 [03:57<15:44, 85368.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "1900| MSE Loss 0.959 | L1 0.513:  19%|██████▉                             | 19353600/100000000 [04:00<15:44, 85368.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "1900| MSE Loss 0.959 | L1 0.513:  20%|███████▎                            | 20428800/100000000 [04:00<15:33, 85271.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "2000| MSE Loss 0.894 | L1 0.508:  20%|███████▎                            | 20428800/100000000 [04:12<15:33, 85271.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "2000| MSE Loss 0.894 | L1 0.508:  22%|███████▋                            | 21504000/100000000 [04:12<15:06, 86605.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "2000| MSE Loss 0.894 | L1 0.508:  22%|███████▋                            | 21504000/100000000 [04:22<15:06, 86605.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "2100| MSE Loss 0.900 | L1 0.505:  22%|███████▋                            | 21504000/100000000 [04:24<15:06, 86605.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "2100| MSE Loss 0.900 | L1 0.505:  23%|████████▏                           | 22579200/100000000 [04:24<14:52, 86775.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "2200| MSE Loss 0.902 | L1 0.505:  23%|████████▏                           | 22579200/100000000 [04:36<14:52, 86775.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "2200| MSE Loss 0.902 | L1 0.505:  24%|████████▌                           | 23654400/100000000 [04:36<14:29, 87774.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "2200| MSE Loss 0.902 | L1 0.505:  24%|████████▌                           | 23654400/100000000 [04:47<14:29, 87774.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "2300| MSE Loss 0.875 | L1 0.497:  24%|████████▌                           | 23654400/100000000 [04:48<14:29, 87774.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "2300| MSE Loss 0.875 | L1 0.497:  25%|████████▉                           | 24729600/100000000 [04:48<14:14, 88085.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "2400| MSE Loss 0.822 | L1 0.492:  25%|████████▉                           | 24729600/100000000 [05:00<14:14, 88085.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "2400| MSE Loss 0.822 | L1 0.492:  26%|█████████▎                          | 25804800/100000000 [05:00<13:48, 89606.12it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2500| MSE Loss 0.823 | L1 0.486:  26%|█████████▎                          | 25804800/100000000 [05:12<13:48, 89606.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "2500| MSE Loss 0.823 | L1 0.486:  27%|█████████▋                          | 26880000/100000000 [05:12<13:35, 89669.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "2500| MSE Loss 0.823 | L1 0.486:  27%|█████████▋                          | 26880000/100000000 [05:22<13:35, 89669.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "2600| MSE Loss 0.827 | L1 0.489:  27%|█████████▋                          | 26880000/100000000 [05:24<13:35, 89669.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "2600| MSE Loss 0.827 | L1 0.489:  28%|██████████                          | 27955200/100000000 [05:24<13:24, 89519.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "2700| MSE Loss 0.787 | L1 0.483:  28%|██████████                          | 27955200/100000000 [05:37<13:24, 89519.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "2700| MSE Loss 0.787 | L1 0.483:  29%|██████████▍                         | 29030400/100000000 [05:37<13:36, 86930.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "2700| MSE Loss 0.787 | L1 0.483:  29%|██████████▍                         | 29030400/100000000 [05:47<13:36, 86930.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "2800| MSE Loss 0.758 | L1 0.477:  29%|██████████▍                         | 29030400/100000000 [05:50<13:36, 86930.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "2800| MSE Loss 0.758 | L1 0.477:  30%|██████████▊                         | 30105600/100000000 [05:50<13:45, 84631.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "2800| MSE Loss 0.758 | L1 0.477:  30%|██████████▊                         | 30105600/100000000 [06:02<13:45, 84631.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "2900| MSE Loss 0.768 | L1 0.481:  30%|██████████▊                         | 30105600/100000000 [06:04<13:45, 84631.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "2900| MSE Loss 0.768 | L1 0.481:  31%|███████████▏                        | 31180800/100000000 [06:04<13:42, 83709.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "3000| MSE Loss 0.753 | L1 0.477:  31%|███████████▏                        | 31180800/100000000 [06:17<13:42, 83709.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "3000| MSE Loss 0.753 | L1 0.477:  32%|███████████▌                        | 32256000/100000000 [06:17<13:46, 81973.37it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3000| MSE Loss 0.753 | L1 0.477:  32%|███████████▌                        | 32256000/100000000 [06:28<13:46, 81973.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "3100| MSE Loss 0.755 | L1 0.475:  32%|███████████▌                        | 32256000/100000000 [06:31<13:46, 81973.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "3100| MSE Loss 0.755 | L1 0.475:  33%|███████████▉                        | 33331200/100000000 [06:31<13:46, 80690.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "3100| MSE Loss 0.755 | L1 0.475:  33%|███████████▉                        | 33331200/100000000 [06:42<13:46, 80690.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "3200| MSE Loss 0.719 | L1 0.466:  33%|███████████▉                        | 33331200/100000000 [06:44<13:46, 80690.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "3200| MSE Loss 0.719 | L1 0.466:  34%|████████████▍                       | 34406400/100000000 [06:44<13:31, 80820.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "3300| MSE Loss 0.727 | L1 0.469:  34%|████████████▍                       | 34406400/100000000 [06:57<13:31, 80820.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "3300| MSE Loss 0.727 | L1 0.469:  35%|████████████▊                       | 35481600/100000000 [06:57<13:09, 81711.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "3300| MSE Loss 0.727 | L1 0.469:  35%|████████████▊                       | 35481600/100000000 [07:08<13:09, 81711.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "3400| MSE Loss 0.709 | L1 0.473:  35%|████████████▊                       | 35481600/100000000 [07:09<13:09, 81711.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "3400| MSE Loss 0.709 | L1 0.473:  37%|█████████████▏                      | 36556800/100000000 [07:09<12:38, 83636.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "3500| MSE Loss 0.694 | L1 0.469:  37%|█████████████▏                      | 36556800/100000000 [07:22<12:38, 83636.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "3500| MSE Loss 0.694 | L1 0.469:  38%|█████████████▌                      | 37632000/100000000 [07:22<12:21, 84149.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "3500| MSE Loss 0.694 | L1 0.469:  38%|█████████████▌                      | 37632000/100000000 [07:32<12:21, 84149.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "3600| MSE Loss 0.707 | L1 0.464:  38%|█████████████▌                      | 37632000/100000000 [07:34<12:21, 84149.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "3600| MSE Loss 0.707 | L1 0.464:  39%|█████████████▉                      | 38707200/100000000 [07:34<11:50, 86307.83it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3700| MSE Loss 0.699 | L1 0.464:  39%|█████████████▉                      | 38707200/100000000 [07:45<11:50, 86307.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "3700| MSE Loss 0.699 | L1 0.464:  40%|██████████████▎                     | 39782400/100000000 [07:45<11:26, 87701.29it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/lob29g44/40008192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3800| MSE Loss 0.665 | L1 0.459:  40%|██████████████▎                     | 39782400/100000000 [07:57<11:26, 87701.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "3800| MSE Loss 0.665 | L1 0.459:  41%|██████████████▋                     | 40857600/100000000 [07:57<11:10, 88170.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "3800| MSE Loss 0.665 | L1 0.459:  41%|██████████████▋                     | 40857600/100000000 [08:08<11:10, 88170.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "3900| MSE Loss 0.660 | L1 0.451:  41%|██████████████▋                     | 40857600/100000000 [08:09<11:10, 88170.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "3900| MSE Loss 0.660 | L1 0.451:  42%|███████████████                     | 41932800/100000000 [08:09<10:53, 88913.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "4000| MSE Loss 0.660 | L1 0.458:  42%|███████████████                     | 41932800/100000000 [08:21<10:53, 88913.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "4000| MSE Loss 0.660 | L1 0.458:  43%|███████████████▍                    | 43008000/100000000 [08:21<10:31, 90316.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "4100| MSE Loss 0.642 | L1 0.460:  43%|███████████████▍                    | 43008000/100000000 [08:32<10:31, 90316.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "4100| MSE Loss 0.642 | L1 0.460:  44%|███████████████▊                    | 44083200/100000000 [08:32<10:10, 91585.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "4100| MSE Loss 0.642 | L1 0.460:  44%|███████████████▊                    | 44083200/100000000 [08:43<10:10, 91585.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "4200| MSE Loss 0.643 | L1 0.456:  44%|███████████████▊                    | 44083200/100000000 [08:43<10:10, 91585.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "4200| MSE Loss 0.643 | L1 0.456:  45%|████████████████▎                   | 45158400/100000000 [08:43<09:46, 93546.74it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4300| MSE Loss 0.633 | L1 0.455:  45%|████████████████▎                   | 45158400/100000000 [08:54<09:46, 93546.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "4300| MSE Loss 0.633 | L1 0.455:  46%|████████████████▋                   | 46233600/100000000 [08:54<09:32, 93915.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "4400| MSE Loss 0.619 | L1 0.454:  46%|████████████████▋                   | 46233600/100000000 [09:05<09:32, 93915.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "4400| MSE Loss 0.619 | L1 0.454:  47%|█████████████████                   | 47308800/100000000 [09:05<09:11, 95511.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "4500| MSE Loss 0.641 | L1 0.457:  47%|█████████████████                   | 47308800/100000000 [09:17<09:11, 95511.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "4500| MSE Loss 0.641 | L1 0.457:  48%|█████████████████▍                  | 48384000/100000000 [09:17<09:07, 94255.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "4500| MSE Loss 0.641 | L1 0.457:  48%|█████████████████▍                  | 48384000/100000000 [09:28<09:07, 94255.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "4600| MSE Loss 0.607 | L1 0.452:  48%|█████████████████▍                  | 48384000/100000000 [09:29<09:07, 94255.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "4600| MSE Loss 0.607 | L1 0.452:  49%|█████████████████▊                  | 49459200/100000000 [09:29<09:11, 91690.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "4700| MSE Loss 0.573 | L1 0.454:  49%|█████████████████▊                  | 49459200/100000000 [09:42<09:11, 91690.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "4700| MSE Loss 0.573 | L1 0.454:  51%|██████████████████▏                 | 50534400/100000000 [09:42<09:17, 88772.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "4700| MSE Loss 0.573 | L1 0.454:  51%|██████████████████▏                 | 50534400/100000000 [09:53<09:17, 88772.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "4800| MSE Loss 0.598 | L1 0.451:  51%|██████████████████▏                 | 50534400/100000000 [09:56<09:17, 88772.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "4800| MSE Loss 0.598 | L1 0.451:  52%|██████████████████▌                 | 51609600/100000000 [09:56<09:18, 86650.86it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4800| MSE Loss 0.598 | L1 0.451:  52%|██████████████████▌                 | 51609600/100000000 [10:08<09:18, 86650.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "4900| MSE Loss 0.563 | L1 0.445:  52%|██████████████████▌                 | 51609600/100000000 [10:09<09:18, 86650.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "4900| MSE Loss 0.563 | L1 0.445:  53%|██████████████████▉                 | 52684800/100000000 [10:09<09:14, 85325.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "5000| MSE Loss 0.553 | L1 0.450:  53%|██████████████████▉                 | 52684800/100000000 [10:21<09:14, 85325.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "5000| MSE Loss 0.553 | L1 0.450:  54%|███████████████████▎                | 53760000/100000000 [10:21<09:03, 85045.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "5000| MSE Loss 0.553 | L1 0.450:  54%|███████████████████▎                | 53760000/100000000 [10:33<09:03, 85045.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "5100| MSE Loss 0.552 | L1 0.447:  54%|███████████████████▎                | 53760000/100000000 [10:34<09:03, 85045.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "5100| MSE Loss 0.552 | L1 0.447:  55%|███████████████████▋                | 54835200/100000000 [10:34<08:54, 84527.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "5200| MSE Loss 0.545 | L1 0.452:  55%|███████████████████▋                | 54835200/100000000 [10:47<08:54, 84527.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "5200| MSE Loss 0.545 | L1 0.452:  56%|████████████████████▏               | 55910400/100000000 [10:47<08:43, 84288.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "5200| MSE Loss 0.545 | L1 0.452:  56%|████████████████████▏               | 55910400/100000000 [10:58<08:43, 84288.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "5300| MSE Loss 0.530 | L1 0.445:  56%|████████████████████▏               | 55910400/100000000 [11:00<08:43, 84288.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "5300| MSE Loss 0.530 | L1 0.445:  57%|████████████████████▌               | 56985600/100000000 [11:00<08:33, 83775.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "5400| MSE Loss 0.570 | L1 0.452:  57%|████████████████████▌               | 56985600/100000000 [11:11<08:33, 83775.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "5400| MSE Loss 0.570 | L1 0.452:  58%|████████████████████▉               | 58060800/100000000 [11:11<07:55, 88238.90it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "5500| MSE Loss 0.541 | L1 0.446:  58%|████████████████████▉               | 58060800/100000000 [11:22<07:55, 88238.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "5500| MSE Loss 0.541 | L1 0.446:  59%|█████████████████████▎              | 59136000/100000000 [11:22<07:30, 90785.33it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/lob29g44/60006912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "5600| MSE Loss 0.509 | L1 0.447:  59%|█████████████████████▎              | 59136000/100000000 [11:33<07:30, 90785.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "5600| MSE Loss 0.509 | L1 0.447:  60%|█████████████████████▋              | 60211200/100000000 [11:33<07:12, 92047.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "5600| MSE Loss 0.509 | L1 0.447:  60%|█████████████████████▋              | 60211200/100000000 [11:44<07:12, 92047.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "5700| MSE Loss 0.541 | L1 0.445:  60%|█████████████████████▋              | 60211200/100000000 [11:44<07:12, 92047.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "5700| MSE Loss 0.541 | L1 0.445:  61%|██████████████████████              | 61286400/100000000 [11:44<06:55, 93080.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "5800| MSE Loss 0.522 | L1 0.443:  61%|██████████████████████              | 61286400/100000000 [11:56<06:55, 93080.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "5800| MSE Loss 0.522 | L1 0.443:  62%|██████████████████████▍             | 62361600/100000000 [11:56<06:42, 93502.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "5900| MSE Loss 0.505 | L1 0.442:  62%|██████████████████████▍             | 62361600/100000000 [12:07<06:42, 93502.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "5900| MSE Loss 0.505 | L1 0.442:  63%|██████████████████████▊             | 63436800/100000000 [12:07<06:27, 94284.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "6000| MSE Loss 0.498 | L1 0.438:  63%|██████████████████████▊             | 63436800/100000000 [12:18<06:27, 94284.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "6000| MSE Loss 0.498 | L1 0.438:  65%|███████████████████████▏            | 64512000/100000000 [12:18<06:12, 95200.79it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6000| MSE Loss 0.498 | L1 0.438:  65%|███████████████████████▏            | 64512000/100000000 [12:28<06:12, 95200.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "6100| MSE Loss 0.505 | L1 0.443:  65%|███████████████████████▏            | 64512000/100000000 [12:29<06:12, 95200.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "6100| MSE Loss 0.505 | L1 0.443:  66%|███████████████████████▌            | 65587200/100000000 [12:29<06:00, 95391.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "6200| MSE Loss 0.514 | L1 0.445:  66%|███████████████████████▌            | 65587200/100000000 [12:40<06:00, 95391.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "6200| MSE Loss 0.514 | L1 0.445:  67%|███████████████████████▉            | 66662400/100000000 [12:40<05:47, 95867.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "6300| MSE Loss 0.494 | L1 0.446:  67%|███████████████████████▉            | 66662400/100000000 [12:51<05:47, 95867.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "6300| MSE Loss 0.494 | L1 0.446:  68%|████████████████████████▍           | 67737600/100000000 [12:51<05:33, 96645.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "6400| MSE Loss 0.496 | L1 0.444:  68%|████████████████████████▍           | 67737600/100000000 [13:03<05:33, 96645.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "6400| MSE Loss 0.496 | L1 0.444:  69%|████████████████████████▊           | 68812800/100000000 [13:03<05:28, 95000.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "6400| MSE Loss 0.496 | L1 0.444:  69%|████████████████████████▊           | 68812800/100000000 [13:14<05:28, 95000.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "6500| MSE Loss 0.489 | L1 0.440:  69%|████████████████████████▊           | 68812800/100000000 [13:15<05:28, 95000.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "6500| MSE Loss 0.489 | L1 0.440:  70%|█████████████████████████▏          | 69888000/100000000 [13:15<05:23, 93062.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "6600| MSE Loss 0.494 | L1 0.438:  70%|█████████████████████████▏          | 69888000/100000000 [13:27<05:23, 93062.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "6600| MSE Loss 0.494 | L1 0.438:  71%|█████████████████████████▌          | 70963200/100000000 [13:27<05:13, 92541.03it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6600| MSE Loss 0.494 | L1 0.438:  71%|█████████████████████████▌          | 70963200/100000000 [13:38<05:13, 92541.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "6700| MSE Loss 0.476 | L1 0.435:  71%|█████████████████████████▌          | 70963200/100000000 [13:40<05:13, 92541.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "6700| MSE Loss 0.476 | L1 0.435:  72%|█████████████████████████▉          | 72038400/100000000 [13:40<05:12, 89582.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "6800| MSE Loss 0.473 | L1 0.434:  72%|█████████████████████████▉          | 72038400/100000000 [13:51<05:12, 89582.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "6800| MSE Loss 0.473 | L1 0.434:  73%|██████████████████████████▎         | 73113600/100000000 [13:51<04:58, 90112.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "6900| MSE Loss 0.476 | L1 0.439:  73%|██████████████████████████▎         | 73113600/100000000 [14:03<04:58, 90112.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "6900| MSE Loss 0.476 | L1 0.439:  74%|██████████████████████████▋         | 74188800/100000000 [14:03<04:45, 90532.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "6900| MSE Loss 0.476 | L1 0.439:  74%|██████████████████████████▋         | 74188800/100000000 [14:14<04:45, 90532.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "7000| MSE Loss 0.483 | L1 0.438:  74%|██████████████████████████▋         | 74188800/100000000 [14:15<04:45, 90532.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "7000| MSE Loss 0.483 | L1 0.438:  75%|███████████████████████████         | 75264000/100000000 [14:15<04:31, 91014.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "7100| MSE Loss 0.454 | L1 0.437:  75%|███████████████████████████         | 75264000/100000000 [14:27<04:31, 91014.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "7100| MSE Loss 0.454 | L1 0.437:  76%|███████████████████████████▍        | 76339200/100000000 [14:27<04:19, 91266.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "7200| MSE Loss 0.469 | L1 0.433:  76%|███████████████████████████▍        | 76339200/100000000 [14:38<04:19, 91266.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "7200| MSE Loss 0.469 | L1 0.433:  77%|███████████████████████████▊        | 77414400/100000000 [14:38<04:06, 91638.37it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "7200| MSE Loss 0.469 | L1 0.433:  77%|███████████████████████████▊        | 77414400/100000000 [14:49<04:06, 91638.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "7300| MSE Loss 0.484 | L1 0.442:  77%|███████████████████████████▊        | 77414400/100000000 [14:49<04:06, 91638.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "7300| MSE Loss 0.484 | L1 0.442:  78%|████████████████████████████▎       | 78489600/100000000 [14:49<03:51, 92914.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "7400| MSE Loss 0.455 | L1 0.434:  78%|████████████████████████████▎       | 78489600/100000000 [15:00<03:51, 92914.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "7400| MSE Loss 0.455 | L1 0.434:  80%|████████████████████████████▋       | 79564800/100000000 [15:00<03:32, 96316.98it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/lob29g44/80005632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "7500| MSE Loss 0.453 | L1 0.431:  80%|████████████████████████████▋       | 79564800/100000000 [15:11<03:32, 96316.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "7500| MSE Loss 0.453 | L1 0.431:  81%|█████████████████████████████       | 80640000/100000000 [15:11<03:22, 95834.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "7600| MSE Loss 0.467 | L1 0.436:  81%|█████████████████████████████       | 80640000/100000000 [15:22<03:22, 95834.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "7600| MSE Loss 0.467 | L1 0.436:  82%|█████████████████████████████▍      | 81715200/100000000 [15:22<03:08, 96930.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "7700| MSE Loss 0.445 | L1 0.434:  82%|█████████████████████████████▍      | 81715200/100000000 [15:33<03:08, 96930.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "7700| MSE Loss 0.445 | L1 0.434:  83%|█████████████████████████████▊      | 82790400/100000000 [15:33<02:57, 96825.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "7800| MSE Loss 0.456 | L1 0.438:  83%|█████████████████████████████▊      | 82790400/100000000 [15:44<02:57, 96825.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "7800| MSE Loss 0.456 | L1 0.438:  84%|██████████████████████████████▏     | 83865600/100000000 [15:44<02:45, 97331.33it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "7800| MSE Loss 0.456 | L1 0.438:  84%|██████████████████████████████▏     | 83865600/100000000 [15:54<02:45, 97331.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "7900| MSE Loss 0.456 | L1 0.440:  84%|██████████████████████████████▏     | 83865600/100000000 [15:55<02:45, 97331.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "7900| MSE Loss 0.456 | L1 0.440:  85%|██████████████████████████████▌     | 84940800/100000000 [15:55<02:35, 97121.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "8000| MSE Loss 0.449 | L1 0.440:  85%|██████████████████████████████▌     | 84940800/100000000 [16:06<02:35, 97121.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "8000| MSE Loss 0.449 | L1 0.440:  86%|██████████████████████████████▉     | 86016000/100000000 [16:06<02:23, 97583.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "8100| MSE Loss 0.431 | L1 0.431:  86%|██████████████████████████████▉     | 86016000/100000000 [16:16<02:23, 97583.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "8100| MSE Loss 0.431 | L1 0.431:  87%|███████████████████████████████▎    | 87091200/100000000 [16:16<02:10, 98836.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "8200| MSE Loss 0.424 | L1 0.432:  87%|███████████████████████████████▎    | 87091200/100000000 [16:28<02:10, 98836.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "8200| MSE Loss 0.424 | L1 0.432:  88%|███████████████████████████████▋    | 88166400/100000000 [16:28<02:00, 97995.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "8300| MSE Loss 0.448 | L1 0.434:  88%|███████████████████████████████▋    | 88166400/100000000 [16:39<02:00, 97995.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "8300| MSE Loss 0.448 | L1 0.434:  89%|████████████████████████████████▏   | 89241600/100000000 [16:39<01:50, 97428.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "8300| MSE Loss 0.448 | L1 0.434:  89%|████████████████████████████████▏   | 89241600/100000000 [16:49<01:50, 97428.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "8400| MSE Loss 0.431 | L1 0.434:  89%|████████████████████████████████▏   | 89241600/100000000 [16:51<01:50, 97428.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "8400| MSE Loss 0.431 | L1 0.434:  90%|████████████████████████████████▌   | 90316800/100000000 [16:51<01:43, 93839.07it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "8500| MSE Loss 0.419 | L1 0.434:  90%|████████████████████████████████▌   | 90316800/100000000 [17:04<01:43, 93839.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "8500| MSE Loss 0.419 | L1 0.434:  91%|████████████████████████████████▉   | 91392000/100000000 [17:04<01:34, 91352.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "8500| MSE Loss 0.419 | L1 0.434:  91%|████████████████████████████████▉   | 91392000/100000000 [17:15<01:34, 91352.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "8600| MSE Loss 0.398 | L1 0.427:  91%|████████████████████████████████▉   | 91392000/100000000 [17:16<01:34, 91352.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "8600| MSE Loss 0.398 | L1 0.427:  92%|█████████████████████████████████▎  | 92467200/100000000 [17:16<01:23, 90214.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "8700| MSE Loss 0.392 | L1 0.431:  92%|█████████████████████████████████▎  | 92467200/100000000 [17:28<01:23, 90214.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "8700| MSE Loss 0.392 | L1 0.431:  94%|█████████████████████████████████▋  | 93542400/100000000 [17:28<01:11, 90114.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "8700| MSE Loss 0.392 | L1 0.431:  94%|█████████████████████████████████▋  | 93542400/100000000 [17:39<01:11, 90114.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "8800| MSE Loss 0.420 | L1 0.432:  94%|█████████████████████████████████▋  | 93542400/100000000 [17:40<01:11, 90114.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "8800| MSE Loss 0.420 | L1 0.432:  95%|██████████████████████████████████  | 94617600/100000000 [17:40<00:59, 90747.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "8800| MSE Loss 0.420 | L1 0.432:  95%|██████████████████████████████████  | 94617600/100000000 [17:50<00:59, 90747.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "8900| MSE Loss 0.417 | L1 0.432:  95%|██████████████████████████████████  | 94617600/100000000 [17:52<00:59, 90747.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "8900| MSE Loss 0.417 | L1 0.432:  96%|██████████████████████████████████▍ | 95692800/100000000 [17:52<00:47, 90569.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "9000| MSE Loss 0.409 | L1 0.432:  96%|██████████████████████████████████▍ | 95692800/100000000 [18:04<00:47, 90569.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "9000| MSE Loss 0.409 | L1 0.432:  97%|██████████████████████████████████▊ | 96768000/100000000 [18:04<00:35, 90256.80it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "9000| MSE Loss 0.409 | L1 0.432:  97%|██████████████████████████████████▊ | 96768000/100000000 [18:15<00:35, 90256.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "9100| MSE Loss 0.404 | L1 0.427:  97%|██████████████████████████████████▊ | 96768000/100000000 [18:16<00:35, 90256.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "9100| MSE Loss 0.404 | L1 0.427:  98%|███████████████████████████████████▏| 97843200/100000000 [18:16<00:23, 89908.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "9200| MSE Loss 0.395 | L1 0.425:  98%|███████████████████████████████████▏| 97843200/100000000 [18:26<00:23, 89908.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "9200| MSE Loss 0.395 | L1 0.425:  99%|███████████████████████████████████▌| 98918400/100000000 [18:26<00:11, 92681.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "9300| MSE Loss 0.398 | L1 0.429:  99%|███████████████████████████████████▌| 98918400/100000000 [18:37<00:11, 92681.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "9300| MSE Loss 0.398 | L1 0.429: 100%|███████████████████████████████████▉| 99993600/100000000 [18:37<00:00, 93958.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/lob29g44/final_100004352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9300| MSE Loss 0.398 | L1 0.429: 100%|███████████████████████████████████▉| 99993600/100000000 [18:38<00:00, 89389.85it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181b3d44493443cebba8dba3e99b3529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.662 MB of 0.662 MB uploaded (0.009 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 1.3%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/current_learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>▁█▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/explained_variance</td><td>▁▆▇▇▇███████████████████████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>█▅▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l0</td><td>█████████████▆█▅▆█▆▄▆█▃▅▅▇▁▄▁▃▃▂▄▃▃▃▃▃▃▄</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>▁▄▇█</td></tr><tr><td>sparsity/below_1e-5</td><td>█▄▁▂</td></tr><tr><td>sparsity/below_1e-6</td><td>█▂▁▃</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▁▁▁▅▅▁▁▁▁▅▁▁▅▁▁█▁▁▁▁▁▁▅▁▁▁▅▁▁▁▁▁</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▅▅▆▆▄▅▅▇█▇▇▇▇█▆▆▅▆▇▆▆▆▆▆▅▅▄▄▄▄▅▅▅▅▆▅▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>0.1</td></tr><tr><td>details/current_learning_rate</td><td>0.0003</td></tr><tr><td>details/n_training_tokens</td><td>99993600</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.0</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.00622</td></tr><tr><td>losses/l1_loss</td><td>4.29483</td></tr><tr><td>losses/mse_loss</td><td>0.39798</td></tr><tr><td>losses/overall_loss</td><td>0.83368</td></tr><tr><td>metrics/explained_variance</td><td>0.96611</td></tr><tr><td>metrics/explained_variance_std</td><td>0.02908</td></tr><tr><td>metrics/l0</td><td>3.9189</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-3.88106</td></tr><tr><td>sparsity/below_1e-5</td><td>100</td></tr><tr><td>sparsity/below_1e-6</td><td>35</td></tr><tr><td>sparsity/dead_features</td><td>0</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>147.58594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">256-topk-4-LR-0.0003-Tokens-1.000e+08</strong> at: <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/mh01kdsc' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/mh01kdsc</a><br/> View project at: <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a><br/>Synced 5 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240711_221648-mh01kdsc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sae_utils import train_sae\n",
    "\n",
    "#I need to be able to tell the SAE to ignore certain tokens during training.\n",
    "sae, store = train_sae(ll_model, sae_lens_cfg, dataset.shuffle(seed=101))#, ignore_tokens=[])#2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb01f50-1ef9-4866-9a4e-581a7f56cce8",
   "metadata": {},
   "source": [
    "# SAELens -- gated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a37b51c0-f3e7-4d62-8aa8-580e15d589b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture gated\n",
      "use_ghost_grads False\n",
      "d_in 64\n",
      "wandb_project benchmark_saes\n",
      "Run name: 256-L1-0.2-LR-0.0003-Tokens-1.000e+08\n",
      "n_tokens_per_buffer (millions): 0.02688\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.00064\n",
      "Total training steps: 9300\n",
      "Total wandb updates: 930\n",
      "n_tokens_per_feature_sampling_window (millions): 903.168\n",
      "n_tokens_per_dead_feature_window (millions): 451.584\n",
      "We will reset the sparsity calculation 4 times.\n",
      "Number tokens in sparsity calculation window: 2.15e+07\n"
     ]
    }
   ],
   "source": [
    "from sae_utils import make_gated_sae_lens_config\n",
    "\n",
    "#seems a lot better than top-k in terms of L0 and MSE.\n",
    "sae_lens_cfg = make_gated_sae_lens_config(\n",
    "    model=ll_model, \n",
    "    hook_name=\"blocks.0.mlp.hook_post\", \n",
    "    hook_layer=0, \n",
    "    l1_coefficient=0.2,\n",
    "    l1_warm_up_steps = 0,\n",
    "    context_size=ll_model.cfg.n_ctx,\n",
    "    d_in=ll_model.cfg.d_mlp,\n",
    "    device = 'cuda',\n",
    "    checkpoint_path = f\"$HOME/persistent-storage/tracr_saes/parens_sae_checkpoints\",\n",
    "    wandb_project =  \"benchmark_saes\",\n",
    "    training_tokens = 100_000_000,\n",
    "    batch_size = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694da2b-25b0-4984-a9a1-05e1db025b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the training dataset contains fewer samples (97472) than the number of samples required by your training configuration (100000000). This will result in multiple training epochs and some samples being used more than once.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:jmdwk0hp) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.409 MB of 0.409 MB uploaded (0.004 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 2.2%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/current_learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/explained_variance</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l0</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▂▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁██</td></tr><tr><td>sparsity/below_1e-6</td><td>▁▆█</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▂▄▄▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>0.1</td></tr><tr><td>details/current_learning_rate</td><td>0.0003</td></tr><tr><td>details/n_training_tokens</td><td>69350400</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.06149</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.0</td></tr><tr><td>losses/l1_loss</td><td>5.01996</td></tr><tr><td>losses/mse_loss</td><td>0.05029</td></tr><tr><td>losses/overall_loss</td><td>0.61377</td></tr><tr><td>metrics/explained_variance</td><td>0.99557</td></tr><tr><td>metrics/explained_variance_std</td><td>0.0037</td></tr><tr><td>metrics/l0</td><td>20.52381</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-1.59449</td></tr><tr><td>sparsity/below_1e-5</td><td>10</td></tr><tr><td>sparsity/below_1e-6</td><td>10</td></tr><tr><td>sparsity/dead_features</td><td>8</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>161.46094</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">256-gated-L1-0.1-LR-0.0003-Tokens-1.000e+08</strong> at: <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/jmdwk0hp' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/jmdwk0hp</a><br/> View project at: <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240711_230207-jmdwk0hp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:jmdwk0hp). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b2673a6d8d49968119cc5f5500e8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113975362645256, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/quick-experiments/wandb/run-20240711_231450-qpswq6wq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evanhanders/benchmark_saes/runs/qpswq6wq' target=\"_blank\">256-gated-L1-0.2-LR-0.0003-Tokens-1.000e+08</a></strong> to <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/qpswq6wq' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/qpswq6wq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SAE:   0%|                                                                         | 0/100000000 [00:00<?, ?it/s]\u001b[A/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:264: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yield torch.tensor(\n",
      "\n",
      "100| MSE Loss 2.448 | L1 4.634:   0%|                                                       | 0/100000000 [00:10<?, ?it/s]\u001b[A\n",
      "100| MSE Loss 2.448 | L1 4.634:   1%|▍                                    | 1075200/100000000 [00:10<15:49, 104151.21it/s]\u001b[A\n",
      "200| MSE Loss 0.694 | L1 2.562:   1%|▍                                    | 1075200/100000000 [00:21<15:49, 104151.21it/s]\u001b[A\n",
      "200| MSE Loss 0.694 | L1 2.562:   2%|▊                                    | 2150400/100000000 [00:21<16:07, 101136.19it/s]\u001b[A\n",
      "300| MSE Loss 0.416 | L1 2.088:   2%|▊                                    | 2150400/100000000 [00:31<16:07, 101136.19it/s]\u001b[A\n",
      "300| MSE Loss 0.416 | L1 2.088:   3%|█▏                                   | 3225600/100000000 [00:31<15:58, 100922.02it/s]\u001b[A\n",
      "400| MSE Loss 0.311 | L1 1.833:   3%|█▏                                   | 3225600/100000000 [00:43<15:58, 100922.02it/s]\u001b[A\n",
      "400| MSE Loss 0.311 | L1 1.833:   4%|█▋                                    | 4300800/100000000 [00:43<16:05, 99086.69it/s]\u001b[A\n",
      "400| MSE Loss 0.311 | L1 1.833:   4%|█▋                                    | 4300800/100000000 [00:54<16:05, 99086.69it/s]\u001b[A\n",
      "500| MSE Loss 0.262 | L1 1.676:   4%|█▋                                    | 4300800/100000000 [00:54<16:05, 99086.69it/s]\u001b[A\n",
      "500| MSE Loss 0.262 | L1 1.676:   5%|██                                    | 5376000/100000000 [00:54<16:24, 96121.05it/s]\u001b[A\n",
      "600| MSE Loss 0.224 | L1 1.554:   5%|██                                    | 5376000/100000000 [01:06<16:24, 96121.05it/s]\u001b[A\n",
      "600| MSE Loss 0.224 | L1 1.554:   6%|██▍                                   | 6451200/100000000 [01:06<16:37, 93823.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "700| MSE Loss 0.197 | L1 1.472:   6%|██▍                                   | 6451200/100000000 [01:18<16:37, 93823.92it/s]\u001b[A\n",
      "700| MSE Loss 0.197 | L1 1.472:   8%|██▊                                   | 7526400/100000000 [01:18<16:37, 92669.41it/s]\u001b[A\n",
      "700| MSE Loss 0.197 | L1 1.472:   8%|██▊                                   | 7526400/100000000 [01:29<16:37, 92669.41it/s]\u001b[A\n",
      "800| MSE Loss 0.186 | L1 1.409:   8%|██▊                                   | 7526400/100000000 [01:30<16:37, 92669.41it/s]\u001b[A\n",
      "800| MSE Loss 0.186 | L1 1.409:   9%|███▎                                  | 8601600/100000000 [01:30<16:36, 91726.82it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from sae_utils import train_sae\n",
    "\n",
    "sae, store = train_sae(ll_model, sae_lens_cfg, dataset.shuffle(seed=101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1ce2f-d424-4776-af4e-bc5b0f7880d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
