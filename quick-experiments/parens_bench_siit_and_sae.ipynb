{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aadb87f4-0900-402d-bcb9-80d8ab780d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08091f5a-0c98-4367-80e3-7611a4f5d626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n",
      "the markers [1, 1, 3, 2, 0, 1, 1, 1, 3, 2]\n",
      "check: [ 1 1 ]  BOS ( ) ( ) ( ( ) ( ) ( ( ) ) ( ( ) ) ( ) ) PAD\n",
      "check: [ 1 1 ]  BOS ( ) ( ( ) ) ( ( ) ) ( ( ( ( ) ) ) ( ) ) PAD\n",
      "check: [ 0 0 ]  BOS ( ) ( ) ( ( ( ( ( ( ) ( ( ( ( ( ) ( ( ( PAD\n",
      "check: [ 0 0 ]  BOS ) ( ) ) ) ) ) ( ( ) ( ) ) ( ( ) ( ( ( ( PAD\n",
      "check: [ 0 0 ]  BOS ) ) ) ) ( ( ) ) ) ) ) ( ) ( ) ( ) ) ) ) PAD\n",
      "check: [ 1 1 ]  BOS ( ( ) ) ( ( ) ( ( ( ) ) ) ( ) ) ( ) ( ) PAD\n",
      "check: [ 1 1 ]  BOS ( ( ) ( ) ) ( ( ( ) ( ) ) ( ( ) ) ( ) ) PAD\n",
      "check: [ 1 1 ]  BOS ( ( ) ) ( ( ) ) ( ) ( ( ( ) ( ) ) ( ) ) PAD\n",
      "check: [ 0 0 ]  BOS ( ) ( ( ( ( ( ( ( ) ( ( ( ( ( ( ( ( ( ( PAD\n",
      "check: [ 0 0 ]  BOS ) ( ) ( ) ) ) ( ) ( ) ( ( ( ) ) ) ( ( ( PAD\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from paren_checker import HighLevelParensBalanceChecker, BalancedParensDataset, SequentialParensDataset\n",
    "from paren_checker import test_HL_parens_components\n",
    "test_HL_parens_components()\n",
    "balance_checker = HighLevelParensBalanceChecker()\n",
    "dset = BalancedParensDataset(\n",
    "        N_samples = 10,\n",
    "        n_ctx = 22, #accounts for a BOS and a PAD\n",
    "        seed = 42\n",
    "    )\n",
    "print('the markers', dset.get_dataset()['markers'])\n",
    "for item in dset.get_dataset():\n",
    "    output = balance_checker(t.Tensor(item['tokens'])[None,:])\n",
    "    print('check: [', output[0,-1].int().item(), item['labels'], '] ', ''.join(item['str_tokens']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a33c5b0b-abee-4cf4-a17f-73868919b479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "HookedTransformer(\n",
      "  (embed): Embed()\n",
      "  (hook_embed): HookPoint()\n",
      "  (pos_embed): PosEmbed()\n",
      "  (hook_pos_embed): HookPoint()\n",
      "  (blocks): ModuleList(\n",
      "    (0-2): 3 x TransformerBlock(\n",
      "      (ln1): LayerNorm(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (ln2): LayerNorm(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (hook_k): HookPoint()\n",
      "        (hook_q): HookPoint()\n",
      "        (hook_v): HookPoint()\n",
      "        (hook_z): HookPoint()\n",
      "        (hook_attn_scores): HookPoint()\n",
      "        (hook_pattern): HookPoint()\n",
      "        (hook_result): HookPoint()\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (hook_pre): HookPoint()\n",
      "        (hook_post): HookPoint()\n",
      "      )\n",
      "      (hook_attn_in): HookPoint()\n",
      "      (hook_q_input): HookPoint()\n",
      "      (hook_k_input): HookPoint()\n",
      "      (hook_v_input): HookPoint()\n",
      "      (hook_mlp_in): HookPoint()\n",
      "      (hook_attn_out): HookPoint()\n",
      "      (hook_mlp_out): HookPoint()\n",
      "      (hook_resid_pre): HookPoint()\n",
      "      (hook_resid_mid): HookPoint()\n",
      "      (hook_resid_post): HookPoint()\n",
      "    )\n",
      "  )\n",
      "  (ln_final): LayerNorm(\n",
      "    (hook_scale): HookPoint()\n",
      "    (hook_normalized): HookPoint()\n",
      "  )\n",
      "  (unembed): Unembed()\n",
      ")\n",
      "\n",
      "Correspondence:\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "elevation_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "elevation_check_hook {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
      "       dtype=torch.int32))}\n",
      "horizon_check_hook {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=tensor([32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
      "        50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63],\n",
      "       dtype=torch.int32))}\n",
      "horizon_lookback_hook {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "balance_check_hook {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "\n",
      "Unused:\n",
      "LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)\n",
      "LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)\n",
      "LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None)\n",
      "LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None)\n",
      "LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None)\n"
     ]
    }
   ],
   "source": [
    "from paren_checker import get_LL_parens_model_and_correspondence\n",
    "ll_model, corr, unused_nodes = get_LL_parens_model_and_correspondence()\n",
    "print(\"Model:\")\n",
    "print(ll_model)\n",
    "print(\"\\nCorrespondence:\")\n",
    "for k, i in corr.items():\n",
    "    print(k, i)\n",
    "print(\"\\nUnused:\")\n",
    "for n in unused_nodes:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4ad087a-b145-48f4-ab2c-75ecc6f7b2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n"
     ]
    }
   ],
   "source": [
    "dset = BalancedParensDataset(\n",
    "        N_samples = 10_000,\n",
    "        n_ctx = 42, #accounts for a BOS and a PAD\n",
    "        seed = 42\n",
    "    )\n",
    "dataset = dset.get_dataset()\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c8849e1c-0a95-4b12-97d3-8c94278adb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf91a74b4674a9d93396795ae24bf63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Epoch 1/100:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached test IIA = 1; finishing training\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from siit_utils import ModelTrainerSIIT\n",
    "from paren_checker import paren_checker_loss_fn as loss_fn\n",
    "\n",
    "t.manual_seed(150) #150 for 10 epochs does pretty well; might be better at 6 epochs.\n",
    "ll_model, corr, unused_nodes = get_LL_parens_model_and_correspondence(n_ctx = 42)\n",
    "\n",
    "trainer = ModelTrainerSIIT(\n",
    "    ll_model=ll_model,\n",
    "    hl_model=balance_checker,\n",
    "    dataset=dataset,\n",
    "    corr=corr,\n",
    "    unused_nodes=unused_nodes,\n",
    "    loss_fn=loss_fn,\n",
    "    baseline_weight = 1,\n",
    "    iit_weight = 1,\n",
    "    siit_weight = 1,\n",
    "    batch_size = 512,\n",
    "    device = 'cuda'\n",
    ")\n",
    "#epoch 6: iia = 1, loss = 0.0027, epoch 7: iia = 1, loss = 0.00296; epoch 8: iia=1, loss = 0.00696; epoch 9: iia=1, loss = 0.00611; epoch 10: iia=1, loss=0.00277\n",
    "results = trainer.train(epochs=100, lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a51fc16-d9fe-497b-bb03-88490768679b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.semilogy(results['train_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77d0dac6-6c3e-4a0b-8716-42d5b01cb3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "steps = np.arange(len(np.array(results['train_IIA'])))\n",
    "plt.figure()\n",
    "plt.semilogy(steps, 1 - np.array(results['train_IIA']))\n",
    "plt.xlim(0, steps.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f6f419e-938c-4f75-b9d7-f6cc712322b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.759782463312149,\n",
       " 0.8170628994703293,\n",
       " 0.8854222744703293,\n",
       " 0.9648774117231369,\n",
       " 0.9759226888418198,\n",
       " 0.9828091114759445,\n",
       " 0.9842234700918198,\n",
       " 0.9823208302259445,\n",
       " 0.9852505177259445,\n",
       " 0.9848127663135529,\n",
       " 0.9843244850635529,\n",
       " 0.99169921875,\n",
       " 0.9896955788135529,\n",
       " 0.9887190163135529,\n",
       " 0.9921369850635529,\n",
       " 0.9950666725635529,\n",
       " 0.9926252663135529,\n",
       " 0.9936018288135529,\n",
       " 0.9931135475635529,\n",
       " 0.9921369850635529,\n",
       " 0.9950666725635529,\n",
       " 0.9945783913135529,\n",
       " 0.9970703125,\n",
       " 0.9970197975635529,\n",
       " 0.9970197975635529,\n",
       " 0.99560546875,\n",
       " 0.9960432350635529,\n",
       " 0.99658203125,\n",
       " 0.99755859375,\n",
       " 0.9965315163135529,\n",
       " 0.99755859375,\n",
       " 0.9970703125,\n",
       " 0.99755859375,\n",
       " 0.9970197975635529,\n",
       " 0.9954539388418198,\n",
       " 0.99755859375,\n",
       " 0.9959927052259445,\n",
       " 0.99755859375,\n",
       " 0.9960432350635529,\n",
       " 0.99755859375,\n",
       " 0.9970197975635529,\n",
       " 0.99853515625,\n",
       " 0.998046875,\n",
       " 0.9965315163135529,\n",
       " 0.99755859375,\n",
       " 0.99853515625,\n",
       " 0.998046875,\n",
       " 0.998046875,\n",
       " 0.99755859375,\n",
       " 0.9950666725635529,\n",
       " 0.99755859375,\n",
       " 0.99755859375,\n",
       " 0.9979963600635529,\n",
       " 0.99755859375,\n",
       " 0.99755859375,\n",
       " 0.9990234375,\n",
       " 0.998046875,\n",
       " 0.998046875,\n",
       " 0.9984846413135529,\n",
       " 0.9990234375,\n",
       " 0.9970197975635529,\n",
       " 0.9984846413135529,\n",
       " 0.998046875,\n",
       " 0.99951171875,\n",
       " 0.99755859375,\n",
       " 0.9990234375,\n",
       " 0.9990234375,\n",
       " 0.9990234375,\n",
       " 0.99951171875,\n",
       " 0.9990234375,\n",
       " 0.99951171875,\n",
       " 0.99755859375,\n",
       " 0.99951171875,\n",
       " 0.99755859375,\n",
       " 0.99755859375,\n",
       " 0.9990234375,\n",
       " 0.9990234375,\n",
       " 1.0]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['test_IIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61f9b230-1fc9-47d9-b7dc-70aea22b25db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 0/2000, Ablated Err: 985/2000\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from siit_utils import make_post_ablation_hook\n",
    "tot = 0\n",
    "errors = 0\n",
    "ablated_errors = 0\n",
    "for b in trainer.test_dataloaders[0]:\n",
    "    tokens, labels = b\n",
    "    logits, cache = ll_model.run_with_cache(tokens)\n",
    "    output_labels = t.round(t.sigmoid(logits)[:,-1,-1])\n",
    "    sumdiff = (labels.cuda() != output_labels.float()).sum().item()\n",
    "\n",
    "    hooks = []\n",
    "    for node in unused_nodes:\n",
    "        hooks.append((node.name, make_post_ablation_hook(ll_node=node, ll_cache=cache, method='mean')))\n",
    "    ablated_logits = ll_model.run_with_hooks(tokens, fwd_hooks=hooks)\n",
    "    \n",
    "    ablated_labels = t.round(t.sigmoid(ablated_logits)[:,-1,-1])\n",
    "    ablated_sumdiff = (labels.cuda() != ablated_labels.float()).sum().item()\n",
    "\n",
    "    errors += sumdiff\n",
    "    ablated_errors += ablated_sumdiff\n",
    "    tot += labels.numel()\n",
    "print(f'Errors: {errors}/{tot}, Ablated Err: {ablated_errors}/{tot}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4175b6e-6308-455d-bff9-5cece1ab0b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add lines to save model to huggingface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed4627-f8eb-4ccc-be69-35beb1138f07",
   "metadata": {},
   "source": [
    "# Take a peek at the attention pattern on the important heads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42cce14-255f-43a2-b427-3149481a8475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c580dbba-f101-4bf4-a1ea-15f9a50b801d",
   "metadata": {},
   "source": [
    "# SAEs -- vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51bb0308-b17b-405a-95fb-d7d0895b5197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Encoded: [3, 0, 1, 0, 1, 2, 2, 2]\n",
      "Decoded: BOS ( ) ( ) PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "from paren_checker import create_paren_checker_tokenizer\n",
    "tokenizer = create_paren_checker_tokenizer()\n",
    "ll_model.tokenizer = tokenizer #attach to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc6b5b5f-8485-4cc6-8f0b-0f2f3c1a72cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_head_index 0\n",
      "d_in 8\n",
      "wandb_project benchmark_saes\n",
      "Run name: 32-L1-0.2-LR-0.0003-Tokens-1.000e+08\n",
      "n_tokens_per_buffer (millions): 0.00336\n",
      "Lower bound: n_contexts_per_buffer (millions): 8e-05\n",
      "Total training steps: 9300\n",
      "Total wandb updates: 930\n",
      "n_tokens_per_feature_sampling_window (millions): 903.168\n",
      "n_tokens_per_dead_feature_window (millions): 451.584\n",
      "We will reset the sparsity calculation 4 times.\n",
      "Number tokens in sparsity calculation window: 2.15e+07\n",
      "Using Ghost Grads.\n"
     ]
    }
   ],
   "source": [
    "from sae_utils import make_sae_lens_config\n",
    "sae_lens_cfg = make_sae_lens_config(\n",
    "    model=ll_model,\n",
    "    hook_name=\"blocks.0.attn.hook_z\", \n",
    "    hook_layer=0, \n",
    "    l1_coefficient=0.2,\n",
    "    l1_warm_up_steps = 0,\n",
    "    hook_head_index=0, \n",
    "    context_size=ll_model.cfg.n_ctx,\n",
    "    d_in=ll_model.cfg.d_head,\n",
    "    device = 'cuda',\n",
    "    checkpoint_path = f\"$HOME/persistent-storage/tracr_saes/parens_sae_checkpoints\",\n",
    "    wandb_project =  \"benchmark_saes\",\n",
    "    training_tokens = 100_000_000,\n",
    "    batch_size = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eacc2c33-2a8d-446b-8fb3-8e5e7cc1f3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mevanhanders\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/quick-experiments/wandb/run-20240711_185327-w66x2lqo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evanhanders/benchmark_saes/runs/w66x2lqo' target=\"_blank\">32-L1-0.2-LR-0.0003-Tokens-1.000e+08</a></strong> to <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/w66x2lqo' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/w66x2lqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SAE:   0%|                                                                         | 0/100000000 [00:00<?, ?it/s]/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:254: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yield torch.tensor(\n",
      "1800| MSE Loss 0.044 | L1 0.141:  19%|██████▊                            | 19353600/100000000 [01:35<06:37, 202837.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/dccr8n2y/20009472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3700| MSE Loss 0.033 | L1 0.127:  40%|█████████████▉                     | 39782400/100000000 [03:23<05:16, 190404.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/dccr8n2y/40008192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5500| MSE Loss 0.033 | L1 0.142:  59%|████████████████████▋              | 59136000/100000000 [05:01<03:23, 201183.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/dccr8n2y/60006912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7400| MSE Loss 0.028 | L1 0.145:  80%|███████████████████████████▊       | 79564800/100000000 [06:48<01:50, 184838.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/dccr8n2y/80005632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9300| MSE Loss 0.033 | L1 0.151: 100%|██████████████████████████████████▉| 99993600/100000000 [08:32<00:00, 198136.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/dccr8n2y/final_100004352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9300| MSE Loss 0.033 | L1 0.151: 100%|██████████████████████████████████▉| 99993600/100000000 [08:33<00:00, 194713.44it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.037 MB of 0.037 MB uploaded (0.009 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 17.4%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/current_learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▅▃▃▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/explained_variance</td><td>▁▅▆▇██▇▇▇▇████████▇██▇██████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>█▅▅▂▁▁▂▂▃▂▂▂▂▁▁▁▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▁▁▂▂▂▂</td></tr><tr><td>metrics/l0</td><td>█▆▄▃▃▃▃▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▄▂▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁▂▅█</td></tr><tr><td>sparsity/below_1e-6</td><td>▁▁██</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁█▁▁▁█</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▁▁▂▃▁▁▂▃▄▂▃▃▅▅▃▃▄▅▅▄▃▅▅▆▅▆▅▆▅▃▄▇▇█▆▅▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>0.2</td></tr><tr><td>details/current_learning_rate</td><td>0.0003</td></tr><tr><td>details/n_training_tokens</td><td>99993600</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.0</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.00414</td></tr><tr><td>losses/l1_loss</td><td>0.75696</td></tr><tr><td>losses/mse_loss</td><td>0.03315</td></tr><tr><td>losses/overall_loss</td><td>0.18868</td></tr><tr><td>metrics/explained_variance</td><td>0.84839</td></tr><tr><td>metrics/explained_variance_std</td><td>0.22962</td></tr><tr><td>metrics/l0</td><td>3.1625</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-3.54624</td></tr><tr><td>sparsity/below_1e-5</td><td>13</td></tr><tr><td>sparsity/below_1e-6</td><td>1</td></tr><tr><td>sparsity/dead_features</td><td>0</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>163.84375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">32-L1-0.2-LR-0.0003-Tokens-1.000e+08</strong> at: <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/w66x2lqo' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/w66x2lqo</a><br/> View project at: <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a><br/>Synced 5 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240711_185327-w66x2lqo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sae_utils import train_sae\n",
    "\n",
    "#I need to be able to tell the SAE to ignore certain tokens during training.\n",
    "sae, store = train_sae(ll_model, sae_lens_cfg, dataset, batch_size=256)#, ignore_tokens=[])#2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13048231-5087-43d3-928d-84b862df9e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12938/718347451.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t.tensor(dataset['tokens']).int(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1ec3ebfadc41f686d91362c41849c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/381 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens torch.Size([97472, 42])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4093824, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sae_utils import make_token_df\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_activations_sum = t.zeros(sae.cfg.d_sae).to(sae.device)\n",
    "input_tokens_list = []\n",
    "learned_activations = []\n",
    "extras_list = []\n",
    "extra_hook = 'left_paren_hook'\n",
    "extra_name = 'left_parens'\n",
    "\n",
    "t_dataset = TensorDataset(\n",
    "    t.tensor(dataset['tokens']).int(), \n",
    "    t.tensor(dataset['labels']).float()\n",
    ")\n",
    "dataloader  = DataLoader(t_dataset, batch_size=256, shuffle = False)\n",
    "\n",
    "#go through the training dataset and get max activations for each feature\n",
    "total_inputs = 0\n",
    "for batch in tqdm(dataloader):\n",
    "    tokens, labels = batch\n",
    "    total_inputs += tokens.numel()\n",
    "    logits, cache = ll_model.run_with_cache(tokens)\n",
    "    sae_in = cache[sae.cfg.hook_name]\n",
    "    if sae.cfg.hook_head_index is not None:\n",
    "        sae_in = sae_in[:,:,sae.cfg.hook_head_index,:] #I think this is how attn head indexing works...\n",
    "    activations = sae.encode(sae_in)\n",
    "    # print(activations.shape, labels.shape, tokens.shape, tokens.numel())\n",
    "    activations[t.isin(tokens.int(), t.Tensor([2, 3]).int())] = 0\n",
    "\n",
    "    # For sparsity calculation\n",
    "    n_new_activations = (activations > 0).sum(dim=(0,1)) #sum over batch and ctx\n",
    "    n_activations_sum = n_activations_sum + n_new_activations\n",
    "\n",
    "    # Save tokens and activations\n",
    "    input_tokens_list.append(tokens.cpu())\n",
    "    learned_activations.append(activations.to(t.float16).cpu().reshape(-1, sae.cfg.d_sae))\n",
    "\n",
    "    #HL output\n",
    "    hl_output, hl_cache = balance_checker.run_with_cache(tokens)\n",
    "    extra = hl_cache[extra_hook]\n",
    "    extras_list.append(extra.cpu())\n",
    "\n",
    "    # if total_inputs > 100_000:\n",
    "    #     break\n",
    "sparsity = n_activations_sum / total_inputs\n",
    "tokens = t.cat(input_tokens_list).to(int)\n",
    "extras = t.cat(extras_list).to(int)\n",
    "token_df = make_token_df(ll_model, tokens, len_prefix=ll_model.cfg.n_ctx, \n",
    "                         extra_token_labels={extra_name : extras})\n",
    "learned_activations = t.cat(learned_activations).to(t.float16)\n",
    "token_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a00cb9d1-c7ed-41a9-ace9-ee83ce9661bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8f8a148f23465480955f64a4413629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Feature:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498f432e550840b78da23c5b62f92f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformer_lens import utils\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def update_dataframe(feature_id):\n",
    "    token_df[\"activation\"] = utils.to_numpy(learned_activations[:,feature_id])\n",
    "    df = token_df[['str_tokens','prefix', 'suffix',  'context', 'activation', extra_name]]\n",
    "    df = df.sort_values(\"activation\", ascending=False).head(100)\n",
    "    # display(df[df['activation'] > 0].style.background_gradient(\"coolwarm\"))\n",
    "    unique = df[['str_tokens', 'prefix', 'activation', extra_name]].drop_duplicates()\n",
    "    display(unique[unique['activation'] > 0].head(100).style.background_gradient(\"coolwarm\"))\n",
    "\n",
    "# Define the dropdown menu for 'feat'\n",
    "feat_dropdown = widgets.Dropdown(\n",
    "    options=range(sae.cfg.d_sae),\n",
    "    value=0,\n",
    "    description='Feature:',\n",
    ")\n",
    "\n",
    "# Create an interactive output widget\n",
    "output = widgets.interactive_output(\n",
    "    update_dataframe, \n",
    "    {\n",
    "        'feature_id': feat_dropdown,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the dropdown menu and output\n",
    "display(feat_dropdown, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c383c1-d5a0-45a7-a328-83261f98f6db",
   "metadata": {},
   "source": [
    "sae for attn 0 head 0:\n",
    "\n",
    "TBD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7216dd9-1741-41dc-aa50-74aef1dd1b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_in 64\n",
      "wandb_project benchmark_saes\n",
      "Run name: 256-L1-0.2-LR-0.0003-Tokens-1.000e+08\n",
      "n_tokens_per_buffer (millions): 0.00336\n",
      "Lower bound: n_contexts_per_buffer (millions): 8e-05\n",
      "Total training steps: 9300\n",
      "Total wandb updates: 930\n",
      "n_tokens_per_feature_sampling_window (millions): 903.168\n",
      "n_tokens_per_dead_feature_window (millions): 451.584\n",
      "We will reset the sparsity calculation 4 times.\n",
      "Number tokens in sparsity calculation window: 2.15e+07\n",
      "Using Ghost Grads.\n"
     ]
    }
   ],
   "source": [
    "from sae_utils import make_sae_lens_config\n",
    "sae_lens_cfg = make_sae_lens_config(\n",
    "    model=ll_model, \n",
    "    hook_name=\"blocks.0.mlp.hook_post\", \n",
    "    hook_layer=0, \n",
    "    l1_coefficient=0.2,\n",
    "    l1_warm_up_steps = 0,\n",
    "    context_size=ll_model.cfg.n_ctx,\n",
    "    d_in=ll_model.cfg.d_mlp,\n",
    "    device = 'cuda',\n",
    "    checkpoint_path = f\"$HOME/persistent-storage/tracr_saes/parens_sae_checkpoints\",\n",
    "    wandb_project =  \"benchmark_saes\",\n",
    "    training_tokens = 100_000_000,\n",
    "    batch_size = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ab00b93-9307-482f-89fb-42286e694da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/quick-experiments/wandb/run-20240711_203830-wzwdcw5r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evanhanders/benchmark_saes/runs/wzwdcw5r' target=\"_blank\">256-L1-0.2-LR-0.0003-Tokens-1.000e+08</a></strong> to <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/wzwdcw5r' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/wzwdcw5r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training SAE:   0%|                                                                         | 0/100000000 [00:00<?, ?it/s]/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:254: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yield torch.tensor(\n",
      "1800| MSE Loss 0.214 | L1 0.991:  19%|██████▊                            | 19353600/100000000 [01:44<07:40, 175175.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/1ct4tqbi/20009472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3700| MSE Loss 0.196 | L1 0.907:  40%|█████████████▉                     | 39782400/100000000 [03:37<05:34, 179809.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/1ct4tqbi/40008192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5500| MSE Loss 0.245 | L1 0.811:  59%|████████████████████▋              | 59136000/100000000 [05:23<03:54, 174439.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/1ct4tqbi/60006912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7400| MSE Loss 0.189 | L1 1.034:  80%|███████████████████████████▊       | 79564800/100000000 [07:17<01:53, 179617.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/1ct4tqbi/80005632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9300| MSE Loss 0.121 | L1 0.773: 100%|██████████████████████████████████▉| 99993600/100000000 [09:08<00:00, 182530.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/1ct4tqbi/final_100004352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9300| MSE Loss 0.121 | L1 0.773: 100%|██████████████████████████████████▉| 99993600/100000000 [09:08<00:00, 182207.75it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.662 MB of 0.662 MB uploaded (0.009 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 1.3%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/current_learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▃▂▂▂▂▂▁▂▁▁▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/explained_variance</td><td>▁▆▇▇████▇█████████▇█████████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>█▂▂▂▂▁▁▁▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>metrics/l0</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▂▁▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁▇██</td></tr><tr><td>sparsity/below_1e-6</td><td>▁██▅</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▃▁▁▁▁█▁▁▁▁▃▁▁▃▁▁▁▁▃▃▃▁▁▃▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▂▂▃▅▃▃▃▆█▄▄▄▅▆▄▄▅▆█▅▅▅▅▆▅▅▆▆█▆▇▆▅▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>0.2</td></tr><tr><td>details/current_learning_rate</td><td>0.0003</td></tr><tr><td>details/n_training_tokens</td><td>99993600</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.0</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.00189</td></tr><tr><td>losses/l1_loss</td><td>3.86355</td></tr><tr><td>losses/mse_loss</td><td>0.12071</td></tr><tr><td>losses/overall_loss</td><td>0.89531</td></tr><tr><td>metrics/explained_variance</td><td>0.97582</td></tr><tr><td>metrics/explained_variance_std</td><td>0.02435</td></tr><tr><td>metrics/l0</td><td>12.69821</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-2.80084</td></tr><tr><td>sparsity/below_1e-5</td><td>48</td></tr><tr><td>sparsity/below_1e-6</td><td>12</td></tr><tr><td>sparsity/dead_features</td><td>0</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>89.12109</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">256-L1-0.2-LR-0.0003-Tokens-1.000e+08</strong> at: <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/wzwdcw5r' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/wzwdcw5r</a><br/> View project at: <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a><br/>Synced 5 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240711_203830-wzwdcw5r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sae_utils import train_sae\n",
    "\n",
    "#I need to be able to tell the SAE to ignore certain tokens during training.\n",
    "sae, store = train_sae(ll_model, sae_lens_cfg, dataset)#, ignore_tokens=[])#2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a034e274-5923-4936-af0e-5613db407885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12938/3317634938.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t.tensor(dataset['tokens']).int(),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa68ef470534b259422701031a605cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(  0%|          | 0/381 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens torch.Size([97472, 42])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4093824, 9)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sae_utils import make_token_df\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "n_activations_sum = t.zeros(sae.cfg.d_sae).to(sae.device)\n",
    "input_tokens_list = []\n",
    "learned_activations = []\n",
    "extras_list = []\n",
    "extra_hook = 'elevation_hook'\n",
    "extra_name = 'elevation'\n",
    "\n",
    "t_dataset = TensorDataset(\n",
    "    t.tensor(dataset['tokens']).int(), \n",
    "    t.tensor(dataset['labels']).float()\n",
    ")\n",
    "dataloader  = DataLoader(t_dataset, batch_size=256, shuffle = False)\n",
    "\n",
    "#go through the training dataset and get max activations for each feature\n",
    "total_inputs = 0\n",
    "for batch in tqdm(dataloader):\n",
    "    tokens, labels = batch\n",
    "    total_inputs += tokens.numel()\n",
    "    logits, cache = ll_model.run_with_cache(tokens)\n",
    "    sae_in = cache[sae.cfg.hook_name]\n",
    "    if sae.cfg.hook_head_index is not None:\n",
    "        sae_in = sae_in[:,:,sae.cfg.hook_head_index,:] #I think this is how attn head indexing works...\n",
    "    activations = sae.encode(sae_in)\n",
    "    # print(activations.shape, labels.shape, tokens.shape, tokens.numel())\n",
    "    activations[t.isin(tokens.int(), t.Tensor([2, 3]).int())] = 0\n",
    "\n",
    "    # For sparsity calculation\n",
    "    n_new_activations = (activations > 0).sum(dim=(0,1)) #sum over batch and ctx\n",
    "    n_activations_sum = n_activations_sum + n_new_activations\n",
    "\n",
    "    # Save tokens and activations\n",
    "    input_tokens_list.append(tokens.cpu())\n",
    "    learned_activations.append(activations.to(t.float16).cpu().reshape(-1, sae.cfg.d_sae))\n",
    "\n",
    "    #HL output\n",
    "    hl_output, hl_cache = balance_checker.run_with_cache(tokens)\n",
    "    extra = hl_cache[extra_hook]\n",
    "    extras_list.append(extra.cpu())\n",
    "\n",
    "    # if total_inputs > 100_000:\n",
    "    #     break\n",
    "sparsity = n_activations_sum / total_inputs\n",
    "tokens = t.cat(input_tokens_list).to(int)\n",
    "extras = t.cat(extras_list).to(int)\n",
    "token_df = make_token_df(ll_model, tokens, len_prefix=ll_model.cfg.n_ctx, \n",
    "                         extra_token_labels={extra_name : extras})\n",
    "learned_activations = t.cat(learned_activations).to(t.float16)\n",
    "token_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ecfb13a-0839-435e-9bfc-24e940af966a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a3d2ea70f840bca8c98028048eec16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Feature:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2334e6ed4947446bae62826bd1a91849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformer_lens import utils\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def update_dataframe(feature_id):\n",
    "    token_df[\"activation\"] = utils.to_numpy(learned_activations[:,feature_id])\n",
    "    df = token_df[['str_tokens','prefix', 'suffix',  'context', 'activation', 'elevation']]\n",
    "    df = df.sort_values(\"activation\", ascending=False).head(100)\n",
    "    # display(df[df['activation'] > 0].style.background_gradient(\"coolwarm\"))\n",
    "    unique = df[['str_tokens', 'prefix', 'activation', 'elevation']].drop_duplicates()\n",
    "    display(unique[unique['activation'] > 0].head(100).style.background_gradient(\"coolwarm\"))\n",
    "\n",
    "# Define the dropdown menu for 'feat'\n",
    "feat_dropdown = widgets.Dropdown(\n",
    "    options=range(sae.cfg.d_sae),\n",
    "    value=0,\n",
    "    description='Feature:',\n",
    ")\n",
    "\n",
    "# Create an interactive output widget\n",
    "output = widgets.interactive_output(\n",
    "    update_dataframe, \n",
    "    {\n",
    "        'feature_id': feat_dropdown,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the dropdown menu and output\n",
    "display(feat_dropdown, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92cc1002-48b6-4b8a-b01c-0b8dd23d9cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.1\n"
     ]
    }
   ],
   "source": [
    "import sae_lens\n",
    "print(sae_lens.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd529f94-c986-44c1-a023-85f2096b13d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SAELens -- top-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a1643ea-ffec-44d1-909c-f6a48d37b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_fn topk\n",
      "activation_fn_kwargs {'k': 4}\n",
      "mse_loss_normalization None\n",
      "d_in 64\n",
      "wandb_project benchmark_saes\n",
      "Run name: 256-L1-0.1-LR-0.0003-Tokens-1.000e+08\n",
      "n_tokens_per_buffer (millions): 0.02688\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.00064\n",
      "Total training steps: 9300\n",
      "Total wandb updates: 930\n",
      "n_tokens_per_feature_sampling_window (millions): 903.168\n",
      "n_tokens_per_dead_feature_window (millions): 451.584\n",
      "We will reset the sparsity calculation 4 times.\n",
      "Number tokens in sparsity calculation window: 2.15e+07\n",
      "Using Ghost Grads.\n"
     ]
    }
   ],
   "source": [
    "from sae_utils import make_topk_sae_lens_config\n",
    "sae_lens_cfg = make_topk_sae_lens_config(\n",
    "    model=ll_model, \n",
    "    hook_name=\"blocks.0.mlp.hook_post\", \n",
    "    hook_layer=0, \n",
    "    k=4, #choose smallest value that achieves good mse loss.\n",
    "    context_size=ll_model.cfg.n_ctx,\n",
    "    d_in=ll_model.cfg.d_mlp,\n",
    "    device = 'cuda',\n",
    "    checkpoint_path = f\"$HOME/persistent-storage/tracr_saes/parens_sae_checkpoints\",\n",
    "    wandb_project =  \"benchmark_saes\",\n",
    "    training_tokens = 100_000_000,\n",
    "    batch_size = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fa44881-eeb0-4bdf-b692-4bd977c9b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the training dataset contains fewer samples (97472) than the number of samples required by your training configuration (100000000). This will result in multiple training epochs and some samples being used more than once.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wqc1tcgn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.273 MB of 0.273 MB uploaded (0.002 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/current_learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>█▆▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>▁▄▇██████████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>losses/mse_loss</td><td>█▆▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>█▆▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/explained_variance</td><td>▁▃▆▇▇▇▇▇▇███████████████████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>█▆▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l0</td><td>███████████████████████████████████▅▁▄█▅</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>▁█</td></tr><tr><td>sparsity/below_1e-5</td><td>█▁</td></tr><tr><td>sparsity/below_1e-6</td><td>█▁</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▅▃▁▁▁▃▁▁▁▁▁</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▂▄▅▆▇▇███▂▂▃▃▃▃▄▄▄▃▃▃▄▄▄▄▄▄▄▃▃▂▂▂▃▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>0.1</td></tr><tr><td>details/current_learning_rate</td><td>0.0003</td></tr><tr><td>details/n_training_tokens</td><td>45696000</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.0</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.0126</td></tr><tr><td>losses/l1_loss</td><td>8.73607</td></tr><tr><td>losses/mse_loss</td><td>0.8065</td></tr><tr><td>losses/overall_loss</td><td>1.6927</td></tr><tr><td>metrics/explained_variance</td><td>0.92588</td></tr><tr><td>metrics/explained_variance_std</td><td>0.06244</td></tr><tr><td>metrics/l0</td><td>4.0</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-4.18563</td></tr><tr><td>sparsity/below_1e-5</td><td>76</td></tr><tr><td>sparsity/below_1e-6</td><td>29</td></tr><tr><td>sparsity/dead_features</td><td>0</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>183.13281</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">256-topk-4-LR-0.0003-Tokens-1.000e+08</strong> at: <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/wqc1tcgn' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/wqc1tcgn</a><br/> View project at: <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a><br/>Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240711_220643-wqc1tcgn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wqc1tcgn). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3a67e8c4e74c67bf87b2a607dc274f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114499510990248, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/quick-experiments/wandb/run-20240711_221648-mh01kdsc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evanhanders/benchmark_saes/runs/mh01kdsc' target=\"_blank\">256-topk-4-LR-0.0003-Tokens-1.000e+08</a></strong> to <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/mh01kdsc' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/mh01kdsc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training SAE:   0%|                                                                         | 0/100000000 [00:00<?, ?it/s]\u001b[A\u001b[A/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:264: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yield torch.tensor(\n",
      "/opt/venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:2265: UserWarning: Run (25elroub) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "1200| MSE Loss 1.594 | L1 0.940:  13%|████▍                             | 12902400/100000000 [18:41<2:06:08, 11507.49it/s]\n",
      "\n",
      "\n",
      "100| MSE Loss 13.181 | L1 0.473:   0%|                                                      | 0/100000000 [00:11<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100| MSE Loss 13.181 | L1 0.473:   1%|▍                                    | 1075200/100000000 [00:11<18:06, 91024.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "100| MSE Loss 13.181 | L1 0.473:   1%|▍                                    | 1075200/100000000 [00:22<18:06, 91024.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "200| MSE Loss 6.829 | L1 0.650:   1%|▍                                     | 1075200/100000000 [00:23<18:06, 91024.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "200| MSE Loss 6.829 | L1 0.650:   2%|▊                                     | 2150400/100000000 [00:23<18:06, 90018.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "300| MSE Loss 4.432 | L1 0.649:   2%|▊                                     | 2150400/100000000 [00:35<18:06, 90018.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "300| MSE Loss 4.432 | L1 0.649:   3%|█▏                                    | 3225600/100000000 [00:35<18:00, 89562.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "300| MSE Loss 4.432 | L1 0.649:   3%|█▏                                    | 3225600/100000000 [00:46<18:00, 89562.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "400| MSE Loss 3.290 | L1 0.601:   3%|█▏                                    | 3225600/100000000 [00:48<18:00, 89562.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "400| MSE Loss 3.290 | L1 0.601:   4%|█▋                                    | 4300800/100000000 [00:48<18:05, 88198.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "500| MSE Loss 2.650 | L1 0.578:   4%|█▋                                    | 4300800/100000000 [01:01<18:05, 88198.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "500| MSE Loss 2.650 | L1 0.578:   5%|██                                    | 5376000/100000000 [01:01<18:16, 86288.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "500| MSE Loss 2.650 | L1 0.578:   5%|██                                    | 5376000/100000000 [01:12<18:16, 86288.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "600| MSE Loss 2.199 | L1 0.563:   5%|██                                    | 5376000/100000000 [01:12<18:16, 86288.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "600| MSE Loss 2.199 | L1 0.563:   6%|██▍                                   | 6451200/100000000 [01:12<17:32, 88884.25it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "700| MSE Loss 1.961 | L1 0.562:   6%|██▍                                   | 6451200/100000000 [01:25<17:32, 88884.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "700| MSE Loss 1.961 | L1 0.562:   8%|██▊                                   | 7526400/100000000 [01:25<17:32, 87889.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "700| MSE Loss 1.961 | L1 0.562:   8%|██▊                                   | 7526400/100000000 [01:37<17:32, 87889.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "800| MSE Loss 1.781 | L1 0.554:   8%|██▊                                   | 7526400/100000000 [01:37<17:32, 87889.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "800| MSE Loss 1.781 | L1 0.554:   9%|███▎                                  | 8601600/100000000 [01:37<17:23, 87551.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "900| MSE Loss 1.595 | L1 0.551:   9%|███▎                                  | 8601600/100000000 [01:50<17:23, 87551.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "900| MSE Loss 1.595 | L1 0.551:  10%|███▋                                  | 9676800/100000000 [01:50<17:32, 85839.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "900| MSE Loss 1.595 | L1 0.551:  10%|███▋                                  | 9676800/100000000 [02:02<17:32, 85839.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "1000| MSE Loss 1.508 | L1 0.548:  10%|███▌                                 | 9676800/100000000 [02:04<17:32, 85839.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "1000| MSE Loss 1.508 | L1 0.548:  11%|███▊                                | 10752000/100000000 [02:04<17:48, 83536.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1000| MSE Loss 1.508 | L1 0.548:  11%|███▊                                | 10752000/100000000 [02:17<17:48, 83536.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1100| MSE Loss 1.436 | L1 0.545:  11%|███▊                                | 10752000/100000000 [02:17<17:48, 83536.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1100| MSE Loss 1.436 | L1 0.545:  12%|████▎                               | 11827200/100000000 [02:17<17:48, 82523.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "1200| MSE Loss 1.305 | L1 0.537:  12%|████▎                               | 11827200/100000000 [02:31<17:48, 82523.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "1200| MSE Loss 1.305 | L1 0.537:  13%|████▋                               | 12902400/100000000 [02:31<17:53, 81164.34it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1200| MSE Loss 1.305 | L1 0.537:  13%|████▋                               | 12902400/100000000 [02:42<17:53, 81164.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "1300| MSE Loss 1.271 | L1 0.536:  13%|████▋                               | 12902400/100000000 [02:45<17:53, 81164.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "1300| MSE Loss 1.271 | L1 0.536:  14%|█████                               | 13977600/100000000 [02:45<17:54, 80071.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1300| MSE Loss 1.271 | L1 0.536:  14%|█████                               | 13977600/100000000 [02:57<17:54, 80071.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1400| MSE Loss 1.173 | L1 0.531:  14%|█████                               | 13977600/100000000 [02:57<17:54, 80071.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "1400| MSE Loss 1.173 | L1 0.531:  15%|█████▍                              | 15052800/100000000 [02:57<17:19, 81751.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "1500| MSE Loss 1.117 | L1 0.520:  15%|█████▍                              | 15052800/100000000 [03:09<17:19, 81751.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "1500| MSE Loss 1.117 | L1 0.520:  16%|█████▊                              | 16128000/100000000 [03:09<16:39, 83910.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "1600| MSE Loss 1.074 | L1 0.523:  16%|█████▊                              | 16128000/100000000 [03:22<16:39, 83910.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "1600| MSE Loss 1.074 | L1 0.523:  17%|██████▏                             | 17203200/100000000 [03:22<16:28, 83782.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "1600| MSE Loss 1.074 | L1 0.523:  17%|██████▏                             | 17203200/100000000 [03:32<16:28, 83782.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "1700| MSE Loss 1.041 | L1 0.521:  17%|██████▏                             | 17203200/100000000 [03:35<16:28, 83782.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "1700| MSE Loss 1.041 | L1 0.521:  18%|██████▌                             | 18278400/100000000 [03:35<16:19, 83428.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "1800| MSE Loss 0.988 | L1 0.515:  18%|██████▌                             | 18278400/100000000 [03:47<16:19, 83428.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "1800| MSE Loss 0.988 | L1 0.515:  19%|██████▉                             | 19353600/100000000 [03:47<15:44, 85368.89it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n",
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/lob29g44/20009472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1800| MSE Loss 0.988 | L1 0.515:  19%|██████▉                             | 19353600/100000000 [03:57<15:44, 85368.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "1900| MSE Loss 0.959 | L1 0.513:  19%|██████▉                             | 19353600/100000000 [04:00<15:44, 85368.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "1900| MSE Loss 0.959 | L1 0.513:  20%|███████▎                            | 20428800/100000000 [04:00<15:33, 85271.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "2000| MSE Loss 0.894 | L1 0.508:  20%|███████▎                            | 20428800/100000000 [04:12<15:33, 85271.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "2000| MSE Loss 0.894 | L1 0.508:  22%|███████▋                            | 21504000/100000000 [04:12<15:06, 86605.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "2000| MSE Loss 0.894 | L1 0.508:  22%|███████▋                            | 21504000/100000000 [04:22<15:06, 86605.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "2100| MSE Loss 0.900 | L1 0.505:  22%|███████▋                            | 21504000/100000000 [04:24<15:06, 86605.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "2100| MSE Loss 0.900 | L1 0.505:  23%|████████▏                           | 22579200/100000000 [04:24<14:52, 86775.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "2200| MSE Loss 0.902 | L1 0.505:  23%|████████▏                           | 22579200/100000000 [04:36<14:52, 86775.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "2200| MSE Loss 0.902 | L1 0.505:  24%|████████▌                           | 23654400/100000000 [04:36<14:29, 87774.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "2200| MSE Loss 0.902 | L1 0.505:  24%|████████▌                           | 23654400/100000000 [04:47<14:29, 87774.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "2300| MSE Loss 0.875 | L1 0.497:  24%|████████▌                           | 23654400/100000000 [04:48<14:29, 87774.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "2300| MSE Loss 0.875 | L1 0.497:  25%|████████▉                           | 24729600/100000000 [04:48<14:14, 88085.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "2400| MSE Loss 0.822 | L1 0.492:  25%|████████▉                           | 24729600/100000000 [05:00<14:14, 88085.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "2400| MSE Loss 0.822 | L1 0.492:  26%|█████████▎                          | 25804800/100000000 [05:00<13:48, 89606.12it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "2500| MSE Loss 0.823 | L1 0.486:  26%|█████████▎                          | 25804800/100000000 [05:12<13:48, 89606.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "2500| MSE Loss 0.823 | L1 0.486:  27%|█████████▋                          | 26880000/100000000 [05:12<13:35, 89669.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "2500| MSE Loss 0.823 | L1 0.486:  27%|█████████▋                          | 26880000/100000000 [05:22<13:35, 89669.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "2600| MSE Loss 0.827 | L1 0.489:  27%|█████████▋                          | 26880000/100000000 [05:24<13:35, 89669.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "2600| MSE Loss 0.827 | L1 0.489:  28%|██████████                          | 27955200/100000000 [05:24<13:24, 89519.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "2700| MSE Loss 0.787 | L1 0.483:  28%|██████████                          | 27955200/100000000 [05:37<13:24, 89519.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "2700| MSE Loss 0.787 | L1 0.483:  29%|██████████▍                         | 29030400/100000000 [05:37<13:36, 86930.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "2700| MSE Loss 0.787 | L1 0.483:  29%|██████████▍                         | 29030400/100000000 [05:47<13:36, 86930.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "2800| MSE Loss 0.758 | L1 0.477:  29%|██████████▍                         | 29030400/100000000 [05:50<13:36, 86930.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "2800| MSE Loss 0.758 | L1 0.477:  30%|██████████▊                         | 30105600/100000000 [05:50<13:45, 84631.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "2800| MSE Loss 0.758 | L1 0.477:  30%|██████████▊                         | 30105600/100000000 [06:02<13:45, 84631.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "2900| MSE Loss 0.768 | L1 0.481:  30%|██████████▊                         | 30105600/100000000 [06:04<13:45, 84631.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "2900| MSE Loss 0.768 | L1 0.481:  31%|███████████▏                        | 31180800/100000000 [06:04<13:42, 83709.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "3000| MSE Loss 0.753 | L1 0.477:  31%|███████████▏                        | 31180800/100000000 [06:17<13:42, 83709.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "3000| MSE Loss 0.753 | L1 0.477:  32%|███████████▌                        | 32256000/100000000 [06:17<13:46, 81973.37it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3000| MSE Loss 0.753 | L1 0.477:  32%|███████████▌                        | 32256000/100000000 [06:28<13:46, 81973.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "3100| MSE Loss 0.755 | L1 0.475:  32%|███████████▌                        | 32256000/100000000 [06:31<13:46, 81973.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "3100| MSE Loss 0.755 | L1 0.475:  33%|███████████▉                        | 33331200/100000000 [06:31<13:46, 80690.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "3100| MSE Loss 0.755 | L1 0.475:  33%|███████████▉                        | 33331200/100000000 [06:42<13:46, 80690.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "3200| MSE Loss 0.719 | L1 0.466:  33%|███████████▉                        | 33331200/100000000 [06:44<13:46, 80690.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "3200| MSE Loss 0.719 | L1 0.466:  34%|████████████▍                       | 34406400/100000000 [06:44<13:31, 80820.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "3300| MSE Loss 0.727 | L1 0.469:  34%|████████████▍                       | 34406400/100000000 [06:57<13:31, 80820.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "3300| MSE Loss 0.727 | L1 0.469:  35%|████████████▊                       | 35481600/100000000 [06:57<13:09, 81711.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "3300| MSE Loss 0.727 | L1 0.469:  35%|████████████▊                       | 35481600/100000000 [07:08<13:09, 81711.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "3400| MSE Loss 0.709 | L1 0.473:  35%|████████████▊                       | 35481600/100000000 [07:09<13:09, 81711.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "3400| MSE Loss 0.709 | L1 0.473:  37%|█████████████▏                      | 36556800/100000000 [07:09<12:38, 83636.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "3500| MSE Loss 0.694 | L1 0.469:  37%|█████████████▏                      | 36556800/100000000 [07:22<12:38, 83636.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "3500| MSE Loss 0.694 | L1 0.469:  38%|█████████████▌                      | 37632000/100000000 [07:22<12:21, 84149.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "3500| MSE Loss 0.694 | L1 0.469:  38%|█████████████▌                      | 37632000/100000000 [07:32<12:21, 84149.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "3600| MSE Loss 0.707 | L1 0.464:  38%|█████████████▌                      | 37632000/100000000 [07:34<12:21, 84149.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "3600| MSE Loss 0.707 | L1 0.464:  39%|█████████████▉                      | 38707200/100000000 [07:34<11:50, 86307.83it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3700| MSE Loss 0.699 | L1 0.464:  39%|█████████████▉                      | 38707200/100000000 [07:45<11:50, 86307.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "3700| MSE Loss 0.699 | L1 0.464:  40%|██████████████▎                     | 39782400/100000000 [07:45<11:26, 87701.29it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/lob29g44/40008192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3800| MSE Loss 0.665 | L1 0.459:  40%|██████████████▎                     | 39782400/100000000 [07:57<11:26, 87701.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "3800| MSE Loss 0.665 | L1 0.459:  41%|██████████████▋                     | 40857600/100000000 [07:57<11:10, 88170.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "3800| MSE Loss 0.665 | L1 0.459:  41%|██████████████▋                     | 40857600/100000000 [08:08<11:10, 88170.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "3900| MSE Loss 0.660 | L1 0.451:  41%|██████████████▋                     | 40857600/100000000 [08:09<11:10, 88170.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "3900| MSE Loss 0.660 | L1 0.451:  42%|███████████████                     | 41932800/100000000 [08:09<10:53, 88913.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "4000| MSE Loss 0.660 | L1 0.458:  42%|███████████████                     | 41932800/100000000 [08:21<10:53, 88913.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "4000| MSE Loss 0.660 | L1 0.458:  43%|███████████████▍                    | 43008000/100000000 [08:21<10:31, 90316.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "4100| MSE Loss 0.642 | L1 0.460:  43%|███████████████▍                    | 43008000/100000000 [08:32<10:31, 90316.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "4100| MSE Loss 0.642 | L1 0.460:  44%|███████████████▊                    | 44083200/100000000 [08:32<10:10, 91585.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "4100| MSE Loss 0.642 | L1 0.460:  44%|███████████████▊                    | 44083200/100000000 [08:43<10:10, 91585.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "4200| MSE Loss 0.643 | L1 0.456:  44%|███████████████▊                    | 44083200/100000000 [08:43<10:10, 91585.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "4200| MSE Loss 0.643 | L1 0.456:  45%|████████████████▎                   | 45158400/100000000 [08:43<09:46, 93546.74it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4300| MSE Loss 0.633 | L1 0.455:  45%|████████████████▎                   | 45158400/100000000 [08:54<09:46, 93546.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "4300| MSE Loss 0.633 | L1 0.455:  46%|████████████████▋                   | 46233600/100000000 [08:54<09:32, 93915.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "4400| MSE Loss 0.619 | L1 0.454:  46%|████████████████▋                   | 46233600/100000000 [09:05<09:32, 93915.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "4400| MSE Loss 0.619 | L1 0.454:  47%|█████████████████                   | 47308800/100000000 [09:05<09:11, 95511.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "4500| MSE Loss 0.641 | L1 0.457:  47%|█████████████████                   | 47308800/100000000 [09:17<09:11, 95511.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "4500| MSE Loss 0.641 | L1 0.457:  48%|█████████████████▍                  | 48384000/100000000 [09:17<09:07, 94255.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "4500| MSE Loss 0.641 | L1 0.457:  48%|█████████████████▍                  | 48384000/100000000 [09:28<09:07, 94255.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "4600| MSE Loss 0.607 | L1 0.452:  48%|█████████████████▍                  | 48384000/100000000 [09:29<09:07, 94255.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "4600| MSE Loss 0.607 | L1 0.452:  49%|█████████████████▊                  | 49459200/100000000 [09:29<09:11, 91690.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "4700| MSE Loss 0.573 | L1 0.454:  49%|█████████████████▊                  | 49459200/100000000 [09:42<09:11, 91690.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "4700| MSE Loss 0.573 | L1 0.454:  51%|██████████████████▏                 | 50534400/100000000 [09:42<09:17, 88772.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "4700| MSE Loss 0.573 | L1 0.454:  51%|██████████████████▏                 | 50534400/100000000 [09:53<09:17, 88772.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "4800| MSE Loss 0.598 | L1 0.451:  51%|██████████████████▏                 | 50534400/100000000 [09:56<09:17, 88772.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "4800| MSE Loss 0.598 | L1 0.451:  52%|██████████████████▌                 | 51609600/100000000 [09:56<09:18, 86650.86it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4800| MSE Loss 0.598 | L1 0.451:  52%|██████████████████▌                 | 51609600/100000000 [10:08<09:18, 86650.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "4900| MSE Loss 0.563 | L1 0.445:  52%|██████████████████▌                 | 51609600/100000000 [10:09<09:18, 86650.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "4900| MSE Loss 0.563 | L1 0.445:  53%|██████████████████▉                 | 52684800/100000000 [10:09<09:14, 85325.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "5000| MSE Loss 0.553 | L1 0.450:  53%|██████████████████▉                 | 52684800/100000000 [10:21<09:14, 85325.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "5000| MSE Loss 0.553 | L1 0.450:  54%|███████████████████▎                | 53760000/100000000 [10:21<09:03, 85045.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "5000| MSE Loss 0.553 | L1 0.450:  54%|███████████████████▎                | 53760000/100000000 [10:33<09:03, 85045.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "5100| MSE Loss 0.552 | L1 0.447:  54%|███████████████████▎                | 53760000/100000000 [10:34<09:03, 85045.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "5100| MSE Loss 0.552 | L1 0.447:  55%|███████████████████▋                | 54835200/100000000 [10:34<08:54, 84527.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "5200| MSE Loss 0.545 | L1 0.452:  55%|███████████████████▋                | 54835200/100000000 [10:47<08:54, 84527.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "5200| MSE Loss 0.545 | L1 0.452:  56%|████████████████████▏               | 55910400/100000000 [10:47<08:43, 84288.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "5200| MSE Loss 0.545 | L1 0.452:  56%|████████████████████▏               | 55910400/100000000 [10:58<08:43, 84288.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "5300| MSE Loss 0.530 | L1 0.445:  56%|████████████████████▏               | 55910400/100000000 [11:00<08:43, 84288.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "5300| MSE Loss 0.530 | L1 0.445:  57%|████████████████████▌               | 56985600/100000000 [11:00<08:33, 83775.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "5400| MSE Loss 0.570 | L1 0.452:  57%|████████████████████▌               | 56985600/100000000 [11:11<08:33, 83775.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "5400| MSE Loss 0.570 | L1 0.452:  58%|████████████████████▉               | 58060800/100000000 [11:11<07:55, 88238.90it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "5500| MSE Loss 0.541 | L1 0.446:  58%|████████████████████▉               | 58060800/100000000 [11:22<07:55, 88238.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "5500| MSE Loss 0.541 | L1 0.446:  59%|█████████████████████▎              | 59136000/100000000 [11:22<07:30, 90785.33it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/lob29g44/60006912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "5600| MSE Loss 0.509 | L1 0.447:  59%|█████████████████████▎              | 59136000/100000000 [11:33<07:30, 90785.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "5600| MSE Loss 0.509 | L1 0.447:  60%|█████████████████████▋              | 60211200/100000000 [11:33<07:12, 92047.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "5600| MSE Loss 0.509 | L1 0.447:  60%|█████████████████████▋              | 60211200/100000000 [11:44<07:12, 92047.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "5700| MSE Loss 0.541 | L1 0.445:  60%|█████████████████████▋              | 60211200/100000000 [11:44<07:12, 92047.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "5700| MSE Loss 0.541 | L1 0.445:  61%|██████████████████████              | 61286400/100000000 [11:44<06:55, 93080.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "5800| MSE Loss 0.522 | L1 0.443:  61%|██████████████████████              | 61286400/100000000 [11:56<06:55, 93080.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "5800| MSE Loss 0.522 | L1 0.443:  62%|██████████████████████▍             | 62361600/100000000 [11:56<06:42, 93502.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "5900| MSE Loss 0.505 | L1 0.442:  62%|██████████████████████▍             | 62361600/100000000 [12:07<06:42, 93502.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "5900| MSE Loss 0.505 | L1 0.442:  63%|██████████████████████▊             | 63436800/100000000 [12:07<06:27, 94284.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "6000| MSE Loss 0.498 | L1 0.438:  63%|██████████████████████▊             | 63436800/100000000 [12:18<06:27, 94284.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "6000| MSE Loss 0.498 | L1 0.438:  65%|███████████████████████▏            | 64512000/100000000 [12:18<06:12, 95200.79it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6000| MSE Loss 0.498 | L1 0.438:  65%|███████████████████████▏            | 64512000/100000000 [12:28<06:12, 95200.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "6100| MSE Loss 0.505 | L1 0.443:  65%|███████████████████████▏            | 64512000/100000000 [12:29<06:12, 95200.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "6100| MSE Loss 0.505 | L1 0.443:  66%|███████████████████████▌            | 65587200/100000000 [12:29<06:00, 95391.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "6200| MSE Loss 0.514 | L1 0.445:  66%|███████████████████████▌            | 65587200/100000000 [12:40<06:00, 95391.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "6200| MSE Loss 0.514 | L1 0.445:  67%|███████████████████████▉            | 66662400/100000000 [12:40<05:47, 95867.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "6300| MSE Loss 0.494 | L1 0.446:  67%|███████████████████████▉            | 66662400/100000000 [12:51<05:47, 95867.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "6300| MSE Loss 0.494 | L1 0.446:  68%|████████████████████████▍           | 67737600/100000000 [12:51<05:33, 96645.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "6400| MSE Loss 0.496 | L1 0.444:  68%|████████████████████████▍           | 67737600/100000000 [13:03<05:33, 96645.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "6400| MSE Loss 0.496 | L1 0.444:  69%|████████████████████████▊           | 68812800/100000000 [13:03<05:28, 95000.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "6400| MSE Loss 0.496 | L1 0.444:  69%|████████████████████████▊           | 68812800/100000000 [13:14<05:28, 95000.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "6500| MSE Loss 0.489 | L1 0.440:  69%|████████████████████████▊           | 68812800/100000000 [13:15<05:28, 95000.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "6500| MSE Loss 0.489 | L1 0.440:  70%|█████████████████████████▏          | 69888000/100000000 [13:15<05:23, 93062.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "6600| MSE Loss 0.494 | L1 0.438:  70%|█████████████████████████▏          | 69888000/100000000 [13:27<05:23, 93062.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "6600| MSE Loss 0.494 | L1 0.438:  71%|█████████████████████████▌          | 70963200/100000000 [13:27<05:13, 92541.03it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "6600| MSE Loss 0.494 | L1 0.438:  71%|█████████████████████████▌          | 70963200/100000000 [13:38<05:13, 92541.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "6700| MSE Loss 0.476 | L1 0.435:  71%|█████████████████████████▌          | 70963200/100000000 [13:40<05:13, 92541.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "6700| MSE Loss 0.476 | L1 0.435:  72%|█████████████████████████▉          | 72038400/100000000 [13:40<05:12, 89582.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "6800| MSE Loss 0.473 | L1 0.434:  72%|█████████████████████████▉          | 72038400/100000000 [13:51<05:12, 89582.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "6800| MSE Loss 0.473 | L1 0.434:  73%|██████████████████████████▎         | 73113600/100000000 [13:51<04:58, 90112.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "6900| MSE Loss 0.476 | L1 0.439:  73%|██████████████████████████▎         | 73113600/100000000 [14:03<04:58, 90112.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "6900| MSE Loss 0.476 | L1 0.439:  74%|██████████████████████████▋         | 74188800/100000000 [14:03<04:45, 90532.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "6900| MSE Loss 0.476 | L1 0.439:  74%|██████████████████████████▋         | 74188800/100000000 [14:14<04:45, 90532.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "7000| MSE Loss 0.483 | L1 0.438:  74%|██████████████████████████▋         | 74188800/100000000 [14:15<04:45, 90532.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "7000| MSE Loss 0.483 | L1 0.438:  75%|███████████████████████████         | 75264000/100000000 [14:15<04:31, 91014.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "7100| MSE Loss 0.454 | L1 0.437:  75%|███████████████████████████         | 75264000/100000000 [14:27<04:31, 91014.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "7100| MSE Loss 0.454 | L1 0.437:  76%|███████████████████████████▍        | 76339200/100000000 [14:27<04:19, 91266.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "7200| MSE Loss 0.469 | L1 0.433:  76%|███████████████████████████▍        | 76339200/100000000 [14:38<04:19, 91266.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "7200| MSE Loss 0.469 | L1 0.433:  77%|███████████████████████████▊        | 77414400/100000000 [14:38<04:06, 91638.37it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "7200| MSE Loss 0.469 | L1 0.433:  77%|███████████████████████████▊        | 77414400/100000000 [14:49<04:06, 91638.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "7300| MSE Loss 0.484 | L1 0.442:  77%|███████████████████████████▊        | 77414400/100000000 [14:49<04:06, 91638.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "7300| MSE Loss 0.484 | L1 0.442:  78%|████████████████████████████▎       | 78489600/100000000 [14:49<03:51, 92914.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "7400| MSE Loss 0.455 | L1 0.434:  78%|████████████████████████████▎       | 78489600/100000000 [15:00<03:51, 92914.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "7400| MSE Loss 0.455 | L1 0.434:  80%|████████████████████████████▋       | 79564800/100000000 [15:00<03:32, 96316.98it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/lob29g44/80005632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "7500| MSE Loss 0.453 | L1 0.431:  80%|████████████████████████████▋       | 79564800/100000000 [15:11<03:32, 96316.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "7500| MSE Loss 0.453 | L1 0.431:  81%|█████████████████████████████       | 80640000/100000000 [15:11<03:22, 95834.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "7600| MSE Loss 0.467 | L1 0.436:  81%|█████████████████████████████       | 80640000/100000000 [15:22<03:22, 95834.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "7600| MSE Loss 0.467 | L1 0.436:  82%|█████████████████████████████▍      | 81715200/100000000 [15:22<03:08, 96930.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "7700| MSE Loss 0.445 | L1 0.434:  82%|█████████████████████████████▍      | 81715200/100000000 [15:33<03:08, 96930.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "7700| MSE Loss 0.445 | L1 0.434:  83%|█████████████████████████████▊      | 82790400/100000000 [15:33<02:57, 96825.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "7800| MSE Loss 0.456 | L1 0.438:  83%|█████████████████████████████▊      | 82790400/100000000 [15:44<02:57, 96825.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "7800| MSE Loss 0.456 | L1 0.438:  84%|██████████████████████████████▏     | 83865600/100000000 [15:44<02:45, 97331.33it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "7800| MSE Loss 0.456 | L1 0.438:  84%|██████████████████████████████▏     | 83865600/100000000 [15:54<02:45, 97331.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "7900| MSE Loss 0.456 | L1 0.440:  84%|██████████████████████████████▏     | 83865600/100000000 [15:55<02:45, 97331.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "7900| MSE Loss 0.456 | L1 0.440:  85%|██████████████████████████████▌     | 84940800/100000000 [15:55<02:35, 97121.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "8000| MSE Loss 0.449 | L1 0.440:  85%|██████████████████████████████▌     | 84940800/100000000 [16:06<02:35, 97121.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "8000| MSE Loss 0.449 | L1 0.440:  86%|██████████████████████████████▉     | 86016000/100000000 [16:06<02:23, 97583.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "8100| MSE Loss 0.431 | L1 0.431:  86%|██████████████████████████████▉     | 86016000/100000000 [16:16<02:23, 97583.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "8100| MSE Loss 0.431 | L1 0.431:  87%|███████████████████████████████▎    | 87091200/100000000 [16:16<02:10, 98836.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "8200| MSE Loss 0.424 | L1 0.432:  87%|███████████████████████████████▎    | 87091200/100000000 [16:28<02:10, 98836.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "8200| MSE Loss 0.424 | L1 0.432:  88%|███████████████████████████████▋    | 88166400/100000000 [16:28<02:00, 97995.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "8300| MSE Loss 0.448 | L1 0.434:  88%|███████████████████████████████▋    | 88166400/100000000 [16:39<02:00, 97995.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "8300| MSE Loss 0.448 | L1 0.434:  89%|████████████████████████████████▏   | 89241600/100000000 [16:39<01:50, 97428.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "8300| MSE Loss 0.448 | L1 0.434:  89%|████████████████████████████████▏   | 89241600/100000000 [16:49<01:50, 97428.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "8400| MSE Loss 0.431 | L1 0.434:  89%|████████████████████████████████▏   | 89241600/100000000 [16:51<01:50, 97428.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "8400| MSE Loss 0.431 | L1 0.434:  90%|████████████████████████████████▌   | 90316800/100000000 [16:51<01:43, 93839.07it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "8500| MSE Loss 0.419 | L1 0.434:  90%|████████████████████████████████▌   | 90316800/100000000 [17:04<01:43, 93839.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "8500| MSE Loss 0.419 | L1 0.434:  91%|████████████████████████████████▉   | 91392000/100000000 [17:04<01:34, 91352.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "8500| MSE Loss 0.419 | L1 0.434:  91%|████████████████████████████████▉   | 91392000/100000000 [17:15<01:34, 91352.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "8600| MSE Loss 0.398 | L1 0.427:  91%|████████████████████████████████▉   | 91392000/100000000 [17:16<01:34, 91352.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "8600| MSE Loss 0.398 | L1 0.427:  92%|█████████████████████████████████▎  | 92467200/100000000 [17:16<01:23, 90214.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "8700| MSE Loss 0.392 | L1 0.431:  92%|█████████████████████████████████▎  | 92467200/100000000 [17:28<01:23, 90214.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "8700| MSE Loss 0.392 | L1 0.431:  94%|█████████████████████████████████▋  | 93542400/100000000 [17:28<01:11, 90114.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "8700| MSE Loss 0.392 | L1 0.431:  94%|█████████████████████████████████▋  | 93542400/100000000 [17:39<01:11, 90114.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "8800| MSE Loss 0.420 | L1 0.432:  94%|█████████████████████████████████▋  | 93542400/100000000 [17:40<01:11, 90114.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "8800| MSE Loss 0.420 | L1 0.432:  95%|██████████████████████████████████  | 94617600/100000000 [17:40<00:59, 90747.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "8800| MSE Loss 0.420 | L1 0.432:  95%|██████████████████████████████████  | 94617600/100000000 [17:50<00:59, 90747.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "8900| MSE Loss 0.417 | L1 0.432:  95%|██████████████████████████████████  | 94617600/100000000 [17:52<00:59, 90747.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "8900| MSE Loss 0.417 | L1 0.432:  96%|██████████████████████████████████▍ | 95692800/100000000 [17:52<00:47, 90569.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "9000| MSE Loss 0.409 | L1 0.432:  96%|██████████████████████████████████▍ | 95692800/100000000 [18:04<00:47, 90569.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "9000| MSE Loss 0.409 | L1 0.432:  97%|██████████████████████████████████▊ | 96768000/100000000 [18:04<00:35, 90256.80it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "9000| MSE Loss 0.409 | L1 0.432:  97%|██████████████████████████████████▊ | 96768000/100000000 [18:15<00:35, 90256.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "9100| MSE Loss 0.404 | L1 0.427:  97%|██████████████████████████████████▊ | 96768000/100000000 [18:16<00:35, 90256.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "9100| MSE Loss 0.404 | L1 0.427:  98%|███████████████████████████████████▏| 97843200/100000000 [18:16<00:23, 89908.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "9200| MSE Loss 0.395 | L1 0.425:  98%|███████████████████████████████████▏| 97843200/100000000 [18:26<00:23, 89908.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "9200| MSE Loss 0.395 | L1 0.425:  99%|███████████████████████████████████▌| 98918400/100000000 [18:26<00:11, 92681.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "9300| MSE Loss 0.398 | L1 0.429:  99%|███████████████████████████████████▌| 98918400/100000000 [18:37<00:11, 92681.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "9300| MSE Loss 0.398 | L1 0.429: 100%|███████████████████████████████████▉| 99993600/100000000 [18:37<00:00, 93958.42it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving $HOME/persistent-storage/tracr_saes/parens_sae_checkpoints/lob29g44/final_100004352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9300| MSE Loss 0.398 | L1 0.429: 100%|███████████████████████████████████▉| 99993600/100000000 [18:38<00:00, 89389.85it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181b3d44493443cebba8dba3e99b3529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.662 MB of 0.662 MB uploaded (0.009 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 1.3%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/current_learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>▁█▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/explained_variance</td><td>▁▆▇▇▇███████████████████████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>█▅▃▃▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l0</td><td>█████████████▆█▅▆█▆▄▆█▃▅▅▇▁▄▁▃▃▂▄▃▃▃▃▃▃▄</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>▁▄▇█</td></tr><tr><td>sparsity/below_1e-5</td><td>█▄▁▂</td></tr><tr><td>sparsity/below_1e-6</td><td>█▂▁▃</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▁▁▁▁▁▅▅▁▁▁▁▅▁▁▅▁▁█▁▁▁▁▁▁▅▁▁▁▅▁▁▁▁▁</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▅▅▆▆▄▅▅▇█▇▇▇▇█▆▆▅▆▇▆▆▆▆▆▅▅▄▄▄▄▅▅▅▅▆▅▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>0.1</td></tr><tr><td>details/current_learning_rate</td><td>0.0003</td></tr><tr><td>details/n_training_tokens</td><td>99993600</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.0</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.00622</td></tr><tr><td>losses/l1_loss</td><td>4.29483</td></tr><tr><td>losses/mse_loss</td><td>0.39798</td></tr><tr><td>losses/overall_loss</td><td>0.83368</td></tr><tr><td>metrics/explained_variance</td><td>0.96611</td></tr><tr><td>metrics/explained_variance_std</td><td>0.02908</td></tr><tr><td>metrics/l0</td><td>3.9189</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-3.88106</td></tr><tr><td>sparsity/below_1e-5</td><td>100</td></tr><tr><td>sparsity/below_1e-6</td><td>35</td></tr><tr><td>sparsity/dead_features</td><td>0</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>147.58594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">256-topk-4-LR-0.0003-Tokens-1.000e+08</strong> at: <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/mh01kdsc' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/mh01kdsc</a><br/> View project at: <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a><br/>Synced 5 W&B file(s), 0 media file(s), 15 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240711_221648-mh01kdsc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sae_utils import train_sae\n",
    "\n",
    "#I need to be able to tell the SAE to ignore certain tokens during training.\n",
    "sae, store = train_sae(ll_model, sae_lens_cfg, dataset.shuffle(seed=101))#, ignore_tokens=[])#2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb01f50-1ef9-4866-9a4e-581a7f56cce8",
   "metadata": {},
   "source": [
    "# SAELens -- gated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a37b51c0-f3e7-4d62-8aa8-580e15d589b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture gated\n",
      "use_ghost_grads False\n",
      "d_in 64\n",
      "wandb_project benchmark_saes\n",
      "Run name: 256-L1-0.2-LR-0.0003-Tokens-1.000e+08\n",
      "n_tokens_per_buffer (millions): 0.02688\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.00064\n",
      "Total training steps: 9300\n",
      "Total wandb updates: 930\n",
      "n_tokens_per_feature_sampling_window (millions): 903.168\n",
      "n_tokens_per_dead_feature_window (millions): 451.584\n",
      "We will reset the sparsity calculation 4 times.\n",
      "Number tokens in sparsity calculation window: 2.15e+07\n"
     ]
    }
   ],
   "source": [
    "from sae_utils import make_gated_sae_lens_config\n",
    "\n",
    "#seems a lot better than top-k in terms of L0 and MSE.\n",
    "sae_lens_cfg = make_gated_sae_lens_config(\n",
    "    model=ll_model, \n",
    "    hook_name=\"blocks.0.mlp.hook_post\", \n",
    "    hook_layer=0, \n",
    "    l1_coefficient=0.2,\n",
    "    l1_warm_up_steps = 0,\n",
    "    context_size=ll_model.cfg.n_ctx,\n",
    "    d_in=ll_model.cfg.d_mlp,\n",
    "    device = 'cuda',\n",
    "    checkpoint_path = f\"$HOME/persistent-storage/tracr_saes/parens_sae_checkpoints\",\n",
    "    wandb_project =  \"benchmark_saes\",\n",
    "    training_tokens = 100_000_000,\n",
    "    batch_size = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694da2b-25b0-4984-a9a1-05e1db025b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the training dataset contains fewer samples (97472) than the number of samples required by your training configuration (100000000). This will result in multiple training epochs and some samples being used more than once.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:jmdwk0hp) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.409 MB of 0.409 MB uploaded (0.004 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 2.2%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/current_learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/explained_variance</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>metrics/explained_variance_std</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l0</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▂▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁██</td></tr><tr><td>sparsity/below_1e-6</td><td>▁▆█</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▂▄▄▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>0.1</td></tr><tr><td>details/current_learning_rate</td><td>0.0003</td></tr><tr><td>details/n_training_tokens</td><td>69350400</td></tr><tr><td>losses/auxiliary_reconstruction_loss</td><td>0.06149</td></tr><tr><td>losses/ghost_grad_loss</td><td>0.0</td></tr><tr><td>losses/l1_loss</td><td>5.01996</td></tr><tr><td>losses/mse_loss</td><td>0.05029</td></tr><tr><td>losses/overall_loss</td><td>0.61377</td></tr><tr><td>metrics/explained_variance</td><td>0.99557</td></tr><tr><td>metrics/explained_variance_std</td><td>0.0037</td></tr><tr><td>metrics/l0</td><td>20.52381</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-1.59449</td></tr><tr><td>sparsity/below_1e-5</td><td>10</td></tr><tr><td>sparsity/below_1e-6</td><td>10</td></tr><tr><td>sparsity/dead_features</td><td>8</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>161.46094</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">256-gated-L1-0.1-LR-0.0003-Tokens-1.000e+08</strong> at: <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/jmdwk0hp' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/jmdwk0hp</a><br/> View project at: <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240711_230207-jmdwk0hp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:jmdwk0hp). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b2673a6d8d49968119cc5f5500e8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113975362645256, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/quick-experiments/wandb/run-20240711_231450-qpswq6wq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evanhanders/benchmark_saes/runs/qpswq6wq' target=\"_blank\">256-gated-L1-0.2-LR-0.0003-Tokens-1.000e+08</a></strong> to <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evanhanders/benchmark_saes' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evanhanders/benchmark_saes/runs/qpswq6wq' target=\"_blank\">https://wandb.ai/evanhanders/benchmark_saes/runs/qpswq6wq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SAE:   0%|                                                                         | 0/100000000 [00:00<?, ?it/s]\u001b[A/opt/venv/lib/python3.10/site-packages/sae_lens/training/activations_store.py:264: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yield torch.tensor(\n",
      "\n",
      "100| MSE Loss 2.448 | L1 4.634:   0%|                                                       | 0/100000000 [00:10<?, ?it/s]\u001b[A\n",
      "100| MSE Loss 2.448 | L1 4.634:   1%|▍                                    | 1075200/100000000 [00:10<15:49, 104151.21it/s]\u001b[A\n",
      "200| MSE Loss 0.694 | L1 2.562:   1%|▍                                    | 1075200/100000000 [00:21<15:49, 104151.21it/s]\u001b[A\n",
      "200| MSE Loss 0.694 | L1 2.562:   2%|▊                                    | 2150400/100000000 [00:21<16:07, 101136.19it/s]\u001b[A\n",
      "300| MSE Loss 0.416 | L1 2.088:   2%|▊                                    | 2150400/100000000 [00:31<16:07, 101136.19it/s]\u001b[A\n",
      "300| MSE Loss 0.416 | L1 2.088:   3%|█▏                                   | 3225600/100000000 [00:31<15:58, 100922.02it/s]\u001b[A\n",
      "400| MSE Loss 0.311 | L1 1.833:   3%|█▏                                   | 3225600/100000000 [00:43<15:58, 100922.02it/s]\u001b[A\n",
      "400| MSE Loss 0.311 | L1 1.833:   4%|█▋                                    | 4300800/100000000 [00:43<16:05, 99086.69it/s]\u001b[A\n",
      "400| MSE Loss 0.311 | L1 1.833:   4%|█▋                                    | 4300800/100000000 [00:54<16:05, 99086.69it/s]\u001b[A\n",
      "500| MSE Loss 0.262 | L1 1.676:   4%|█▋                                    | 4300800/100000000 [00:54<16:05, 99086.69it/s]\u001b[A\n",
      "500| MSE Loss 0.262 | L1 1.676:   5%|██                                    | 5376000/100000000 [00:54<16:24, 96121.05it/s]\u001b[A\n",
      "600| MSE Loss 0.224 | L1 1.554:   5%|██                                    | 5376000/100000000 [01:06<16:24, 96121.05it/s]\u001b[A\n",
      "600| MSE Loss 0.224 | L1 1.554:   6%|██▍                                   | 6451200/100000000 [01:06<16:37, 93823.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All samples in the training dataset have been exhausted, we are now beginning a new epoch with the same samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "700| MSE Loss 0.197 | L1 1.472:   6%|██▍                                   | 6451200/100000000 [01:18<16:37, 93823.92it/s]\u001b[A\n",
      "700| MSE Loss 0.197 | L1 1.472:   8%|██▊                                   | 7526400/100000000 [01:18<16:37, 92669.41it/s]\u001b[A\n",
      "700| MSE Loss 0.197 | L1 1.472:   8%|██▊                                   | 7526400/100000000 [01:29<16:37, 92669.41it/s]\u001b[A\n",
      "800| MSE Loss 0.186 | L1 1.409:   8%|██▊                                   | 7526400/100000000 [01:30<16:37, 92669.41it/s]\u001b[A\n",
      "800| MSE Loss 0.186 | L1 1.409:   9%|███▎                                  | 8601600/100000000 [01:30<16:36, 91726.82it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from sae_utils import train_sae\n",
    "\n",
    "sae, store = train_sae(ll_model, sae_lens_cfg, dataset.shuffle(seed=101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1ce2f-d424-4776-af4e-bc5b0f7880d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
