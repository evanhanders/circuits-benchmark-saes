{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from iit.model_pairs.strict_iit_model_pair import StrictIITModelPair\n",
    "\n",
    "from poly_bench.cases.paren_checker import HighLevelParensBalanceChecker, BalancedParensDataset\n",
    "from poly_bench.cases.left_greater import HighLevelLeftGreater, LeftGreaterDataset\n",
    "from poly_bench.cases.duplicate_remover import HighLevelDuplicateRemover, DuplicateRemoverDataset\n",
    "from poly_bench.cases.unique_extractor import HighLevelUniqueExtractor, UniqueExtractorDataset\n",
    "from poly_bench.io import save_model_to_dir, save_to_hf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "n_samples = 10_000\n",
    "training_args = {\n",
    "    \"batch_size\": 256,\n",
    "    \"num_workers\": 0,\n",
    "    \"use_single_loss\": True,\n",
    "    \"behavior_weight\": 0.4, #basically doubles the strict weight's job.\n",
    "    \"iit_weight\": 1.,\n",
    "    \"strict_weight\": 0.4,\n",
    "    \"clip_grad_norm\": 1.0,\n",
    "    \"early_stop\" : True,\n",
    "    \"lr_scheduler\": torch.optim.lr_scheduler.LinearLR,\n",
    "    \"scheduler_kwargs\": dict(start_factor=1, end_factor=0.2, total_iters=int(n_epochs)),\n",
    "    \"optimizer_kwargs\": dict(lr=1e-3, betas=(0.9, 0.9)),\n",
    "    \"scheduler_val_metric\": [\"val/accuracy\", \"val/IIA\"], #for ReduceLRonPlateau\n",
    "    \"scheduler_mode\": \"max\", #for ReduceLRonPlateau\n",
    "    \"siit_sampling\" : \"sample_all\",\n",
    "    \"val_IIA_sampling\": \"all\", # random or all\n",
    "    \"seed\" : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paren Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making IIT dataset\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelParensBalanceChecker()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = BalancedParensDataset(N_samples=n_samples, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 2, 3, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2] [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "i = 6\n",
    "print(dataset.get_dataset()[i]['tokens'], dataset.get_dataset()[i]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7007, 4)\n",
      "[[0, 2, 2, 3, 3, 3, 2, 2, 3, 3, 2, 3, 2, 2, 3], [0, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3], [0, 3, 2, 2, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 3], [0, 3, 2, 2, 3, 3, 3, 2, 3, 3, 3, 3, 2, 2, 2], [0, 2, 3, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 2, 2], [0, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2], [0, 2, 2, 3, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2], [0, 2, 3, 3, 3, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2], [0, 2, 2, 2, 2, 3, 3, 2, 3, 2, 2, 3, 2, 2, 2], [0, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 3]]\n",
      "[[[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.get_dataset().shape)\n",
    "print(dataset.get_dataset()[:10]['tokens'])\n",
    "print(dataset.get_dataset()[:10]['labels'])\n",
    "for i in range(10):\n",
    "    tokens, labels, hl_outputs = dataset.get_dataset()[i]['tokens'], dataset.get_dataset()[i]['labels'], hl_model((torch.tensor(dataset.get_dataset()[i]['tokens'])[None,:], None, None))\n",
    "    nonzero = (torch.tensor(labels) - hl_outputs[0].cpu()).nonzero()\n",
    "    if nonzero.numel() > 0:\n",
    "        print(tokens, torch.unique(nonzero[:,0]))\n",
    "        bad_indices = torch.unique(nonzero[:,0]).tolist()\n",
    "        for idx in bad_indices:\n",
    "            print(labels[idx], hl_outputs[0,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4473, 0.4485])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [torch.tensor(0.4473), torch.tensor(0.4485)]\n",
    "torch.stack(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dfbfb2b12b4bc8b50c7a25c6f7db54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a35ff5235194edb8487c9510796f54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.6369, train/behavior_loss: 0.2491, train/strict_loss: 0.0997, val/iit_loss: 0.4413, val/IIA: 95.80%, val/accuracy: 95.82%, val/strict_accuracy: 95.82%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.3699, train/behavior_loss: 0.1422, train/strict_loss: 0.0569, val/iit_loss: 0.2894, val/IIA: 95.76%, val/accuracy: 95.76%, val/strict_accuracy: 95.76%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.2525, train/behavior_loss: 0.0887, train/strict_loss: 0.0359, val/iit_loss: 0.2065, val/IIA: 96.08%, val/accuracy: 97.42%, val/strict_accuracy: 97.05%\n",
      "Epoch 4: lr: 9.68e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1947, train/behavior_loss: 0.0579, train/strict_loss: 0.0250, val/iit_loss: 0.1687, val/IIA: 96.26%, val/accuracy: 97.41%, val/strict_accuracy: 97.34%\n",
      "Epoch 5: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1808, train/behavior_loss: 0.0485, train/strict_loss: 0.0219, val/iit_loss: 0.1468, val/IIA: 96.19%, val/accuracy: 97.41%, val/strict_accuracy: 97.33%\n",
      "Epoch 6: lr: 9.52e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1300, train/behavior_loss: 0.0375, train/strict_loss: 0.0187, val/iit_loss: 0.1278, val/IIA: 96.32%, val/accuracy: 97.43%, val/strict_accuracy: 97.35%\n",
      "Epoch 7: lr: 9.44e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1335, train/behavior_loss: 0.0318, train/strict_loss: 0.0178, val/iit_loss: 0.1193, val/IIA: 96.62%, val/accuracy: 97.49%, val/strict_accuracy: 97.34%\n",
      "Epoch 8: lr: 9.36e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1254, train/behavior_loss: 0.0327, train/strict_loss: 0.0169, val/iit_loss: 0.1069, val/IIA: 96.78%, val/accuracy: 98.25%, val/strict_accuracy: 98.06%\n",
      "Epoch 9: lr: 9.28e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0941, train/behavior_loss: 0.0212, train/strict_loss: 0.0146, val/iit_loss: 0.1108, val/IIA: 96.83%, val/accuracy: 98.27%, val/strict_accuracy: 97.70%\n",
      "Epoch 10: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0899, train/behavior_loss: 0.0173, train/strict_loss: 0.0157, val/iit_loss: 0.0832, val/IIA: 97.38%, val/accuracy: 99.54%, val/strict_accuracy: 99.19%\n",
      "Epoch 11: lr: 9.12e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0918, train/behavior_loss: 0.0109, train/strict_loss: 0.0126, val/iit_loss: 0.0544, val/IIA: 98.27%, val/accuracy: 99.52%, val/strict_accuracy: 99.39%\n",
      "Epoch 12: lr: 9.04e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0690, train/behavior_loss: 0.0146, train/strict_loss: 0.0121, val/iit_loss: 0.0504, val/IIA: 97.99%, val/accuracy: 98.74%, val/strict_accuracy: 98.60%\n",
      "Epoch 13: lr: 8.96e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0437, train/behavior_loss: 0.0083, train/strict_loss: 0.0071, val/iit_loss: 0.0544, val/IIA: 98.24%, val/accuracy: 98.93%, val/strict_accuracy: 98.82%\n",
      "Epoch 14: lr: 8.88e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0403, train/behavior_loss: 0.0079, train/strict_loss: 0.0052, val/iit_loss: 0.0620, val/IIA: 97.66%, val/accuracy: 98.75%, val/strict_accuracy: 98.70%\n",
      "Epoch 15: lr: 8.80e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0300, train/behavior_loss: 0.0057, train/strict_loss: 0.0039, val/iit_loss: 0.0358, val/IIA: 98.83%, val/accuracy: 99.58%, val/strict_accuracy: 99.53%\n",
      "Epoch 16: lr: 8.72e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0469, train/behavior_loss: 0.0076, train/strict_loss: 0.0036, val/iit_loss: 0.0203, val/IIA: 99.28%, val/accuracy: 99.93%, val/strict_accuracy: 99.91%\n",
      "Epoch 17: lr: 8.64e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0435, train/behavior_loss: 0.0044, train/strict_loss: 0.0028, val/iit_loss: 0.0403, val/IIA: 98.51%, val/accuracy: 99.73%, val/strict_accuracy: 99.48%\n",
      "Epoch 18: lr: 8.56e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0227, train/behavior_loss: 0.0031, train/strict_loss: 0.0025, val/iit_loss: 0.0147, val/IIA: 99.57%, val/accuracy: 100.00%, val/strict_accuracy: 99.99%\n",
      "Epoch 19: lr: 8.48e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0107, train/behavior_loss: 0.0011, train/strict_loss: 0.0013, val/iit_loss: 0.0133, val/IIA: 99.46%, val/accuracy: 100.00%, val/strict_accuracy: 99.97%\n",
      "Epoch 20: lr: 8.40e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0105, train/behavior_loss: 0.0008, train/strict_loss: 0.0007, val/iit_loss: 0.0204, val/IIA: 99.46%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n",
      "Epoch 21: lr: 8.32e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0092, train/behavior_loss: 0.0003, train/strict_loss: 0.0002, val/iit_loss: 0.0197, val/IIA: 99.33%, val/accuracy: 99.87%, val/strict_accuracy: 99.80%\n",
      "Epoch 22: lr: 8.24e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0207, train/behavior_loss: 0.0034, train/strict_loss: 0.0018, val/iit_loss: 0.0090, val/IIA: 99.65%, val/accuracy: 100.00%, val/strict_accuracy: 99.98%\n",
      "Epoch 23: lr: 8.16e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0140, train/behavior_loss: 0.0023, train/strict_loss: 0.0013, val/iit_loss: 0.0157, val/IIA: 99.62%, val/accuracy: 99.99%, val/strict_accuracy: 99.99%\n",
      "Epoch 24: lr: 8.08e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0111, train/behavior_loss: 0.0012, train/strict_loss: 0.0010, val/iit_loss: 0.0039, val/IIA: 99.89%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n",
      "Epoch 25: lr: 8.00e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0036, train/behavior_loss: 0.0002, train/strict_loss: 0.0002, val/iit_loss: 0.0018, val/IIA: 99.96%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n",
      "Epoch 26: lr: 7.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0044, train/behavior_loss: 0.0011, train/strict_loss: 0.0008, val/iit_loss: 0.0121, val/IIA: 99.77%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n",
      "Epoch 27: lr: 7.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0085, train/behavior_loss: 0.0001, train/strict_loss: 0.0001, val/iit_loss: 0.0004, val/IIA: 99.99%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n",
      "Epoch 28: lr: 7.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0010, train/behavior_loss: 0.0001, train/strict_loss: 0.0001, val/iit_loss: 0.0027, val/IIA: 99.91%, val/accuracy: 100.00%, val/strict_accuracy: 99.99%\n",
      "Epoch 29: lr: 7.68e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0018, train/behavior_loss: 0.0001, train/strict_loss: 0.0001, val/iit_loss: 0.0082, val/IIA: 99.70%, val/accuracy: 99.82%, val/strict_accuracy: 99.84%\n",
      "Epoch 30: lr: 7.60e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0009, train/behavior_loss: 0.0001, train/strict_loss: 0.0000, val/iit_loss: 0.0001, val/IIA: 100.00%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n",
      "Epoch 31: lr: 7.52e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0014, train/behavior_loss: 0.0000, train/strict_loss: 0.0001, val/iit_loss: 0.0001, val/IIA: 100.00%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n",
      "Epoch 32: lr: 7.44e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0039, train/behavior_loss: 0.0001, train/strict_loss: 0.0001, val/iit_loss: 0.0018, val/IIA: 99.94%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n",
      "Epoch 33: lr: 7.36e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0010, train/behavior_loss: 0.0001, train/strict_loss: 0.0002, val/iit_loss: 0.0006, val/IIA: 99.98%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n",
      "Epoch 34: lr: 7.28e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0003, train/behavior_loss: 0.0000, train/strict_loss: 0.0000, val/iit_loss: 0.0005, val/IIA: 99.98%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n",
      "Epoch 35: lr: 7.20e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0021, train/behavior_loss: 0.0002, train/strict_loss: 0.0003, val/iit_loss: 0.0016, val/IIA: 99.96%, val/accuracy: 100.00%, val/strict_accuracy: 99.99%\n",
      "Epoch 36: lr: 7.12e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0029, train/behavior_loss: 0.0008, train/strict_loss: 0.0003, val/iit_loss: 0.0019, val/IIA: 99.92%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n",
      "Epoch 37: lr: 7.04e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0026, train/behavior_loss: 0.0004, train/strict_loss: 0.0003, val/iit_loss: 0.0001, val/IIA: 100.00%, val/accuracy: 100.00%, val/strict_accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "ll_model = hl_model.get_ll_model(seed=42).to(hl_model.device)\n",
    "ll_model.device = hl_model.device\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('saved_models/parens_checker_model')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_to_dir(ll_model, f\"./saved_models/{str(hl_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 2, 2, 3, 3, 3, 3, 2, 2, 3, 3, 2, 2, 2])\n",
      "tensor([[[0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.]]], device='mps:0', grad_fn=<RoundBackward0>)\n",
      "tensor([[[0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.]]], device='mps:0')\n",
      "[[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ry/qny1f95136l2lpppg_d78n6c0000gq/T/ipykernel_30222/775366424.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(hl_model((torch.tensor(input)[None,:], None, None)))\n"
     ]
    }
   ],
   "source": [
    "i = 6\n",
    "input = torch.tensor(dataset.get_dataset()[i]['tokens'])\n",
    "print(input)\n",
    "print(torch.round(torch.nn.functional.softmax(model_pair.ll_model.forward(input), dim=-1)))\n",
    "print(hl_model((torch.tensor(input)[None,:], None, None))) \n",
    "print(dataset.get_dataset()[i]['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left > Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making IIT dataset\n",
      "{'input_hook': HookPoint(), 'paren_counts_hook': HookPoint(), 'mlp0_hook': HookPoint()}\n",
      "[input_hook, paren_counts_hook, mlp0_hook]\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelLeftGreater()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = LeftGreaterDataset(N_samples=n_samples, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()\n",
    "print(hl_model.hook_dict)\n",
    "print(list(corr.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bdb4d233f045a789bf61c2fd0ab8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7395db4ef42c48b8b5586f037e860c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 1.1604, train/behavior_loss: 0.4518, train/strict_loss: 0.1816, val/iit_loss: 1.0236, val/IIA: 56.51%, val/accuracy: 66.84%, val/strict_accuracy: 64.26%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.9398, train/behavior_loss: 0.3593, train/strict_loss: 0.1456, val/iit_loss: 0.8540, val/IIA: 67.08%, val/accuracy: 80.21%, val/strict_accuracy: 76.87%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m ll_model\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m hl_model\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m      4\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mhl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# optimizer_cls=torch.optim.AdamW,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:281\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    279\u001b[0m     batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 281\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval_epoch(test_loader, loss_fn)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:330\u001b[0m, in \u001b[0;36mBaseModelPair._run_train_epoch\u001b[0;34m(self, loader, loss_fn, optimizer, pbar)\u001b[0m\n\u001b[1;32m    327\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_metrics()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    329\u001b[0m     train_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:132\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_train_step\u001b[0;34m(self, base_input, ablation_input, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_single_loss:\n\u001b[1;32m    131\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m iit_loss \u001b[38;5;241m+\u001b[39m behavior_loss \u001b[38;5;241m+\u001b[39m siit_loss\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_on_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/iit_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: iit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/behavior_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: behavior_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/strict_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: siit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    138\u001b[0m }\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:65\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.step_on_loss\u001b[0;34m(self, loss, optimizer)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_on_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss: Tensor, optimizer: t\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_fn()\n\u001b[1;32m     67\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = hl_model.get_ll_model(seed=42).to(hl_model.device)\n",
    "ll_model.device = hl_model.device\n",
    "\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    # optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('saved_models/left_greater_model')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_to_dir(ll_model, f\"./saved_models/{str(hl_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from poly_bench.utils import load_from_hf\n",
    "# loaded_model = load_from_hf(model_name=\"left_greater_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate remover\n",
    "case 19 in circuits-bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making IIT dataset\n",
      "{'input_hook': HookPoint(), 'prev_token_hook': HookPoint(), 'prev_equal_hook': HookPoint(), 'output_hook': HookPoint()}\n",
      "[input_hook, prev_token_hook, prev_equal_hook, output_hook]\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelDuplicateRemover()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = DuplicateRemoverDataset(N_samples=n_samples, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()\n",
    "print(hl_model.hook_dict)\n",
    "print(list(corr.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36afa0e23bcf4d699f3ea8353766a5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97054b18e8f43be8b62e83f834f3613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 1.2145, train/behavior_loss: 0.4685, train/strict_loss: 0.1875, val/iit_loss: 0.9727, val/IIA: 71.06%, val/accuracy: 71.06%, val/strict_accuracy: 71.06%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.8526, train/behavior_loss: 0.3247, train/strict_loss: 0.1334, val/iit_loss: 0.7254, val/IIA: 77.13%, val/accuracy: 83.15%, val/strict_accuracy: 81.46%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m ll_model\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m hl_model\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m      4\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mhl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# optimizer_cls=torch.optim.AdamW,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:281\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    279\u001b[0m     batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 281\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval_epoch(test_loader, loss_fn)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:330\u001b[0m, in \u001b[0;36mBaseModelPair._run_train_epoch\u001b[0;34m(self, loader, loss_fn, optimizer, pbar)\u001b[0m\n\u001b[1;32m    327\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_metrics()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    329\u001b[0m     train_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:132\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_train_step\u001b[0;34m(self, base_input, ablation_input, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_single_loss:\n\u001b[1;32m    131\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m iit_loss \u001b[38;5;241m+\u001b[39m behavior_loss \u001b[38;5;241m+\u001b[39m siit_loss\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_on_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/iit_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: iit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/behavior_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: behavior_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/strict_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: siit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    138\u001b[0m }\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:65\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.step_on_loss\u001b[0;34m(self, loss, optimizer)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_on_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss: Tensor, optimizer: t\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_fn()\n\u001b[1;32m     67\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = hl_model.get_ll_model(seed=42).to(hl_model.device)\n",
    "ll_model.device = hl_model.device\n",
    "\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('saved_models/duplicate_remover_model')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_to_dir(ll_model, f\"./saved_models/{str(hl_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making IIT dataset\n",
      "{'input_hook': HookPoint(), 'counter_head': HookPoint(), 'appeared_mlp': HookPoint(), 'mask_mlp': HookPoint(), 'output_mlp': HookPoint()}\n",
      "[input_hook, counter_head, appeared_mlp, mask_mlp, output_mlp]\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelUniqueExtractor()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = UniqueExtractorDataset(N_samples=n_samples, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()\n",
    "print(hl_model.hook_dict)\n",
    "print(list(corr.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb922559e2ed4497ac3827774369a1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34bd6b083384b2ba29ec7bc802c8bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.7626, train/behavior_loss: 0.2869, train/strict_loss: 0.1154, val/iit_loss: 0.5199, val/IIA: 88.10%, val/accuracy: 92.56%, val/strict_accuracy: 92.56%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.3963, train/behavior_loss: 0.1192, train/strict_loss: 0.0567, val/iit_loss: 0.2905, val/IIA: 93.55%, val/accuracy: 98.89%, val/strict_accuracy: 98.52%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.2357, train/behavior_loss: 0.0508, train/strict_loss: 0.0243, val/iit_loss: 0.1563, val/IIA: 96.20%, val/accuracy: 98.29%, val/strict_accuracy: 98.12%\n",
      "Epoch 4: lr: 9.68e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1216, train/behavior_loss: 0.0272, train/strict_loss: 0.0139, val/iit_loss: 0.0972, val/IIA: 97.75%, val/accuracy: 99.56%, val/strict_accuracy: 99.51%\n",
      "Epoch 5: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1068, train/behavior_loss: 0.0139, train/strict_loss: 0.0075, val/iit_loss: 0.0802, val/IIA: 97.85%, val/accuracy: 99.44%, val/strict_accuracy: 99.41%\n",
      "Epoch 6: lr: 9.52e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0600, train/behavior_loss: 0.0091, train/strict_loss: 0.0050, val/iit_loss: 0.0844, val/IIA: 97.85%, val/accuracy: 99.52%, val/strict_accuracy: 99.46%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m ll_model\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m hl_model\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m      4\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mhl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# optimizer_cls=torch.optim.AdamW,\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:281\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    279\u001b[0m     batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 281\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval_epoch(test_loader, loss_fn)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:330\u001b[0m, in \u001b[0;36mBaseModelPair._run_train_epoch\u001b[0;34m(self, loader, loss_fn, optimizer, pbar)\u001b[0m\n\u001b[1;32m    327\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_metrics()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    329\u001b[0m     train_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:132\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_train_step\u001b[0;34m(self, base_input, ablation_input, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_single_loss:\n\u001b[1;32m    131\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m iit_loss \u001b[38;5;241m+\u001b[39m behavior_loss \u001b[38;5;241m+\u001b[39m siit_loss\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_on_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/iit_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: iit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/behavior_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: behavior_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/strict_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: siit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    138\u001b[0m }\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:65\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.step_on_loss\u001b[0;34m(self, loss, optimizer)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_on_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss: Tensor, optimizer: t\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_fn()\n\u001b[1;32m     67\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = hl_model.get_ll_model(seed=42).to(hl_model.device)\n",
    "ll_model.device = hl_model.device\n",
    "\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    # optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('saved_models/unique_extractor_model')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_to_dir(ll_model, f\"./saved_models/{str(hl_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3497a1b6bec9415db49f4283e8aa3a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df67e3fe8a594ff495352588962e653e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/10.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666d2422bb874a23ad7398ec39ef0d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/68.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c1d074f6114a1e866b9a59fb393c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbbf1dab02241049ddebe987667e0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e85cba3f34d475b9a104f8b2e619f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/161k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_to_hf(local_dir=\"saved_models\", message=\"pushes all monosemantic models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
