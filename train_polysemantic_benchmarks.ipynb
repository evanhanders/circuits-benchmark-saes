{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from iit.model_pairs.strict_iit_model_pair import StrictIITModelPair\n",
    "\n",
    "from poly_bench.cases.paren_checker import HighLevelParensBalanceChecker, BalancedParensDataset\n",
    "from poly_bench.cases.left_greater import HighLevelLeftGreater, LeftGreaterDataset\n",
    "from poly_bench.cases.duplicate_remover import HighLevelDuplicateRemover, DuplicateRemoverDataset\n",
    "from poly_bench.cases.unique_extractor import HighLevelUniqueExtractor, UniqueExtractorDataset\n",
    "from poly_bench.poly_hl_model import PolyHLModel, PolyModelDataset\n",
    "from poly_bench.io import save_poly_model_to_dir, save_to_hf\n",
    "\n",
    "Case0 = HighLevelDuplicateRemover\n",
    "Case1 = HighLevelLeftGreater\n",
    "Case2 = HighLevelParensBalanceChecker\n",
    "Case3 = HighLevelUniqueExtractor\n",
    "\n",
    "dataset_mapping = {\n",
    "    HighLevelDuplicateRemover: DuplicateRemoverDataset,\n",
    "    HighLevelLeftGreater: LeftGreaterDataset,\n",
    "    HighLevelParensBalanceChecker: BalancedParensDataset,\n",
    "    HighLevelUniqueExtractor: UniqueExtractorDataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "n_samples = 10_000\n",
    "training_args = {\n",
    "    \"batch_size\": 256,\n",
    "    \"num_workers\": 0,\n",
    "    \"use_single_loss\": True,\n",
    "    \"behavior_weight\": 0.4, #basically doubles the strict weight's job.\n",
    "    \"iit_weight\": 1.,\n",
    "    \"strict_weight\": 0.4,\n",
    "    \"clip_grad_norm\": 1.0,\n",
    "    \"early_stop\" : True,\n",
    "    \"lr_scheduler\": torch.optim.lr_scheduler.LinearLR,\n",
    "    \"scheduler_kwargs\": dict(start_factor=1, end_factor=0.2, total_iters=int(n_epochs)),\n",
    "    \"optimizer_kwargs\": dict(lr=1e-3, betas=(0.9, 0.9)),\n",
    "    \"scheduler_val_metric\": [\"val/accuracy\", \"val/IIA\"], #for ReduceLRonPlateau\n",
    "    \"scheduler_mode\": \"max\", #for ReduceLRonPlateau\n",
    "    \"siit_sampling\" : \"sample_all\",\n",
    "    \"val_IIA_sampling\": \"all\", # random or all\n",
    "    \"seed\" : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ctx = 15\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0) DuplicateRemover + (1) LeftGreater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[prev_equal_hook], [mlp0_hook]]\n",
      "blocks.0.attn.hook_z.0 [[prev_token_hook], None]\n",
      "blocks.0.attn.hook_z.1 [None, [paren_counts_hook]]\n",
      "blocks.0.attn.hook_z.2 [None, None]\n",
      "blocks.0.attn.hook_z.3 [None, None]\n",
      "blocks.1.mlp.hook_post [[output_hook], None]\n",
      "blocks.1.attn.hook_z.0 [None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None]\n"
     ]
    }
   ],
   "source": [
    "cases = [Case0, Case1]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=1)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cases = [dataset_mapping[case] for case in cases]\n",
    "dsets = [dsetcase(N_samples=n_samples, n_ctx=n_ctx, seed=seed) for dsetcase in dataset_cases]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "[LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90430a39d9554a3989aaa17405f2b9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049280e36a19480889c99f6c6280a863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 1.1320, train/behavior_loss: 0.4307, train/strict_loss: 0.1762, val/iit_loss: 0.8251, val/IIA: 74.23%, val/accuracy: 80.66%, val/strict_accuracy: 79.61%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.6478, train/behavior_loss: 0.2137, train/strict_loss: 0.0958, val/iit_loss: 0.5150, val/IIA: 80.31%, val/accuracy: 85.56%, val/strict_accuracy: 84.76%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.4251, train/behavior_loss: 0.1182, train/strict_loss: 0.0605, val/iit_loss: 0.3778, val/IIA: 85.40%, val/accuracy: 90.14%, val/strict_accuracy: 88.80%\n",
      "Epoch 4: lr: 9.68e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.3296, train/behavior_loss: 0.0812, train/strict_loss: 0.0545, val/iit_loss: 0.3014, val/IIA: 88.43%, val/accuracy: 93.40%, val/strict_accuracy: 90.51%\n",
      "Epoch 5: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.2564, train/behavior_loss: 0.0564, train/strict_loss: 0.0501, val/iit_loss: 0.2378, val/IIA: 90.76%, val/accuracy: 96.18%, val/strict_accuracy: 92.55%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mpoly_hl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_pair\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:282\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    279\u001b[0m batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    281\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_train_epoch(train_loader, loss_fn, optimizer, batch_pbar)\n\u001b[0;32m--> 282\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_eval_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_scheduler(lr_scheduler, test_metrics)\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:346\u001b[0m, in \u001b[0;36mBaseModelPair._run_eval_epoch\u001b[0;34m(self, loader, loss_fn)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m t\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    345\u001b[0m         test_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 346\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m         )\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m test_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:146\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_eval_step\u001b[0;34m(self, base_input, ablation_input, loss_fn)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_eval_step\u001b[39m(\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    142\u001b[0m         base_input: \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor, Tensor],\n\u001b[1;32m    143\u001b[0m         ablation_input: \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor, Tensor],\n\u001b[1;32m    144\u001b[0m         loss_fn: Callable[[Tensor, Tensor], Tensor]\n\u001b[1;32m    145\u001b[0m         ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 146\u001b[0m     eval_returns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     base_x, base_y \u001b[38;5;241m=\u001b[39m base_input[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    148\u001b[0m     ablation_x, ablation_y \u001b[38;5;241m=\u001b[39m ablation_input[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:138\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.run_eval_step\u001b[0;34m(self, base_input, ablation_input, loss_fn)\u001b[0m\n\u001b[1;32m    136\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hl_node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorr\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 138\u001b[0m     IIA, loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_node_IIT_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhl_node\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     iias\u001b[38;5;241m.\u001b[39mappend(IIA)\n\u001b[1;32m    140\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:114\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.run_eval_step.<locals>.get_node_IIT_info\u001b[0;34m(hl_node)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_node_IIT_info\u001b[39m(hl_node: HLNode) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, Tensor]:\n\u001b[0;32m--> 114\u001b[0m     hl_output, ll_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_intervention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhl_node\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     hl_output \u001b[38;5;241m=\u001b[39m hl_output\u001b[38;5;241m.\u001b[39mto(ll_output\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    116\u001b[0m     hl_output \u001b[38;5;241m=\u001b[39m hl_output[label_idx\u001b[38;5;241m.\u001b[39mas_index]\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:90\u001b[0m, in \u001b[0;36mBaseModelPair.do_intervention\u001b[0;34m(self, base_input, ablation_input, hl_node, verbose)\u001b[0m\n\u001b[1;32m     87\u001b[0m ll_ablation_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mll_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mll_model\u001b[38;5;241m.\u001b[39mrun_with_cache(ablation_x)\n\u001b[1;32m     88\u001b[0m ll_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorr[hl_node]\n\u001b[0;32m---> 90\u001b[0m hl_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_hooks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfwd_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhl_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_hl_ablation_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhl_node\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m ll_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mll_model\u001b[38;5;241m.\u001b[39mrun_with_hooks(\n\u001b[1;32m     94\u001b[0m     base_x,\n\u001b[1;32m     95\u001b[0m     fwd_hooks\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m     ],\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/hook_points.py:401\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_hooks\u001b[0;34m(self, fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: Hooks will be reset at the end of run_with_hooks. This removes the backward hooks before a backward pass can occur.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m     )\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts) \u001b[38;5;28;01mas\u001b[39;00m hooked_model:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhooked_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/poly_bench/poly_hl_model.py:342\u001b[0m, in \u001b[0;36mPolyHLModel.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m hl_model\u001b[38;5;241m.\u001b[39mrun_with_hooks((these_tokens, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m), fwd_hooks\u001b[38;5;241m=\u001b[39mhooks)\n\u001b[1;32m    340\u001b[0m     model_outputs\u001b[38;5;241m.\u001b[39mappend(model_output)\n\u001b[0;32m--> 342\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/poly_bench/poly_hl_model.py:218\u001b[0m, in \u001b[0;36mPolyHLModel.sort_output\u001b[0;34m(self, tokens, model_outputs, task_ids)\u001b[0m\n\u001b[1;32m    215\u001b[0m     outputs[task_ids \u001b[38;5;241m==\u001b[39m i, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m#TODO: Make & return (or store?) a mask for evaluating the loss on the output.\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask[task_ids \u001b[38;5;241m==\u001b[39m i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_ctx_list[i]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model().to(poly_hl_model.device)\n",
    "ll_model.device = poly_hl_model.device\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_poly_model_to_dir(ll_model, poly_hl_model, f\"./saved_poly_models/cases_0+1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0) DuplicateRemover + (2) ParenChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[prev_equal_hook], [mlp0_hook]]\n",
      "blocks.0.attn.hook_z.0 [[prev_token_hook], None]\n",
      "blocks.0.attn.hook_z.1 [None, None]\n",
      "blocks.0.attn.hook_z.2 [None, None]\n",
      "blocks.0.attn.hook_z.3 [None, [paren_counts_hook]]\n",
      "blocks.1.mlp.hook_post [[output_hook], [mlp1_hook]]\n",
      "blocks.1.attn.hook_z.0 [None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None]\n",
      "blocks.2.mlp.hook_post [None, [mlp2_hook]]\n",
      "blocks.2.attn.hook_z.0 [None, None]\n",
      "blocks.2.attn.hook_z.1 [None, None]\n",
      "blocks.2.attn.hook_z.2 [None, None]\n",
      "blocks.2.attn.hook_z.3 [None, [horizon_lookback_hook]]\n"
     ]
    }
   ],
   "source": [
    "cases = [Case0, Case2]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=1)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evananders/far_cluster/polysemantic-benchmark/poly_bench/cases/duplicate_remover.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  _, cache = hl_model.run_with_cache((t.tensor(sample).unsqueeze(0), None, None))\n",
      "/Users/evananders/far_cluster/polysemantic-benchmark/poly_bench/utils.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.inputs = t.tensor(inputs).to(t.int)\n",
      "/Users/evananders/far_cluster/polysemantic-benchmark/poly_bench/utils.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.targets = t.tensor(targets).to(t.float32)\n",
      "/Users/evananders/far_cluster/polysemantic-benchmark/poly_bench/utils.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.markers = t.tensor(markers).to(t.int)\n"
     ]
    }
   ],
   "source": [
    "dataset_cases = [dataset_mapping[case] for case in cases]\n",
    "dsets = [dsetcase(N_samples=n_samples, n_ctx=n_ctx, seed=seed) for dsetcase in dataset_cases]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "[LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc39799f6814bb3814b5663ef68945c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e56c7fdb6014f90b48b0c3a0739139e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 1.0499, train/behavior_loss: 0.4056, train/strict_loss: 0.1749, val/iit_loss: 0.7415, val/IIA: 77.54%, val/accuracy: 77.78%, val/strict_accuracy: 77.74%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.6019, train/behavior_loss: 0.2266, train/strict_loss: 0.0986, val/iit_loss: 0.4637, val/IIA: 84.28%, val/accuracy: 87.01%, val/strict_accuracy: 86.89%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.3655, train/behavior_loss: 0.1171, train/strict_loss: 0.0596, val/iit_loss: 0.3122, val/IIA: 89.59%, val/accuracy: 90.68%, val/strict_accuracy: 89.52%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mpoly_hl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_pair\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:281\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    279\u001b[0m     batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 281\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval_epoch(test_loader, loss_fn)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:330\u001b[0m, in \u001b[0;36mBaseModelPair._run_train_epoch\u001b[0;34m(self, loader, loss_fn, optimizer, pbar)\u001b[0m\n\u001b[1;32m    327\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_metrics()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    329\u001b[0m     train_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:132\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_train_step\u001b[0;34m(self, base_input, ablation_input, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_single_loss:\n\u001b[1;32m    131\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m iit_loss \u001b[38;5;241m+\u001b[39m behavior_loss \u001b[38;5;241m+\u001b[39m siit_loss\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_on_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/iit_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: iit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/behavior_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: behavior_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/strict_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: siit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    138\u001b[0m }\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:65\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.step_on_loss\u001b[0;34m(self, loss, optimizer)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_on_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss: Tensor, optimizer: t\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_fn()\n\u001b[1;32m     67\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model().to(poly_hl_model.device)\n",
    "ll_model.device = poly_hl_model.device\n",
    "\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_poly_model_to_dir(ll_model, poly_hl_model, f\"./saved_poly_models/cases_0+2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0) DuplicateRemover + (3) UniqueExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[prev_equal_hook], [appeared_mlp]]\n",
      "blocks.0.attn.hook_z.0 [[prev_token_hook], None]\n",
      "blocks.0.attn.hook_z.1 [None, None]\n",
      "blocks.0.attn.hook_z.2 [None, [counter_head]]\n",
      "blocks.0.attn.hook_z.3 [None, None]\n",
      "blocks.1.mlp.hook_post [[output_hook], [mask_mlp]]\n",
      "blocks.1.attn.hook_z.0 [None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None]\n",
      "blocks.2.mlp.hook_post [None, [output_mlp]]\n",
      "blocks.2.attn.hook_z.0 [None, None]\n",
      "blocks.2.attn.hook_z.1 [None, None]\n",
      "blocks.2.attn.hook_z.2 [None, None]\n",
      "blocks.2.attn.hook_z.3 [None, None]\n"
     ]
    }
   ],
   "source": [
    "cases = [Case0, Case3]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=1)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evananders/far_cluster/polysemantic-benchmark/poly_bench/cases/unique_extractor.py:210: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  _, cache = hl_model.run_with_cache((t.tensor(sample).unsqueeze(0), None, None))\n"
     ]
    }
   ],
   "source": [
    "dataset_cases = [dataset_mapping[case] for case in cases]\n",
    "dsets = [dsetcase(N_samples=n_samples, n_ctx=n_ctx, seed=seed) for dsetcase in dataset_cases]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "[LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9f33ab5a6b49aaab8723db80bc6ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f9a5de3508425fb48a5a0e6811cbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.8313, train/behavior_loss: 0.3056, train/strict_loss: 0.1350, val/iit_loss: 0.4445, val/IIA: 86.38%, val/accuracy: 89.22%, val/strict_accuracy: 88.26%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.3394, train/behavior_loss: 0.0955, train/strict_loss: 0.0590, val/iit_loss: 0.2728, val/IIA: 89.50%, val/accuracy: 92.86%, val/strict_accuracy: 91.79%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.2184, train/behavior_loss: 0.0447, train/strict_loss: 0.0405, val/iit_loss: 0.1827, val/IIA: 93.22%, val/accuracy: 95.85%, val/strict_accuracy: 95.51%\n",
      "Epoch 4: lr: 9.68e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1523, train/behavior_loss: 0.0205, train/strict_loss: 0.0359, val/iit_loss: 0.1395, val/IIA: 93.95%, val/accuracy: 99.95%, val/strict_accuracy: 99.17%\n",
      "Epoch 5: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0956, train/behavior_loss: 0.0148, train/strict_loss: 0.0293, val/iit_loss: 0.0967, val/IIA: 96.76%, val/accuracy: 96.89%, val/strict_accuracy: 98.13%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mpoly_hl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_pair\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:281\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    279\u001b[0m     batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 281\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval_epoch(test_loader, loss_fn)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:330\u001b[0m, in \u001b[0;36mBaseModelPair._run_train_epoch\u001b[0;34m(self, loader, loss_fn, optimizer, pbar)\u001b[0m\n\u001b[1;32m    327\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_metrics()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    329\u001b[0m     train_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:132\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_train_step\u001b[0;34m(self, base_input, ablation_input, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_single_loss:\n\u001b[1;32m    131\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m iit_loss \u001b[38;5;241m+\u001b[39m behavior_loss \u001b[38;5;241m+\u001b[39m siit_loss\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_on_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/iit_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: iit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/behavior_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: behavior_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/strict_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: siit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    138\u001b[0m }\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:65\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.step_on_loss\u001b[0;34m(self, loss, optimizer)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_on_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss: Tensor, optimizer: t\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_fn()\n\u001b[1;32m     67\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model().to(poly_hl_model.device)\n",
    "ll_model.device = poly_hl_model.device\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_poly_model_to_dir(ll_model, poly_hl_model, f\"./saved_poly_models/cases_0+3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) LeftGreater + (2) ParenChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[mlp0_hook], [mlp0_hook]]\n",
      "blocks.0.attn.hook_z.0 [None, None]\n",
      "blocks.0.attn.hook_z.1 [[paren_counts_hook], None]\n",
      "blocks.0.attn.hook_z.2 [None, None]\n",
      "blocks.0.attn.hook_z.3 [None, [paren_counts_hook]]\n",
      "blocks.1.mlp.hook_post [None, [mlp1_hook]]\n",
      "blocks.1.attn.hook_z.0 [None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None]\n",
      "blocks.2.mlp.hook_post [None, [mlp2_hook]]\n",
      "blocks.2.attn.hook_z.0 [None, None]\n",
      "blocks.2.attn.hook_z.1 [None, None]\n",
      "blocks.2.attn.hook_z.2 [None, None]\n",
      "blocks.2.attn.hook_z.3 [None, [horizon_lookback_hook]]\n"
     ]
    }
   ],
   "source": [
    "cases = [Case1, Case2]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=1)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)\n",
    "\n",
    "dataset_cases = [dataset_mapping[case] for case in cases]\n",
    "dsets = [dsetcase(N_samples=n_samples, n_ctx=n_ctx, seed=seed) for dsetcase in dataset_cases]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "[LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d415cc9aca94b2e839ae663aeb8e2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d8744f7faa44b1af9e9429cc2ab770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.7506, train/behavior_loss: 0.3005, train/strict_loss: 0.1257, val/iit_loss: 0.4640, val/IIA: 88.62%, val/accuracy: 90.57%, val/strict_accuracy: 88.67%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.3442, train/behavior_loss: 0.1330, train/strict_loss: 0.0730, val/iit_loss: 0.2874, val/IIA: 93.25%, val/accuracy: 94.91%, val/strict_accuracy: 94.67%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mpoly_hl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_pair\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:281\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    279\u001b[0m     batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 281\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval_epoch(test_loader, loss_fn)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:330\u001b[0m, in \u001b[0;36mBaseModelPair._run_train_epoch\u001b[0;34m(self, loader, loss_fn, optimizer, pbar)\u001b[0m\n\u001b[1;32m    327\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_metrics()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    329\u001b[0m     train_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:132\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_train_step\u001b[0;34m(self, base_input, ablation_input, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_single_loss:\n\u001b[1;32m    131\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m iit_loss \u001b[38;5;241m+\u001b[39m behavior_loss \u001b[38;5;241m+\u001b[39m siit_loss\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_on_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/iit_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: iit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/behavior_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: behavior_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/strict_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: siit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    138\u001b[0m }\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:65\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.step_on_loss\u001b[0;34m(self, loss, optimizer)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_on_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss: Tensor, optimizer: t\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_fn()\n\u001b[1;32m     67\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model().to(poly_hl_model.device)\n",
    "ll_model.device = poly_hl_model.device\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_poly_model_to_dir(ll_model, poly_hl_model, f\"./saved_poly_models/cases_1+2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) LeftGreater + (3) UniqueExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[mlp0_hook], [appeared_mlp]]\n",
      "blocks.0.attn.hook_z.0 [None, None]\n",
      "blocks.0.attn.hook_z.1 [[paren_counts_hook], None]\n",
      "blocks.0.attn.hook_z.2 [None, [counter_head]]\n",
      "blocks.0.attn.hook_z.3 [None, None]\n",
      "blocks.1.mlp.hook_post [None, [mask_mlp]]\n",
      "blocks.1.attn.hook_z.0 [None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None]\n",
      "blocks.2.mlp.hook_post [None, [output_mlp]]\n",
      "blocks.2.attn.hook_z.0 [None, None]\n",
      "blocks.2.attn.hook_z.1 [None, None]\n",
      "blocks.2.attn.hook_z.2 [None, None]\n",
      "blocks.2.attn.hook_z.3 [None, None]\n"
     ]
    }
   ],
   "source": [
    "cases = [Case1, Case3]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=1)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)\n",
    "\n",
    "dataset_cases = [dataset_mapping[case] for case in cases]\n",
    "dsets = [dsetcase(N_samples=n_samples, n_ctx=n_ctx, seed=seed) for dsetcase in dataset_cases]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "[LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcaad44db4242a19311182609d51c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6e0ff2f1864b66a435dc559598b024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.7742, train/behavior_loss: 0.2961, train/strict_loss: 0.1280, val/iit_loss: 0.4539, val/IIA: 86.35%, val/accuracy: 93.13%, val/strict_accuracy: 92.86%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.3026, train/behavior_loss: 0.0835, train/strict_loss: 0.0447, val/iit_loss: 0.1840, val/IIA: 95.54%, val/accuracy: 95.60%, val/strict_accuracy: 95.18%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1620, train/behavior_loss: 0.0288, train/strict_loss: 0.0192, val/iit_loss: 0.1470, val/IIA: 95.88%, val/accuracy: 95.98%, val/strict_accuracy: 95.65%\n",
      "Epoch 4: lr: 9.68e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1460, train/behavior_loss: 0.0208, train/strict_loss: 0.0209, val/iit_loss: 0.1264, val/IIA: 94.55%, val/accuracy: 99.97%, val/strict_accuracy: 99.65%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mpoly_hl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_pair\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:282\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    279\u001b[0m batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    281\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_train_epoch(train_loader, loss_fn, optimizer, batch_pbar)\n\u001b[0;32m--> 282\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_eval_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_scheduler(lr_scheduler, test_metrics)\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:346\u001b[0m, in \u001b[0;36mBaseModelPair._run_eval_epoch\u001b[0;34m(self, loader, loss_fn)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m t\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    345\u001b[0m         test_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 346\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m         )\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m test_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:150\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_eval_step\u001b[0;34m(self, base_input, ablation_input, loss_fn)\u001b[0m\n\u001b[1;32m    147\u001b[0m base_x, base_y \u001b[38;5;241m=\u001b[39m base_input[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    148\u001b[0m ablation_x, ablation_y \u001b[38;5;241m=\u001b[39m ablation_input[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m--> 150\u001b[0m _, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mll_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mablation_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m label_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_label_idxs()\n\u001b[1;32m    152\u001b[0m base_y \u001b[38;5;241m=\u001b[39m base_y[label_idx\u001b[38;5;241m.\u001b[39mas_index]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mll_model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/ll_model.py:152\u001b[0m, in \u001b[0;36mLLModel.run_with_cache\u001b[0;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m cache_dict, fwd, bwd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_caching_hooks(\n\u001b[1;32m    143\u001b[0m     names_filter, incl_bwd, device, remove_batch_dim\u001b[38;5;241m=\u001b[39mremove_batch_dim\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhooks(\n\u001b[1;32m    147\u001b[0m     fwd_hooks\u001b[38;5;241m=\u001b[39mfwd,\n\u001b[1;32m    148\u001b[0m     bwd_hooks\u001b[38;5;241m=\u001b[39mbwd,\n\u001b[1;32m    149\u001b[0m     reset_hooks_end\u001b[38;5;241m=\u001b[39mreset_hooks_end,\n\u001b[1;32m    150\u001b[0m     clear_contexts\u001b[38;5;241m=\u001b[39mclear_contexts,\n\u001b[1;32m    151\u001b[0m ):\n\u001b[0;32m--> 152\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incl_bwd:\n\u001b[1;32m    154\u001b[0m         model_out\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:550\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    547\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    548\u001b[0m         )\n\u001b[0;32m--> 550\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:1585\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1579\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1581\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_out(\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m-> 1585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1594\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m   1596\u001b[0m     resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(resid_pre \u001b[38;5;241m+\u001b[39m attn_out)  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:535\u001b[0m, in \u001b[0;36mAbstractAttention.forward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     query_input: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m     attention_mask: Optional[Int[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch offset_pos\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    527\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    528\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m    shortformer_pos_embed is only used if self.cfg.positional_embedding_type == \"shortformer\", else defaults to None and is irrelevant. See HookedTransformerConfig for more details\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m    past_kv_cache_entry is an optional entry of past keys and values for this layer, only relevant if generating text. Defaults to None\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;124;03m    additive_attention_mask is an optional mask to add to the attention weights. Defaults to None.\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03m    attention_mask is the attention mask for padded tokens. Defaults to None.\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_qkv_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_kv_cache_entry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;66;03m# Appends the new keys and values to the cached values, and automatically updates the cache\u001b[39;00m\n\u001b[1;32m    539\u001b[0m         kv_cache_pos_offset \u001b[38;5;241m=\u001b[39m past_kv_cache_entry\u001b[38;5;241m.\u001b[39mpast_keys\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:704\u001b[0m, in \u001b[0;36mAbstractAttention.calculate_qkv_matrices\u001b[0;34m(self, query_input, key_input, value_input)\u001b[0m\n\u001b[1;32m    691\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_k(\n\u001b[1;32m    692\u001b[0m         \u001b[38;5;66;03m# call bitsandbytes method to dequantize and multiply\u001b[39;00m\n\u001b[1;32m    693\u001b[0m         bnb\u001b[38;5;241m.\u001b[39mmatmul_4bit(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_K\n\u001b[1;32m    702\u001b[0m     )\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhook_k\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mqkv_einops_string\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, head_index d_model d_head \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;43m            -> batch pos head_index d_head\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb_K\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mload_in_4bit:\n\u001b[1;32m    715\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_v(\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;66;03m# call bitsandbytes method to dequantize and multiply\u001b[39;00m\n\u001b[1;32m    717\u001b[0m         bnb\u001b[38;5;241m.\u001b[39mmatmul_4bit(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_V\n\u001b[1;32m    729\u001b[0m     )\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model().to(poly_hl_model.device)\n",
    "ll_model.device = poly_hl_model.device\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_poly_model_to_dir(ll_model, poly_hl_model, f\"./saved_poly_models/cases_1+3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) ParenChecker + (3) UniqueExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[mlp0_hook], [appeared_mlp]]\n",
      "blocks.0.attn.hook_z.0 [None, None]\n",
      "blocks.0.attn.hook_z.1 [None, None]\n",
      "blocks.0.attn.hook_z.2 [None, [counter_head]]\n",
      "blocks.0.attn.hook_z.3 [[paren_counts_hook], None]\n",
      "blocks.1.mlp.hook_post [[mlp1_hook], [mask_mlp]]\n",
      "blocks.1.attn.hook_z.0 [None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None]\n",
      "blocks.2.mlp.hook_post [[mlp2_hook], [output_mlp]]\n",
      "blocks.2.attn.hook_z.0 [None, None]\n",
      "blocks.2.attn.hook_z.1 [None, None]\n",
      "blocks.2.attn.hook_z.2 [None, None]\n",
      "blocks.2.attn.hook_z.3 [[horizon_lookback_hook], None]\n"
     ]
    }
   ],
   "source": [
    "cases = [Case2, Case3]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=1)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)\n",
    "\n",
    "dataset_cases = [dataset_mapping[case] for case in cases]\n",
    "dsets = [dsetcase(N_samples=n_samples, n_ctx=n_ctx, seed=seed) for dsetcase in dataset_cases]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "[LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24b5b5e1d934e33a9ef38371140cde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abcb8ac73b249e69a994046ef7c3e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.8036, train/behavior_loss: 0.3006, train/strict_loss: 0.1285, val/iit_loss: 0.4144, val/IIA: 89.61%, val/accuracy: 86.95%, val/strict_accuracy: 86.95%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.2988, train/behavior_loss: 0.0937, train/strict_loss: 0.0420, val/iit_loss: 0.1993, val/IIA: 94.29%, val/accuracy: 95.22%, val/strict_accuracy: 95.61%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1571, train/behavior_loss: 0.0424, train/strict_loss: 0.0212, val/iit_loss: 0.1156, val/IIA: 97.55%, val/accuracy: 93.32%, val/strict_accuracy: 94.67%\n",
      "Epoch 4: lr: 9.68e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1005, train/behavior_loss: 0.0324, train/strict_loss: 0.0161, val/iit_loss: 0.1152, val/IIA: 93.39%, val/accuracy: 99.41%, val/strict_accuracy: 99.28%\n",
      "Epoch 5: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0953, train/behavior_loss: 0.0279, train/strict_loss: 0.0127, val/iit_loss: 0.0673, val/IIA: 98.33%, val/accuracy: 93.36%, val/strict_accuracy: 94.23%\n",
      "Epoch 6: lr: 9.52e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0703, train/behavior_loss: 0.0289, train/strict_loss: 0.0109, val/iit_loss: 0.0793, val/IIA: 98.06%, val/accuracy: 93.34%, val/strict_accuracy: 95.41%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mpoly_hl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_pair\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:281\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    279\u001b[0m     batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 281\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval_epoch(test_loader, loss_fn)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:330\u001b[0m, in \u001b[0;36mBaseModelPair._run_train_epoch\u001b[0;34m(self, loader, loss_fn, optimizer, pbar)\u001b[0m\n\u001b[1;32m    327\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_metrics()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    329\u001b[0m     train_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:106\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_train_step\u001b[0;34m(self, base_input, ablation_input, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miit_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    104\u001b[0m     hl_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_hl_name()  \u001b[38;5;66;03m# sample a high-level variable to ablate\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     iit_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 106\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_IIT_loss_over_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhl_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miit_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    108\u001b[0m     )\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_single_loss:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_on_loss(iit_loss, optimizer)\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:180\u001b[0m, in \u001b[0;36mBaseModelPair.get_IIT_loss_over_batch\u001b[0;34m(self, base_input, ablation_input, hl_node, loss_fn)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_IIT_loss_over_batch\u001b[39m(\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    175\u001b[0m     base_input: \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor, Tensor],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m     loss_fn: Callable[[Tensor, Tensor], Tensor],\n\u001b[1;32m    179\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 180\u001b[0m     hl_output, ll_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_intervention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhl_node\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     label_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_label_idxs()\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# IIT loss is only computed on the tokens we care about\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:93\u001b[0m, in \u001b[0;36mBaseModelPair.do_intervention\u001b[0;34m(self, base_input, ablation_input, hl_node, verbose)\u001b[0m\n\u001b[1;32m     88\u001b[0m ll_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorr[hl_node]\n\u001b[1;32m     90\u001b[0m hl_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhl_model\u001b[38;5;241m.\u001b[39mrun_with_hooks(\n\u001b[1;32m     91\u001b[0m     base_input, fwd_hooks\u001b[38;5;241m=\u001b[39m[(hl_node\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_hl_ablation_hook(hl_node))]\n\u001b[1;32m     92\u001b[0m )\n\u001b[0;32m---> 93\u001b[0m ll_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mll_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_hooks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfwd_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mll_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_ll_ablation_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mll_node\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mll_node\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mll_nodes\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_x\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_y\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/hook_points.py:401\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_hooks\u001b[0;34m(self, fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: Hooks will be reset at the end of run_with_hooks. This removes the backward hooks before a backward pass can occur.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m     )\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts) \u001b[38;5;28;01mas\u001b[39;00m hooked_model:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhooked_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:550\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    547\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    548\u001b[0m         )\n\u001b[0;32m--> 550\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:1588\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1579\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1581\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_out(\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[1;32m   1585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[1;32m   1586\u001b[0m         query_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(query_input)\n\u001b[1;32m   1587\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[0;32m-> 1588\u001b[0m         key_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[1;32m   1590\u001b[0m         value_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(value_input),\n\u001b[1;32m   1591\u001b[0m         past_kv_cache_entry\u001b[38;5;241m=\u001b[39mpast_kv_cache_entry,\n\u001b[1;32m   1592\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1593\u001b[0m     )\n\u001b[1;32m   1594\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m   1596\u001b[0m     resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(resid_pre \u001b[38;5;241m+\u001b[39m attn_out)  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:316\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    312\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    314\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# [batch, pos, length]\u001b[39;00m\n\u001b[1;32m    315\u001b[0m scale: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos 1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_scale(\n\u001b[0;32m--> 316\u001b[0m     (\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\u001b[38;5;241m.\u001b[39msqrt()\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    318\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m/\u001b[39m scale  \u001b[38;5;66;03m# [batch, pos, length]\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_normalized(x \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model().to(poly_hl_model.device)\n",
    "ll_model.device = poly_hl_model.device\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_poly_model_to_dir(ll_model, poly_hl_model, f\"./saved_poly_models/cases_2+3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0) DuplicateRemover + (1) LeftGreater + (2) ParenChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[prev_equal_hook], [mlp0_hook], [mlp0_hook]]\n",
      "blocks.0.attn.hook_z.0 [[prev_token_hook], None, None]\n",
      "blocks.0.attn.hook_z.1 [None, [paren_counts_hook], None]\n",
      "blocks.0.attn.hook_z.2 [None, None, None]\n",
      "blocks.0.attn.hook_z.3 [None, None, [paren_counts_hook]]\n",
      "blocks.1.mlp.hook_post [[output_hook], None, [mlp1_hook]]\n",
      "blocks.1.attn.hook_z.0 [None, None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None, None]\n",
      "blocks.2.mlp.hook_post [None, None, [mlp2_hook]]\n",
      "blocks.2.attn.hook_z.0 [None, None, None]\n",
      "blocks.2.attn.hook_z.1 [None, None, None]\n",
      "blocks.2.attn.hook_z.2 [None, None, None]\n",
      "blocks.2.attn.hook_z.3 [None, None, [horizon_lookback_hook]]\n"
     ]
    }
   ],
   "source": [
    "cases = [Case0, Case1, Case2]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=1)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)\n",
    "\n",
    "dataset_cases = [dataset_mapping[case] for case in cases]\n",
    "dsets = [dsetcase(N_samples=n_samples, n_ctx=n_ctx, seed=seed) for dsetcase in dataset_cases]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "[LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4cd3ab1a564e04b2a82fa816a103d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a46da31c994a08bd12248f843a0831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.9253, train/behavior_loss: 0.3471, train/strict_loss: 0.1651, val/iit_loss: 0.5707, val/IIA: 81.28%, val/accuracy: 85.31%, val/strict_accuracy: 84.14%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.4242, train/behavior_loss: 0.1499, train/strict_loss: 0.0831, val/iit_loss: 0.3493, val/IIA: 86.77%, val/accuracy: 90.85%, val/strict_accuracy: 90.38%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.3061, train/behavior_loss: 0.0817, train/strict_loss: 0.0472, val/iit_loss: 0.2568, val/IIA: 90.01%, val/accuracy: 91.84%, val/strict_accuracy: 91.32%\n",
      "Epoch 4: lr: 9.68e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.2245, train/behavior_loss: 0.0610, train/strict_loss: 0.0387, val/iit_loss: 0.2061, val/IIA: 92.28%, val/accuracy: 93.85%, val/strict_accuracy: 92.61%\n",
      "Epoch 5: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1778, train/behavior_loss: 0.0382, train/strict_loss: 0.0345, val/iit_loss: 0.1536, val/IIA: 94.37%, val/accuracy: 96.30%, val/strict_accuracy: 95.23%\n",
      "Epoch 6: lr: 9.52e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1288, train/behavior_loss: 0.0199, train/strict_loss: 0.0293, val/iit_loss: 0.1178, val/IIA: 95.80%, val/accuracy: 97.65%, val/strict_accuracy: 97.39%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mpoly_hl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_pair\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:281\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    279\u001b[0m     batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 281\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval_epoch(test_loader, loss_fn)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:330\u001b[0m, in \u001b[0;36mBaseModelPair._run_train_epoch\u001b[0;34m(self, loader, loss_fn, optimizer, pbar)\u001b[0m\n\u001b[1;32m    327\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_metrics()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    329\u001b[0m     train_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:116\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_train_step\u001b[0;34m(self, base_input, ablation_input, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# loss for nodes that are not in the circuit\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# should not have causal effect on the high-level output\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    115\u001b[0m     siit_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_SIIT_loss_over_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    118\u001b[0m )\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_single_loss:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_on_loss(siit_loss, optimizer)\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:74\u001b[0m, in \u001b[0;36mStrictIITModelPair.get_SIIT_loss_over_batch\u001b[0;34m(self, base_input, ablation_input, loss_fn)\u001b[0m\n\u001b[1;32m     72\u001b[0m ablation_x, _ \u001b[38;5;241m=\u001b[39m ablation_input[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     73\u001b[0m ll_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_ll_nodes()\n\u001b[0;32m---> 74\u001b[0m _, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mll_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mablation_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mll_cache \u001b[38;5;241m=\u001b[39m cache\n\u001b[1;32m     76\u001b[0m hooks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/ll_model.py:152\u001b[0m, in \u001b[0;36mLLModel.run_with_cache\u001b[0;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m cache_dict, fwd, bwd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_caching_hooks(\n\u001b[1;32m    143\u001b[0m     names_filter, incl_bwd, device, remove_batch_dim\u001b[38;5;241m=\u001b[39mremove_batch_dim\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhooks(\n\u001b[1;32m    147\u001b[0m     fwd_hooks\u001b[38;5;241m=\u001b[39mfwd,\n\u001b[1;32m    148\u001b[0m     bwd_hooks\u001b[38;5;241m=\u001b[39mbwd,\n\u001b[1;32m    149\u001b[0m     reset_hooks_end\u001b[38;5;241m=\u001b[39mreset_hooks_end,\n\u001b[1;32m    150\u001b[0m     clear_contexts\u001b[38;5;241m=\u001b[39mclear_contexts,\n\u001b[1;32m    151\u001b[0m ):\n\u001b[0;32m--> 152\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incl_bwd:\n\u001b[1;32m    154\u001b[0m         model_out\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:550\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    547\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    548\u001b[0m         )\n\u001b[0;32m--> 550\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:1585\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1579\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1581\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_out(\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m-> 1585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1594\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m   1596\u001b[0m     resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(resid_pre \u001b[38;5;241m+\u001b[39m attn_out)  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:535\u001b[0m, in \u001b[0;36mAbstractAttention.forward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     query_input: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m     attention_mask: Optional[Int[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch offset_pos\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    527\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    528\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m    shortformer_pos_embed is only used if self.cfg.positional_embedding_type == \"shortformer\", else defaults to None and is irrelevant. See HookedTransformerConfig for more details\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m    past_kv_cache_entry is an optional entry of past keys and values for this layer, only relevant if generating text. Defaults to None\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;124;03m    additive_attention_mask is an optional mask to add to the attention weights. Defaults to None.\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03m    attention_mask is the attention mask for padded tokens. Defaults to None.\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_qkv_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_kv_cache_entry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;66;03m# Appends the new keys and values to the cached values, and automatically updates the cache\u001b[39;00m\n\u001b[1;32m    539\u001b[0m         kv_cache_pos_offset \u001b[38;5;241m=\u001b[39m past_kv_cache_entry\u001b[38;5;241m.\u001b[39mpast_keys\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:704\u001b[0m, in \u001b[0;36mAbstractAttention.calculate_qkv_matrices\u001b[0;34m(self, query_input, key_input, value_input)\u001b[0m\n\u001b[1;32m    691\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_k(\n\u001b[1;32m    692\u001b[0m         \u001b[38;5;66;03m# call bitsandbytes method to dequantize and multiply\u001b[39;00m\n\u001b[1;32m    693\u001b[0m         bnb\u001b[38;5;241m.\u001b[39mmatmul_4bit(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_K\n\u001b[1;32m    702\u001b[0m     )\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhook_k\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mqkv_einops_string\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, head_index d_model d_head \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;43m            -> batch pos head_index d_head\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb_K\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mload_in_4bit:\n\u001b[1;32m    715\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_v(\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;66;03m# call bitsandbytes method to dequantize and multiply\u001b[39;00m\n\u001b[1;32m    717\u001b[0m         bnb\u001b[38;5;241m.\u001b[39mmatmul_4bit(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_V\n\u001b[1;32m    729\u001b[0m     )\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model().to(poly_hl_model.device)\n",
    "ll_model.device = poly_hl_model.device\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_poly_model_to_dir(ll_model, poly_hl_model, f\"./saved_poly_models/cases_0+1+2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0) DuplicateRemover + (1) LeftGreater + (3) UniqueExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[prev_equal_hook], [mlp0_hook], [appeared_mlp]]\n",
      "blocks.0.attn.hook_z.0 [[prev_token_hook], None, None]\n",
      "blocks.0.attn.hook_z.1 [None, [paren_counts_hook], None]\n",
      "blocks.0.attn.hook_z.2 [None, None, [counter_head]]\n",
      "blocks.0.attn.hook_z.3 [None, None, None]\n",
      "blocks.1.mlp.hook_post [[output_hook], None, [mask_mlp]]\n",
      "blocks.1.attn.hook_z.0 [None, None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None, None]\n",
      "blocks.2.mlp.hook_post [None, None, [output_mlp]]\n",
      "blocks.2.attn.hook_z.0 [None, None, None]\n",
      "blocks.2.attn.hook_z.1 [None, None, None]\n",
      "blocks.2.attn.hook_z.2 [None, None, None]\n",
      "blocks.2.attn.hook_z.3 [None, None, None]\n"
     ]
    }
   ],
   "source": [
    "cases = [Case0, Case1, Case3]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=1)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)\n",
    "\n",
    "dataset_cases = [dataset_mapping[case] for case in cases]\n",
    "dsets = [dsetcase(N_samples=n_samples, n_ctx=n_ctx, seed=seed) for dsetcase in dataset_cases]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "[LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3239f566b54847bbca14e8fec6fd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1cf270f58b4413480cac041372c0430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.7985, train/behavior_loss: 0.2824, train/strict_loss: 0.1248, val/iit_loss: 0.4628, val/IIA: 82.20%, val/accuracy: 88.30%, val/strict_accuracy: 88.28%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.3609, train/behavior_loss: 0.0864, train/strict_loss: 0.0529, val/iit_loss: 0.2789, val/IIA: 88.48%, val/accuracy: 95.40%, val/strict_accuracy: 94.75%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.2055, train/behavior_loss: 0.0401, train/strict_loss: 0.0347, val/iit_loss: 0.1913, val/IIA: 92.46%, val/accuracy: 99.04%, val/strict_accuracy: 97.70%\n",
      "Epoch 4: lr: 9.68e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1676, train/behavior_loss: 0.0213, train/strict_loss: 0.0325, val/iit_loss: 0.1490, val/IIA: 94.94%, val/accuracy: 97.41%, val/strict_accuracy: 96.87%\n",
      "Epoch 5: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1330, train/behavior_loss: 0.0149, train/strict_loss: 0.0203, val/iit_loss: 0.1241, val/IIA: 95.18%, val/accuracy: 99.99%, val/strict_accuracy: 99.78%\n",
      "Epoch 6: lr: 9.52e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1095, train/behavior_loss: 0.0116, train/strict_loss: 0.0149, val/iit_loss: 0.0971, val/IIA: 96.01%, val/accuracy: 99.99%, val/strict_accuracy: 99.84%\n",
      "Epoch 7: lr: 9.44e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1085, train/behavior_loss: 0.0127, train/strict_loss: 0.0120, val/iit_loss: 0.1207, val/IIA: 94.96%, val/accuracy: 100.00%, val/strict_accuracy: 99.92%\n",
      "Epoch 8: lr: 9.36e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0841, train/behavior_loss: 0.0092, train/strict_loss: 0.0114, val/iit_loss: 0.0872, val/IIA: 97.40%, val/accuracy: 97.69%, val/strict_accuracy: 98.57%\n",
      "Epoch 9: lr: 9.28e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0870, train/behavior_loss: 0.0090, train/strict_loss: 0.0102, val/iit_loss: 0.0572, val/IIA: 98.09%, val/accuracy: 97.69%, val/strict_accuracy: 97.80%\n",
      "Epoch 10: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0639, train/behavior_loss: 0.0104, train/strict_loss: 0.0094, val/iit_loss: 0.0817, val/IIA: 96.52%, val/accuracy: 100.00%, val/strict_accuracy: 99.92%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mpoly_hl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_pair\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:282\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    279\u001b[0m batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    281\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_train_epoch(train_loader, loss_fn, optimizer, batch_pbar)\n\u001b[0;32m--> 282\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_eval_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_scheduler(lr_scheduler, test_metrics)\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:346\u001b[0m, in \u001b[0;36mBaseModelPair._run_eval_epoch\u001b[0;34m(self, loader, loss_fn)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m t\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    345\u001b[0m         test_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 346\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m         )\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m test_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:156\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_eval_step\u001b[0;34m(self, base_input, ablation_input, loss_fn)\u001b[0m\n\u001b[1;32m    154\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit:\n\u001b[0;32m--> 156\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mll_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_hooks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfwd_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_ll_ablation_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     ll_output \u001b[38;5;241m=\u001b[39m out[label_idx\u001b[38;5;241m.\u001b[39mas_index]\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhl_model\u001b[38;5;241m.\u001b[39mis_categorical():\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/hook_points.py:401\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_hooks\u001b[0;34m(self, fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: Hooks will be reset at the end of run_with_hooks. This removes the backward hooks before a backward pass can occur.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m     )\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts) \u001b[38;5;28;01mas\u001b[39;00m hooked_model:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhooked_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:550\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    547\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    548\u001b[0m         )\n\u001b[0;32m--> 550\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:1586\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1579\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1581\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_out(\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[1;32m   1585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[0;32m-> 1586\u001b[0m         query_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[1;32m   1588\u001b[0m         key_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(key_input)\n\u001b[1;32m   1589\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[1;32m   1590\u001b[0m         value_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(value_input),\n\u001b[1;32m   1591\u001b[0m         past_kv_cache_entry\u001b[38;5;241m=\u001b[39mpast_kv_cache_entry,\n\u001b[1;32m   1592\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1593\u001b[0m     )\n\u001b[1;32m   1594\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m   1596\u001b[0m     resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(resid_pre \u001b[38;5;241m+\u001b[39m attn_out)  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:316\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    312\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    314\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# [batch, pos, length]\u001b[39;00m\n\u001b[1;32m    315\u001b[0m scale: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos 1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_scale(\n\u001b[0;32m--> 316\u001b[0m     (\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\u001b[38;5;241m.\u001b[39msqrt()\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    318\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m/\u001b[39m scale  \u001b[38;5;66;03m# [batch, pos, length]\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_normalized(x \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model().to(poly_hl_model.device)\n",
    "ll_model.device = poly_hl_model.device\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_poly_model_to_dir(ll_model, poly_hl_model, f\"./saved_poly_models/cases_0+1+3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0) DuplicateRemover + (2) ParenChecker + (3) UniqueExtractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[prev_equal_hook], [mlp0_hook], [appeared_mlp]]\n",
      "blocks.0.attn.hook_z.0 [[prev_token_hook], None, None]\n",
      "blocks.0.attn.hook_z.1 [None, None, None]\n",
      "blocks.0.attn.hook_z.2 [None, None, [counter_head]]\n",
      "blocks.0.attn.hook_z.3 [None, [paren_counts_hook], None]\n",
      "blocks.1.mlp.hook_post [[output_hook], [mlp1_hook], [mask_mlp]]\n",
      "blocks.1.attn.hook_z.0 [None, None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None, None]\n",
      "blocks.2.mlp.hook_post [None, [mlp2_hook], [output_mlp]]\n",
      "blocks.2.attn.hook_z.0 [None, None, None]\n",
      "blocks.2.attn.hook_z.1 [None, None, None]\n",
      "blocks.2.attn.hook_z.2 [None, None, None]\n",
      "blocks.2.attn.hook_z.3 [None, [horizon_lookback_hook], None]\n"
     ]
    }
   ],
   "source": [
    "cases = [Case0, Case2, Case3]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=1)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)\n",
    "\n",
    "dataset_cases = [dataset_mapping[case] for case in cases]\n",
    "dsets = [dsetcase(N_samples=n_samples, n_ctx=n_ctx, seed=seed) for dsetcase in dataset_cases]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "[LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfdb11137b441be92b0bae0231579dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7678c90f3044c01a63cce826c624246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.8023, train/behavior_loss: 0.2993, train/strict_loss: 0.1361, val/iit_loss: 0.4318, val/IIA: 84.82%, val/accuracy: 87.76%, val/strict_accuracy: 87.14%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.3200, train/behavior_loss: 0.0853, train/strict_loss: 0.0488, val/iit_loss: 0.2822, val/IIA: 90.63%, val/accuracy: 92.03%, val/strict_accuracy: 91.50%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.2377, train/behavior_loss: 0.0429, train/strict_loss: 0.0329, val/iit_loss: 0.1742, val/IIA: 94.00%, val/accuracy: 96.90%, val/strict_accuracy: 96.59%\n",
      "Epoch 4: lr: 9.68e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1367, train/behavior_loss: 0.0227, train/strict_loss: 0.0240, val/iit_loss: 0.1413, val/IIA: 93.89%, val/accuracy: 99.30%, val/strict_accuracy: 98.91%\n",
      "Epoch 5: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1158, train/behavior_loss: 0.0191, train/strict_loss: 0.0181, val/iit_loss: 0.1245, val/IIA: 95.29%, val/accuracy: 97.33%, val/strict_accuracy: 97.16%\n",
      "Epoch 6: lr: 9.52e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1049, train/behavior_loss: 0.0174, train/strict_loss: 0.0119, val/iit_loss: 0.1094, val/IIA: 95.20%, val/accuracy: 99.48%, val/strict_accuracy: 99.38%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mpoly_hl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_pair\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:282\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    279\u001b[0m batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    281\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_train_epoch(train_loader, loss_fn, optimizer, batch_pbar)\n\u001b[0;32m--> 282\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_eval_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_scheduler(lr_scheduler, test_metrics)\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:346\u001b[0m, in \u001b[0;36mBaseModelPair._run_eval_epoch\u001b[0;34m(self, loader, loss_fn)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m t\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    345\u001b[0m         test_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 346\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m         )\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m test_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:146\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_eval_step\u001b[0;34m(self, base_input, ablation_input, loss_fn)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_eval_step\u001b[39m(\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    142\u001b[0m         base_input: \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor, Tensor],\n\u001b[1;32m    143\u001b[0m         ablation_input: \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor, Tensor],\n\u001b[1;32m    144\u001b[0m         loss_fn: Callable[[Tensor, Tensor], Tensor]\n\u001b[1;32m    145\u001b[0m         ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 146\u001b[0m     eval_returns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     base_x, base_y \u001b[38;5;241m=\u001b[39m base_input[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    148\u001b[0m     ablation_x, ablation_y \u001b[38;5;241m=\u001b[39m ablation_input[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:138\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.run_eval_step\u001b[0;34m(self, base_input, ablation_input, loss_fn)\u001b[0m\n\u001b[1;32m    136\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hl_node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorr\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 138\u001b[0m     IIA, loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_node_IIT_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhl_node\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     iias\u001b[38;5;241m.\u001b[39mappend(IIA)\n\u001b[1;32m    140\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:114\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.run_eval_step.<locals>.get_node_IIT_info\u001b[0;34m(hl_node)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_node_IIT_info\u001b[39m(hl_node: HLNode) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, Tensor]:\n\u001b[0;32m--> 114\u001b[0m     hl_output, ll_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_intervention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhl_node\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     hl_output \u001b[38;5;241m=\u001b[39m hl_output\u001b[38;5;241m.\u001b[39mto(ll_output\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    116\u001b[0m     hl_output \u001b[38;5;241m=\u001b[39m hl_output[label_idx\u001b[38;5;241m.\u001b[39mas_index]\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:87\u001b[0m, in \u001b[0;36mBaseModelPair.do_intervention\u001b[0;34m(self, base_input, ablation_input, hl_node, verbose)\u001b[0m\n\u001b[1;32m     84\u001b[0m base_x, base_y \u001b[38;5;241m=\u001b[39m base_input[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     86\u001b[0m hl_ablation_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhl_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhl_model\u001b[38;5;241m.\u001b[39mrun_with_cache(ablation_input)\n\u001b[0;32m---> 87\u001b[0m ll_ablation_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mll_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mll_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mablation_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m ll_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorr[hl_node]\n\u001b[1;32m     90\u001b[0m hl_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhl_model\u001b[38;5;241m.\u001b[39mrun_with_hooks(\n\u001b[1;32m     91\u001b[0m     base_input, fwd_hooks\u001b[38;5;241m=\u001b[39m[(hl_node\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_hl_ablation_hook(hl_node))]\n\u001b[1;32m     92\u001b[0m )\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/ll_model.py:152\u001b[0m, in \u001b[0;36mLLModel.run_with_cache\u001b[0;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m cache_dict, fwd, bwd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_caching_hooks(\n\u001b[1;32m    143\u001b[0m     names_filter, incl_bwd, device, remove_batch_dim\u001b[38;5;241m=\u001b[39mremove_batch_dim\n\u001b[1;32m    144\u001b[0m )\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhooks(\n\u001b[1;32m    147\u001b[0m     fwd_hooks\u001b[38;5;241m=\u001b[39mfwd,\n\u001b[1;32m    148\u001b[0m     bwd_hooks\u001b[38;5;241m=\u001b[39mbwd,\n\u001b[1;32m    149\u001b[0m     reset_hooks_end\u001b[38;5;241m=\u001b[39mreset_hooks_end,\n\u001b[1;32m    150\u001b[0m     clear_contexts\u001b[38;5;241m=\u001b[39mclear_contexts,\n\u001b[1;32m    151\u001b[0m ):\n\u001b[0;32m--> 152\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incl_bwd:\n\u001b[1;32m    154\u001b[0m         model_out\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:550\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    547\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    548\u001b[0m         )\n\u001b[0;32m--> 550\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:1585\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1579\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1581\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_out(\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m-> 1585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1594\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m   1596\u001b[0m     resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(resid_pre \u001b[38;5;241m+\u001b[39m attn_out)  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:583\u001b[0m, in \u001b[0;36mAbstractAttention.forward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask)\u001b[0m\n\u001b[1;32m    581\u001b[0m attn_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_scores(attn_scores)\n\u001b[1;32m    582\u001b[0m pattern \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(attn_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 583\u001b[0m pattern \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mzeros_like(pattern), pattern)\n\u001b[1;32m    584\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_pattern(pattern)  \u001b[38;5;66;03m# [batch, head_index, query_pos, key_pos]\u001b[39;00m\n\u001b[1;32m    585\u001b[0m pattern \u001b[38;5;241m=\u001b[39m pattern\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model().to(poly_hl_model.device)\n",
    "ll_model.device = poly_hl_model.device\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_poly_model_to_dir(ll_model, poly_hl_model, f\"./saved_poly_models/cases_0+2+3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) LeftGreater + (2) ParenChecker + (3) UniqueExtractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[mlp0_hook], [mlp0_hook], [appeared_mlp]]\n",
      "blocks.0.attn.hook_z.0 [None, None, None]\n",
      "blocks.0.attn.hook_z.1 [[paren_counts_hook], None, None]\n",
      "blocks.0.attn.hook_z.2 [None, None, [counter_head]]\n",
      "blocks.0.attn.hook_z.3 [None, [paren_counts_hook], None]\n",
      "blocks.1.mlp.hook_post [None, [mlp1_hook], [mask_mlp]]\n",
      "blocks.1.attn.hook_z.0 [None, None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None, None]\n",
      "blocks.2.mlp.hook_post [None, [mlp2_hook], [output_mlp]]\n",
      "blocks.2.attn.hook_z.0 [None, None, None]\n",
      "blocks.2.attn.hook_z.1 [None, None, None]\n",
      "blocks.2.attn.hook_z.2 [None, None, None]\n",
      "blocks.2.attn.hook_z.3 [None, [horizon_lookback_hook], None]\n"
     ]
    }
   ],
   "source": [
    "cases = [Case1, Case2, Case3]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=1)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)\n",
    "\n",
    "dataset_cases = [dataset_mapping[case] for case in cases]\n",
    "dsets = [dsetcase(N_samples=n_samples, n_ctx=n_ctx, seed=seed) for dsetcase in dataset_cases]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "[LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d70a9c15d4466fa3e86722b5144295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7a9c8644b946669296bb999fd23e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.7353, train/behavior_loss: 0.2803, train/strict_loss: 0.1233, val/iit_loss: 0.3883, val/IIA: 88.49%, val/accuracy: 93.60%, val/strict_accuracy: 92.23%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.2830, train/behavior_loss: 0.0842, train/strict_loss: 0.0461, val/iit_loss: 0.1897, val/IIA: 94.31%, val/accuracy: 93.04%, val/strict_accuracy: 92.96%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1657, train/behavior_loss: 0.0381, train/strict_loss: 0.0253, val/iit_loss: 0.1424, val/IIA: 94.76%, val/accuracy: 98.61%, val/strict_accuracy: 98.65%\n",
      "Epoch 4: lr: 9.68e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.1145, train/behavior_loss: 0.0253, train/strict_loss: 0.0170, val/iit_loss: 0.1125, val/IIA: 95.51%, val/accuracy: 97.90%, val/strict_accuracy: 97.94%\n",
      "Epoch 5: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0938, train/behavior_loss: 0.0217, train/strict_loss: 0.0158, val/iit_loss: 0.0888, val/IIA: 96.22%, val/accuracy: 98.52%, val/strict_accuracy: 98.91%\n",
      "Epoch 6: lr: 9.52e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0981, train/behavior_loss: 0.0231, train/strict_loss: 0.0150, val/iit_loss: 0.0954, val/IIA: 97.16%, val/accuracy: 95.33%, val/strict_accuracy: 96.01%\n",
      "Epoch 7: lr: 9.44e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0921, train/behavior_loss: 0.0205, train/strict_loss: 0.0117, val/iit_loss: 0.0781, val/IIA: 96.43%, val/accuracy: 98.92%, val/strict_accuracy: 99.19%\n",
      "Epoch 8: lr: 9.36e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0790, train/behavior_loss: 0.0201, train/strict_loss: 0.0098, val/iit_loss: 0.0720, val/IIA: 96.92%, val/accuracy: 97.94%, val/strict_accuracy: 98.74%\n",
      "Epoch 9: lr: 9.28e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0708, train/behavior_loss: 0.0181, train/strict_loss: 0.0084, val/iit_loss: 0.0689, val/IIA: 96.73%, val/accuracy: 98.73%, val/strict_accuracy: 99.28%\n",
      "Epoch 10: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0724, train/behavior_loss: 0.0173, train/strict_loss: 0.0078, val/iit_loss: 0.0639, val/IIA: 97.71%, val/accuracy: 97.05%, val/strict_accuracy: 98.35%\n",
      "Epoch 11: lr: 9.12e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0606, train/behavior_loss: 0.0182, train/strict_loss: 0.0078, val/iit_loss: 0.0550, val/IIA: 96.91%, val/accuracy: 99.58%, val/strict_accuracy: 99.54%\n",
      "Epoch 12: lr: 9.04e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0672, train/behavior_loss: 0.0206, train/strict_loss: 0.0083, val/iit_loss: 0.0815, val/IIA: 97.41%, val/accuracy: 94.90%, val/strict_accuracy: 95.54%\n",
      "Epoch 13: lr: 8.96e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0531, train/behavior_loss: 0.0184, train/strict_loss: 0.0074, val/iit_loss: 0.0533, val/IIA: 97.32%, val/accuracy: 98.94%, val/strict_accuracy: 99.20%\n",
      "Epoch 14: lr: 8.88e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.0577, train/behavior_loss: 0.0168, train/strict_loss: 0.0070, val/iit_loss: 0.0465, val/IIA: 98.29%, val/accuracy: 97.17%, val/strict_accuracy: 98.27%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mpoly_hl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_pair\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:282\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    279\u001b[0m batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    281\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_train_epoch(train_loader, loss_fn, optimizer, batch_pbar)\n\u001b[0;32m--> 282\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_eval_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_scheduler(lr_scheduler, test_metrics)\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:346\u001b[0m, in \u001b[0;36mBaseModelPair._run_eval_epoch\u001b[0;34m(self, loader, loss_fn)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m t\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    345\u001b[0m         test_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 346\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m         )\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m test_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:156\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_eval_step\u001b[0;34m(self, base_input, ablation_input, loss_fn)\u001b[0m\n\u001b[1;32m    154\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit:\n\u001b[0;32m--> 156\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mll_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_hooks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfwd_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_ll_ablation_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     ll_output \u001b[38;5;241m=\u001b[39m out[label_idx\u001b[38;5;241m.\u001b[39mas_index]\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhl_model\u001b[38;5;241m.\u001b[39mis_categorical():\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/hook_points.py:401\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_hooks\u001b[0;34m(self, fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: Hooks will be reset at the end of run_with_hooks. This removes the backward hooks before a backward pass can occur.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m     )\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(fwd_hooks, bwd_hooks, reset_hooks_end, clear_contexts) \u001b[38;5;28;01mas\u001b[39;00m hooked_model:\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhooked_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/HookedTransformer.py:550\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    547\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    548\u001b[0m         )\n\u001b[0;32m--> 550\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:1588\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1579\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1581\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_out(\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[1;32m   1585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[1;32m   1586\u001b[0m         query_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(query_input)\n\u001b[1;32m   1587\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[0;32m-> 1588\u001b[0m         key_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[1;32m   1590\u001b[0m         value_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(value_input),\n\u001b[1;32m   1591\u001b[0m         past_kv_cache_entry\u001b[38;5;241m=\u001b[39mpast_kv_cache_entry,\n\u001b[1;32m   1592\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1593\u001b[0m     )\n\u001b[1;32m   1594\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m   1596\u001b[0m     resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(resid_pre \u001b[38;5;241m+\u001b[39m attn_out)  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/transformer_lens/components.py:315\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    312\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    314\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# [batch, pos, length]\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m scale: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos 1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhook_scale\u001b[49m(\n\u001b[1;32m    316\u001b[0m     (x\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\u001b[38;5;241m.\u001b[39msqrt()\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    318\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m/\u001b[39m scale  \u001b[38;5;66;03m# [batch, pos, length]\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_normalized(x \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1696\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1698\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model().to(poly_hl_model.device)\n",
    "ll_model.device = poly_hl_model.device\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_poly_model_to_dir(ll_model, poly_hl_model, f\"./saved_poly_models/cases_1+2+3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0) DuplicateRemover + (1) LeftGreater + (2) ParenChecker + (3) UniqueExtractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[prev_equal_hook], [mlp0_hook], [mlp0_hook], [appeared_mlp]]\n",
      "blocks.0.attn.hook_z.0 [[prev_token_hook], None, None, None]\n",
      "blocks.0.attn.hook_z.1 [None, [paren_counts_hook], None, None]\n",
      "blocks.0.attn.hook_z.2 [None, None, None, [counter_head]]\n",
      "blocks.0.attn.hook_z.3 [None, None, [paren_counts_hook], None]\n",
      "blocks.1.mlp.hook_post [[output_hook], None, [mlp1_hook], [mask_mlp]]\n",
      "blocks.1.attn.hook_z.0 [None, None, None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None, None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None, None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None, None, None]\n",
      "blocks.2.mlp.hook_post [None, None, [mlp2_hook], [output_mlp]]\n",
      "blocks.2.attn.hook_z.0 [None, None, None, None]\n",
      "blocks.2.attn.hook_z.1 [None, None, None, None]\n",
      "blocks.2.attn.hook_z.2 [None, None, None, None]\n",
      "blocks.2.attn.hook_z.3 [None, None, [horizon_lookback_hook], None]\n"
     ]
    }
   ],
   "source": [
    "cases = [Case0, Case1, Case2, Case3]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=1)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)\n",
    "\n",
    "dataset_cases = [dataset_mapping[case] for case in cases]\n",
    "dsets = [dsetcase(N_samples=n_samples, n_ctx=n_ctx, seed=seed) for dsetcase in dataset_cases]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  mps\n",
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "attn_hooks.0.2 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "[LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0.2, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 42, 'detach_while_caching': True, 'optimizer_cls': <class 'torch.optim.adam.Adam'>, 'optimizer_kwargs': {'lr': 0.001, 'betas': (0.9, 0.9)}, 'atol': 0.05, 'use_single_loss': True, 'iit_weight': 1.0, 'behavior_weight': 0.4, 'val_IIA_sampling': 'all', 'strict_weight': 0.4, 'siit_sampling': 'sample_all'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aacabbe3568342a4a7d3df1ff9145488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef9b96adad3450aafee0238dcc015e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Batches:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.92e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.7291, train/behavior_loss: 0.2524, train/strict_loss: 0.1103, val/iit_loss: 0.3870, val/IIA: 86.22%, val/accuracy: 91.63%, val/strict_accuracy: 91.31%\n",
      "Epoch 2: lr: 9.84e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.3005, train/behavior_loss: 0.0633, train/strict_loss: 0.0347, val/iit_loss: 0.2351, val/IIA: 91.75%, val/accuracy: 94.55%, val/strict_accuracy: 94.21%\n",
      "Epoch 3: lr: 9.76e-04, iit_weight: 1.00e+00, behavior_weight: 4.00e-01, strict_weight: 4.00e-01, train/iit_loss: 0.2001, train/behavior_loss: 0.0286, train/strict_loss: 0.0277, val/iit_loss: 0.1544, val/IIA: 94.96%, val/accuracy: 96.65%, val/strict_accuracy: 96.43%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m model_pair \u001b[38;5;241m=\u001b[39m StrictIITModelPair(hl_model\u001b[38;5;241m=\u001b[39mpoly_hl_model, ll_model\u001b[38;5;241m=\u001b[39mll_model, corr\u001b[38;5;241m=\u001b[39mcorr, training_args\u001b[38;5;241m=\u001b[39mtraining_args)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_pair\u001b[38;5;241m.\u001b[39mnodes_not_in_circuit)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:281\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, epochs, use_wandb, wandb_name_suffix)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    279\u001b[0m     batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 281\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval_epoch(test_loader, loss_fn)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:330\u001b[0m, in \u001b[0;36mBaseModelPair._run_train_epoch\u001b[0;34m(self, loader, loss_fn, optimizer, pbar)\u001b[0m\n\u001b[1;32m    327\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_metrics()\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    329\u001b[0m     train_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    332\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:132\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_train_step\u001b[0;34m(self, base_input, ablation_input, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_single_loss:\n\u001b[1;32m    131\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m iit_loss \u001b[38;5;241m+\u001b[39m behavior_loss \u001b[38;5;241m+\u001b[39m siit_loss\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_on_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/iit_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: iit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/behavior_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: behavior_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain/strict_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: siit_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    138\u001b[0m }\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:65\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.step_on_loss\u001b[0;34m(self, loss, optimizer)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_on_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss: Tensor, optimizer: t\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_fn()\n\u001b[1;32m     67\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/polysemantic-benchmark/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model().to(poly_hl_model.device)\n",
    "ll_model.device = poly_hl_model.device\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    epochs=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_poly_model_to_dir(ll_model, poly_hl_model, f\"./saved_poly_models/cases_0+1+2+3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b849c8b4b854a1c9e4dd3daa3907a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/162k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68cf07700b24609923279f6c256bb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/162k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a355976816ba415c80b69c0512a60e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 11 LFS files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0102f11025448e9233ef61ca6a076b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/68.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f8f9e659a64a0481b9c1b614d8f68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102d650dca6b44de8cf96f5494ea731f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/68.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48f0b0ce25e4b428ff82a488e9a9a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/162k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0348cf7217d042f09cf02b502709ecfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/162k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250f0f80f7854a978f2967448aa94fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/68.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9cbe89e1ee46d499d2f68b02a6deab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/162k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a058729a7654796a6d5861494ba0bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/162k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9011a1714124d4f87ea9b04987721ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/162k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_to_hf(local_dir=\"saved_poly_models\", message=\"pushes all polysemantic models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
