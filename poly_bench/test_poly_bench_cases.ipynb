{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paren Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import torch\n",
    "from cases.paren_checker import HighLevelParensBalanceChecker, test_HL_parens_balancer_components, BalancedParensDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Balance tests passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_HL_parens_balancer_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making IIT dataset\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelParensBalanceChecker()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = BalancedParensDataset(N_samples=5_000, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 4)\n",
      "[[3, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 2], [3, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2], [3, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 2], [3, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 2], [3, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2], [3, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2], [3, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2], [3, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2], [3, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 2], [3, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 2]]\n",
      "[[[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.get_dataset().shape)\n",
    "print(dataset.get_dataset()[:10]['tokens'])\n",
    "print(dataset.get_dataset()[:10]['labels'])\n",
    "for i in range(10):\n",
    "    tokens, labels, hl_outputs = dataset.get_dataset()[i]['tokens'], dataset.get_dataset()[i]['labels'], hl_model((torch.tensor(dataset.get_dataset()[i]['tokens'])[None,:], None, None))\n",
    "    nonzero = (torch.tensor(labels) - hl_outputs[0]).nonzero()\n",
    "    if nonzero.numel() > 0:\n",
    "        print(tokens, torch.unique(nonzero[:,0]))\n",
    "        bad_indices = torch.unique(nonzero[:,0]).tolist()\n",
    "        for idx in bad_indices:\n",
    "            print(labels[idx], hl_outputs[0,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iit.model_pairs.strict_iit_model_pair import StrictIITModelPair\n",
    "from iit.utils.index import Ix\n",
    "import torch\n",
    "\n",
    "n_epochs = 100\n",
    "training_args = {\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "    \"use_single_loss\": False,\n",
    "    \"behavior_weight\": 0., #basically doubles the strict weight's job.\n",
    "    \"iit_weight\": 1.,\n",
    "    \"strict_weight\": 1.0,\n",
    "    \"clip_grad_norm\": 1.0,\n",
    "    \"iit_weight_schedule\" : lambda s, i: s,\n",
    "    \"strict_weight_schedule\" : lambda s, i: s,\n",
    "    \"behavior_weight_schedule\" : lambda s, i: s, #0.955*s if 0.955**i > 0.01 else s, #have behavior weight decay over time\n",
    "    \"early_stop\" : True,\n",
    "    \"lr_scheduler\": torch.optim.lr_scheduler.LinearLR,\n",
    "    \"scheduler_kwargs\": dict(start_factor=1, end_factor=0, total_iters=n_epochs),\n",
    "    \"scheduler_val_metric\": [\"val/accuracy\", \"val/IIA\"], #for ReduceLRonPlateau\n",
    "    \"scheduler_mode\": \"max\", #for ReduceLRonPlateau\n",
    "}\n",
    "\n",
    "class LastTokenStrictIITModelPair(StrictIITModelPair):\n",
    "    def get_label_idxs(self):\n",
    "        return Ix[[None,-1]]\n",
    "\n",
    "    # def loss_fn(self) -> Callable[[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "    #     return torch.nn.CrossEntropyLoss()\n",
    "\n",
    "ll_model = hl_model.get_ll_model()\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args={'batch_size': 256, 'lr': 0.001, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 0, 'detach_while_caching': True, 'iit_weight_schedule': <function <lambda> at 0x17fb9d760>, 'strict_weight_schedule': <function <lambda> at 0x17fb9d080>, 'behavior_weight_schedule': <function <lambda> at 0x17fbfe160>, 'atol': 0.05, 'use_single_loss': False, 'iit_weight': 1.0, 'behavior_weight': 0.0, 'strict_weight': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8fdbfaba8544828eccf715e1e6bc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.26e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.28e-01, val/iit_loss: 2.05e-01, val/IIA: 94.15, val/accuracy: 93.91, val/strict_accuracy: 93.91\n",
      "Epoch 2: lr: 9.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.07e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.59e-01, val/iit_loss: 2.25e-01, val/IIA: 92.46, val/accuracy: 96.38, val/strict_accuracy: 96.38\n",
      "Epoch 3: lr: 9.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.83e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 8.44e-02, val/iit_loss: 1.29e-01, val/IIA: 96.19, val/accuracy: 98.63, val/strict_accuracy: 98.63\n",
      "Epoch 4: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.64e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.97e-02, val/iit_loss: 1.13e-01, val/IIA: 96.98, val/accuracy: 99.63, val/strict_accuracy: 99.63\n",
      "Epoch 5: lr: 9.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.56e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.59e-02, val/iit_loss: 1.31e-01, val/IIA: 95.95, val/accuracy: 99.64, val/strict_accuracy: 99.64\n",
      "Epoch 6: lr: 9.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.16e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.31e-02, val/iit_loss: 9.15e-02, val/IIA: 97.09, val/accuracy: 99.54, val/strict_accuracy: 99.54\n",
      "Epoch 7: lr: 9.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.05e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.85e-02, val/iit_loss: 1.71e-01, val/IIA: 94.10, val/accuracy: 99.98, val/strict_accuracy: 99.98\n",
      "Epoch 8: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.88e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.72e-02, val/iit_loss: 6.97e-02, val/IIA: 97.57, val/accuracy: 99.96, val/strict_accuracy: 99.96\n",
      "Epoch 9: lr: 9.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.18e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.13e-02, val/iit_loss: 8.42e-02, val/IIA: 97.50, val/accuracy: 99.20, val/strict_accuracy: 99.20\n",
      "Epoch 10: lr: 9.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.79e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.32e-02, val/iit_loss: 5.36e-02, val/IIA: 98.01, val/accuracy: 99.96, val/strict_accuracy: 99.96\n",
      "Epoch 11: lr: 8.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.83e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 7.11e-03, val/iit_loss: 3.88e-02, val/IIA: 98.67, val/accuracy: 99.84, val/strict_accuracy: 99.84\n",
      "Epoch 12: lr: 8.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.01e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 7.52e-03, val/iit_loss: 1.41e-01, val/IIA: 95.56, val/accuracy: 99.91, val/strict_accuracy: 99.91\n",
      "Epoch 13: lr: 8.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.96e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 4.66e-03, val/iit_loss: 4.07e-02, val/IIA: 98.61, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 14: lr: 8.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.63e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 4.42e-03, val/iit_loss: 1.15e-01, val/IIA: 96.26, val/accuracy: 99.90, val/strict_accuracy: 99.90\n",
      "Epoch 15: lr: 8.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.73e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.56e-03, val/iit_loss: 8.54e-02, val/IIA: 97.41, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 16: lr: 8.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.47e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 6.99e-03, val/iit_loss: 1.02e-01, val/IIA: 96.25, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 17: lr: 8.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.90e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.54e-03, val/iit_loss: 3.55e-02, val/IIA: 99.03, val/accuracy: 99.99, val/strict_accuracy: 99.99\n",
      "Epoch 18: lr: 8.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.84e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.46e-03, val/iit_loss: 4.14e-02, val/IIA: 98.15, val/accuracy: 99.29, val/strict_accuracy: 99.29\n",
      "Epoch 19: lr: 8.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.76e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.24e-03, val/iit_loss: 4.24e-02, val/IIA: 98.41, val/accuracy: 99.98, val/strict_accuracy: 99.98\n",
      "Epoch 20: lr: 8.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.46e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 8.55e-03, val/iit_loss: 1.08e-01, val/IIA: 96.29, val/accuracy: 99.53, val/strict_accuracy: 99.53\n",
      "Epoch 21: lr: 7.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.96e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.18e-03, val/iit_loss: 9.64e-02, val/IIA: 96.67, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 22: lr: 7.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.91e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.81e-03, val/iit_loss: 5.97e-02, val/IIA: 98.19, val/accuracy: 99.72, val/strict_accuracy: 99.72\n",
      "Epoch 23: lr: 7.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.61e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.08e-03, val/iit_loss: 5.67e-03, val/IIA: 99.95, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 24: lr: 7.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.79e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.38e-03, val/iit_loss: 9.73e-02, val/IIA: 96.53, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 25: lr: 7.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.17e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.18e-03, val/iit_loss: 8.20e-02, val/IIA: 96.95, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 26: lr: 7.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.39e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.82e-03, val/iit_loss: 6.36e-02, val/IIA: 97.61, val/accuracy: 99.49, val/strict_accuracy: 99.49\n",
      "Epoch 27: lr: 7.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.38e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 4.17e-03, val/iit_loss: 3.11e-03, val/IIA: 99.99, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 28: lr: 7.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.90e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.30e-03, val/iit_loss: 2.22e-02, val/IIA: 99.25, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 29: lr: 7.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.75e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.05e-03, val/iit_loss: 3.26e-02, val/IIA: 98.94, val/accuracy: 99.98, val/strict_accuracy: 99.98\n",
      "Epoch 30: lr: 7.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.49e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.33e-03, val/iit_loss: 3.04e-02, val/IIA: 98.84, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 31: lr: 6.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.65e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.20e-03, val/iit_loss: 4.02e-02, val/IIA: 98.54, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 32: lr: 6.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.79e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.25e-03, val/iit_loss: 7.53e-02, val/IIA: 97.32, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 33: lr: 6.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.64e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.96e-03, val/iit_loss: 4.55e-03, val/IIA: 99.90, val/accuracy: 99.99, val/strict_accuracy: 99.99\n",
      "Epoch 34: lr: 6.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.14e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.82e-03, val/iit_loss: 4.70e-02, val/IIA: 98.35, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 35: lr: 6.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.16e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.12e-03, val/iit_loss: 1.84e-02, val/IIA: 99.31, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 36: lr: 6.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.41e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 8.90e-04, val/iit_loss: 6.27e-02, val/IIA: 97.74, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 37: lr: 6.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.45e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.34e-03, val/iit_loss: 2.00e-02, val/IIA: 99.24, val/accuracy: 99.99, val/strict_accuracy: 99.99\n",
      "Epoch 38: lr: 6.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.90e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.42e-03, val/iit_loss: 1.32e-02, val/IIA: 99.51, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 39: lr: 6.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.36e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.09e-03, val/iit_loss: 1.32e-02, val/IIA: 99.49, val/accuracy: 99.99, val/strict_accuracy: 99.99\n",
      "Epoch 40: lr: 6.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.64e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.24e-03, val/iit_loss: 7.55e-02, val/IIA: 97.35, val/accuracy: 99.99, val/strict_accuracy: 99.99\n",
      "Epoch 41: lr: 5.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.33e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 7.38e-04, val/iit_loss: 4.34e-02, val/IIA: 98.33, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 42: lr: 5.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.24e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.64e-03, val/iit_loss: 2.70e-02, val/IIA: 98.97, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 43: lr: 5.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.17e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.53e-04, val/iit_loss: 4.32e-02, val/IIA: 98.45, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 44: lr: 5.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.65e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 6.31e-04, val/iit_loss: 2.88e-02, val/IIA: 99.10, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 45: lr: 5.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.64e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 8.30e-04, val/iit_loss: 1.55e-02, val/IIA: 99.48, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 46: lr: 5.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.46e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 7.01e-04, val/iit_loss: 6.19e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    "    optimizer_kwargs=dict(weight_decay=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left > Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All left greater tests passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cases.left_greater import HighLevelLeftGreater, test_HL_left_greater_components, LeftGreaterDataset\n",
    "\n",
    "test_HL_left_greater_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making IIT dataset\n",
      "{'input_hook': HookPoint(), 'left_parens_hook': HookPoint(), 'right_parens_hook': HookPoint(), 'mlp0_hook': HookPoint()}\n",
      "[input_hook, left_parens_hook, right_parens_hook, mlp0_hook]\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelLeftGreater()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = LeftGreaterDataset(N_samples=1_000, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()\n",
    "print(hl_model.hook_dict)\n",
    "print(list(corr.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args={'batch_size': 256, 'lr': 0.001, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 0, 'detach_while_caching': True, 'iit_weight_schedule': <function <lambda> at 0x17fb9d760>, 'strict_weight_schedule': <function <lambda> at 0x17fb9d080>, 'behavior_weight_schedule': <function <lambda> at 0x17fbfe160>, 'atol': 0.05, 'use_single_loss': False, 'iit_weight': 1.0, 'behavior_weight': 0.0, 'strict_weight': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09e6938be764ecca8a1fc69df1fa838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.63e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 1.57e+00, val/iit_loss: 1.22e+00, val/IIA: 39.32, val/accuracy: 36.75, val/strict_accuracy: 36.75\n",
      "Epoch 2: lr: 9.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.10e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 1.06e+00, val/iit_loss: 9.43e-01, val/IIA: 48.45, val/accuracy: 52.61, val/strict_accuracy: 52.61\n",
      "Epoch 3: lr: 9.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.66e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 8.37e-01, val/iit_loss: 7.67e-01, val/IIA: 72.09, val/accuracy: 74.48, val/strict_accuracy: 74.48\n",
      "Epoch 4: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.07e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.90e-01, val/iit_loss: 6.71e-01, val/IIA: 72.53, val/accuracy: 80.08, val/strict_accuracy: 80.08\n",
      "Epoch 5: lr: 9.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.19e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.68e-01, val/iit_loss: 5.57e-01, val/IIA: 79.64, val/accuracy: 84.87, val/strict_accuracy: 84.87\n",
      "Epoch 6: lr: 9.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.72e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.81e-01, val/iit_loss: 5.27e-01, val/IIA: 79.27, val/accuracy: 89.87, val/strict_accuracy: 89.87\n",
      "Epoch 7: lr: 9.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.88e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.66e-01, val/iit_loss: 4.55e-01, val/IIA: 84.79, val/accuracy: 94.11, val/strict_accuracy: 94.11\n",
      "Epoch 8: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.14e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.03e-01, val/iit_loss: 5.09e-01, val/IIA: 79.79, val/accuracy: 96.28, val/strict_accuracy: 96.28\n",
      "Epoch 9: lr: 9.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.53e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.40e-01, val/iit_loss: 3.30e-01, val/IIA: 89.58, val/accuracy: 98.05, val/strict_accuracy: 98.05\n",
      "Epoch 10: lr: 9.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.74e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.84e-01, val/iit_loss: 5.10e-01, val/IIA: 80.04, val/accuracy: 99.08, val/strict_accuracy: 99.08\n",
      "Epoch 11: lr: 8.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.60e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.66e-01, val/iit_loss: 4.84e-01, val/IIA: 80.49, val/accuracy: 99.37, val/strict_accuracy: 99.37\n",
      "Epoch 12: lr: 8.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.88e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.38e-01, val/iit_loss: 1.29e-01, val/IIA: 99.41, val/accuracy: 99.59, val/strict_accuracy: 99.59\n",
      "Epoch 13: lr: 8.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.96e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.07e-01, val/iit_loss: 2.23e-01, val/IIA: 92.19, val/accuracy: 99.52, val/strict_accuracy: 99.52\n",
      "Epoch 14: lr: 8.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.18e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 9.44e-02, val/iit_loss: 9.19e-02, val/IIA: 99.59, val/accuracy: 99.85, val/strict_accuracy: 99.85\n",
      "Epoch 15: lr: 8.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.36e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.83e-02, val/iit_loss: 1.28e-01, val/IIA: 98.82, val/accuracy: 99.71, val/strict_accuracy: 99.71\n",
      "Epoch 16: lr: 8.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.50e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.53e-02, val/iit_loss: 1.23e-01, val/IIA: 98.78, val/accuracy: 99.89, val/strict_accuracy: 99.89\n",
      "Epoch 17: lr: 8.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.18e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.15e-02, val/iit_loss: 1.13e-01, val/IIA: 99.04, val/accuracy: 99.71, val/strict_accuracy: 99.71\n",
      "Epoch 18: lr: 8.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.11e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.44e-02, val/iit_loss: 1.04e-01, val/IIA: 99.34, val/accuracy: 99.89, val/strict_accuracy: 99.89\n",
      "Epoch 19: lr: 8.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.88e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.00e-02, val/iit_loss: 4.98e-01, val/IIA: 82.40, val/accuracy: 99.74, val/strict_accuracy: 99.74\n",
      "Epoch 20: lr: 8.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.12e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.55e-02, val/iit_loss: 1.59e-01, val/IIA: 94.85, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 21: lr: 7.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.94e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.06e-02, val/iit_loss: 4.85e-02, val/IIA: 99.89, val/accuracy: 99.85, val/strict_accuracy: 99.85\n",
      "Epoch 22: lr: 7.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.19e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 4.71e-02, val/iit_loss: 6.95e-02, val/IIA: 99.82, val/accuracy: 99.96, val/strict_accuracy: 99.96\n",
      "Epoch 23: lr: 7.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.84e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.95e-02, val/iit_loss: 4.21e-02, val/IIA: 99.89, val/accuracy: 99.96, val/strict_accuracy: 99.96\n",
      "Epoch 24: lr: 7.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.47e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.95e-02, val/iit_loss: 6.72e-02, val/IIA: 99.63, val/accuracy: 99.74, val/strict_accuracy: 99.74\n",
      "Epoch 25: lr: 7.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.09e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 4.11e-02, val/iit_loss: 6.33e-02, val/IIA: 99.67, val/accuracy: 99.96, val/strict_accuracy: 99.96\n",
      "Epoch 26: lr: 7.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.01e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.63e-02, val/iit_loss: 5.74e-02, val/IIA: 99.74, val/accuracy: 99.96, val/strict_accuracy: 99.96\n",
      "Epoch 27: lr: 7.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.94e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.59e-02, val/iit_loss: 3.65e-02, val/IIA: 100.00, val/accuracy: 99.96, val/strict_accuracy: 99.96\n",
      "Epoch 28: lr: 7.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.02e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.70e-02, val/iit_loss: 4.84e-02, val/IIA: 99.59, val/accuracy: 99.78, val/strict_accuracy: 99.78\n",
      "Epoch 29: lr: 7.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.09e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.73e-02, val/iit_loss: 5.20e-02, val/IIA: 99.63, val/accuracy: 99.93, val/strict_accuracy: 99.93\n",
      "Epoch 30: lr: 7.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.06e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.10e-02, val/iit_loss: 4.33e-01, val/IIA: 85.09, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 31: lr: 6.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.32e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.82e-02, val/iit_loss: 9.54e-02, val/IIA: 97.24, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 32: lr: 6.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.44e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.08e-02, val/iit_loss: 3.11e-02, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "ll_model = hl_model.get_ll_model()\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    "    optimizer_kwargs=dict(weight_decay=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
