{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cases.paren_checker import HighLevelParensBalanceChecker, test_HL_parens_balancer_components, BalancedParensDataset\n",
    "from cases.left_greater import HighLevelLeftGreater, test_HL_left_greater_components, LeftGreaterDataset\n",
    "from cases.duplicate_remover import HighLevelDuplicateRemover, test_HL_duplicate_remover_components, DuplicateRemoverDataset\n",
    "from poly_hl_model import PolyHLModel, PolyModelDataset\n",
    "\n",
    "from iit.model_pairs.strict_iit_model_pair import StrictIITModelPair\n",
    "from iit.utils.index import Ix\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paren Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Balance tests passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_HL_parens_balancer_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m hl_model \u001b[38;5;241m=\u001b[39m HighLevelParensBalanceChecker()\n\u001b[1;32m      2\u001b[0m corr \u001b[38;5;241m=\u001b[39m hl_model\u001b[38;5;241m.\u001b[39mget_correspondence()\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mBalancedParensDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ll_model_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m train_set, test_set \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_IIT_train_test_set()\n",
      "File \u001b[0;32m~/far_cluster/circuits-benchmark-saes/poly_bench/cases/paren_checker.py:187\u001b[0m, in \u001b[0;36mBalancedParensDataset.__init__\u001b[0;34m(self, N_samples, map_dict, n_ctx, seed)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    182\u001b[0m     N_samples: \u001b[38;5;28mint\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m     seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m    186\u001b[0m ):\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mN_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/circuits-benchmark-saes/poly_bench/cases/poly_case.py:66\u001b[0m, in \u001b[0;36mPolyBenchDataset.__init__\u001b[0;34m(self, N_samples, map_dict, n_ctx, seed)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_tokens()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_tokens_to_str()\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_dataset()\n",
      "File \u001b[0;32m~/far_cluster/circuits-benchmark-saes/poly_bench/cases/paren_checker.py:299\u001b[0m, in \u001b[0;36mBalancedParensDataset.generate_labels\u001b[0;34m(self, skip_first)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     sample \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 299\u001b[0m new_markers[i,\u001b[38;5;241m1\u001b[39m:][\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpasses_balance_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    300\u001b[0m new_markers[i,\u001b[38;5;241m1\u001b[39m:][np\u001b[38;5;241m.\u001b[39mlogical_and(\u001b[38;5;241m~\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpasses_balance(sample), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpasses_horizon(sample))] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    301\u001b[0m new_markers[i,\u001b[38;5;241m1\u001b[39m:][np\u001b[38;5;241m.\u001b[39mlogical_and(\u001b[38;5;241m~\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpasses_horizon(sample), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpasses_balance(sample))] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[0;32m~/far_cluster/circuits-benchmark-saes/poly_bench/cases/paren_checker.py:209\u001b[0m, in \u001b[0;36mBalancedParensDataset.passes_balance_test\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpasses_balance_test\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample):\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpasses_balance(sample)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpasses_horizon\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/circuits-benchmark-saes/poly_bench/cases/paren_checker.py:202\u001b[0m, in \u001b[0;36mBalancedParensDataset.passes_horizon\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    200\u001b[0m mod[mod \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    201\u001b[0m mod[mod \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 202\u001b[0m horizon \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m horizon_bool \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(horizon\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    204\u001b[0m horizon_bool[horizon \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/circuits_bench/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2508\u001b[0m, in \u001b[0;36m_cumsum_dispatcher\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2423\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;124;03m    Test whether all array elements along a given axis evaluate to True.\u001b[39;00m\n\u001b[1;32m   2425\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2502\u001b[0m \n\u001b[1;32m   2503\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39mlogical_and, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out,\n\u001b[1;32m   2505\u001b[0m                           keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[0;32m-> 2508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cumsum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   2512\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_cumsum_dispatcher)\n\u001b[1;32m   2513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcumsum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelParensBalanceChecker()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = BalancedParensDataset(N_samples=5_000, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 4)\n",
      "[[3, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0], [3, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0], [3, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1], [3, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1], [3, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1], [3, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0], [3, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0], [3, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0]]\n",
      "[[[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.get_dataset().shape)\n",
    "print(dataset.get_dataset()[:10]['tokens'])\n",
    "print(dataset.get_dataset()[:10]['labels'])\n",
    "for i in range(10):\n",
    "    tokens, labels, hl_outputs = dataset.get_dataset()[i]['tokens'], dataset.get_dataset()[i]['labels'], hl_model((torch.tensor(dataset.get_dataset()[i]['tokens'])[None,:], None, None))\n",
    "    nonzero = (torch.tensor(labels) - hl_outputs[0].cpu()).nonzero()\n",
    "    if nonzero.numel() > 0:\n",
    "        print(tokens, torch.unique(nonzero[:,0]))\n",
    "        bad_indices = torch.unique(nonzero[:,0]).tolist()\n",
    "        for idx in bad_indices:\n",
    "            print(labels[idx], hl_outputs[0,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_epochs = 100\n",
    "training_args = {\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "    \"use_single_loss\": False,\n",
    "    \"behavior_weight\": 0., #basically doubles the strict weight's job.\n",
    "    \"iit_weight\": 1.,\n",
    "    \"strict_weight\": 1.0,\n",
    "    \"clip_grad_norm\": 1.0,\n",
    "    \"iit_weight_schedule\" : lambda s, i: s,\n",
    "    \"strict_weight_schedule\" : lambda s, i: s,\n",
    "    \"behavior_weight_schedule\" : lambda s, i: s, #0.955*s if 0.955**i > 0.01 else s, #have behavior weight decay over time\n",
    "    \"early_stop\" : True,\n",
    "    \"lr_scheduler\": torch.optim.lr_scheduler.LinearLR,\n",
    "    \"scheduler_kwargs\": dict(start_factor=1, end_factor=0, total_iters=n_epochs),\n",
    "    \"scheduler_val_metric\": [\"val/accuracy\", \"val/IIA\"], #for ReduceLRonPlateau\n",
    "    \"scheduler_mode\": \"max\", #for ReduceLRonPlateau\n",
    "}\n",
    "\n",
    "class LastTokenStrictIITModelPair(StrictIITModelPair):\n",
    "    def get_label_idxs(self):\n",
    "        return Ix[[None,-1]]\n",
    "\n",
    "    # def loss_fn(self) -> Callable[[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "    #     return torch.nn.CrossEntropyLoss()\n",
    "\n",
    "ll_model = hl_model.get_ll_model()\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args={'batch_size': 256, 'lr': 0.001, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 0, 'detach_while_caching': True, 'iit_weight_schedule': <function <lambda> at 0x1041b6ca0>, 'strict_weight_schedule': <function <lambda> at 0x1041b68e0>, 'behavior_weight_schedule': <function <lambda> at 0x1677a6c00>, 'atol': 0.05, 'use_single_loss': False, 'iit_weight': 1.0, 'behavior_weight': 0.0, 'strict_weight': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2514e844ca7e4089b4aacebc64564f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.07e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.60e-01, val/iit_loss: 1.82e-01, val/IIA: 95.50, val/accuracy: 95.16, val/strict_accuracy: 95.16\n",
      "Epoch 2: lr: 9.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.68e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.29e-01, val/iit_loss: 1.33e-01, val/IIA: 95.79, val/accuracy: 96.67, val/strict_accuracy: 96.67\n",
      "Epoch 3: lr: 9.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.45e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.62e-02, val/iit_loss: 1.09e-01, val/IIA: 96.75, val/accuracy: 98.90, val/strict_accuracy: 98.90\n",
      "Epoch 4: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.19e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.31e-02, val/iit_loss: 1.25e-01, val/IIA: 96.22, val/accuracy: 97.81, val/strict_accuracy: 97.81\n",
      "Epoch 5: lr: 9.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.52e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.43e-02, val/iit_loss: 8.67e-02, val/IIA: 97.42, val/accuracy: 99.20, val/strict_accuracy: 99.20\n",
      "Epoch 6: lr: 9.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.24e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.23e-02, val/iit_loss: 3.80e-02, val/IIA: 98.61, val/accuracy: 99.49, val/strict_accuracy: 99.49\n",
      "Epoch 7: lr: 9.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.82e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.83e-02, val/iit_loss: 1.49e-01, val/IIA: 95.22, val/accuracy: 96.93, val/strict_accuracy: 96.93\n",
      "Epoch 8: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.08e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.72e-02, val/iit_loss: 2.49e-02, val/IIA: 99.63, val/accuracy: 99.93, val/strict_accuracy: 99.93\n",
      "Epoch 9: lr: 9.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.86e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.33e-02, val/iit_loss: 1.65e-02, val/IIA: 99.66, val/accuracy: 99.91, val/strict_accuracy: 99.91\n",
      "Epoch 10: lr: 9.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.71e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.47e-02, val/iit_loss: 5.43e-02, val/IIA: 98.01, val/accuracy: 98.81, val/strict_accuracy: 98.81\n",
      "Epoch 11: lr: 8.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.00e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.33e-02, val/iit_loss: 3.68e-02, val/IIA: 98.86, val/accuracy: 99.99, val/strict_accuracy: 99.99\n",
      "Epoch 12: lr: 8.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.78e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 9.44e-03, val/iit_loss: 8.18e-02, val/IIA: 97.12, val/accuracy: 99.66, val/strict_accuracy: 99.66\n",
      "Epoch 13: lr: 8.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.53e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 8.97e-03, val/iit_loss: 5.55e-02, val/IIA: 98.03, val/accuracy: 99.96, val/strict_accuracy: 99.96\n",
      "Epoch 14: lr: 8.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.61e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 8.01e-03, val/iit_loss: 2.68e-02, val/IIA: 99.04, val/accuracy: 99.95, val/strict_accuracy: 99.95\n",
      "Epoch 15: lr: 8.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.63e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 8.16e-03, val/iit_loss: 3.59e-02, val/IIA: 98.91, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 16: lr: 8.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.64e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.97e-03, val/iit_loss: 4.22e-02, val/IIA: 98.60, val/accuracy: 99.99, val/strict_accuracy: 99.99\n",
      "Epoch 17: lr: 8.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.42e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 6.63e-03, val/iit_loss: 4.91e-02, val/IIA: 98.78, val/accuracy: 99.88, val/strict_accuracy: 99.88\n",
      "Epoch 18: lr: 8.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.64e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 4.98e-03, val/iit_loss: 9.05e-03, val/IIA: 99.78, val/accuracy: 99.89, val/strict_accuracy: 99.89\n",
      "Epoch 19: lr: 8.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.76e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.19e-03, val/iit_loss: 2.72e-02, val/IIA: 99.04, val/accuracy: 99.88, val/strict_accuracy: 99.88\n",
      "Epoch 20: lr: 8.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.37e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.25e-03, val/iit_loss: 1.90e-02, val/IIA: 99.30, val/accuracy: 99.98, val/strict_accuracy: 99.98\n",
      "Epoch 21: lr: 7.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.56e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 7.86e-03, val/iit_loss: 1.52e-02, val/IIA: 99.44, val/accuracy: 99.99, val/strict_accuracy: 99.99\n",
      "Epoch 22: lr: 7.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.81e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.78e-03, val/iit_loss: 3.27e-02, val/IIA: 98.87, val/accuracy: 99.98, val/strict_accuracy: 99.98\n",
      "Epoch 23: lr: 7.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.89e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.31e-03, val/iit_loss: 3.62e-03, val/IIA: 99.89, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 24: lr: 7.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.32e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.35e-03, val/iit_loss: 1.12e-02, val/IIA: 99.58, val/accuracy: 99.91, val/strict_accuracy: 99.91\n",
      "Epoch 25: lr: 7.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.02e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.52e-03, val/iit_loss: 1.59e-02, val/IIA: 99.46, val/accuracy: 99.99, val/strict_accuracy: 99.99\n",
      "Epoch 26: lr: 7.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.52e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.20e-03, val/iit_loss: 7.88e-03, val/IIA: 99.77, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 27: lr: 7.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.52e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.06e-03, val/iit_loss: 6.51e-03, val/IIA: 99.80, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 28: lr: 7.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.74e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 8.90e-04, val/iit_loss: 1.59e-03, val/IIA: 99.98, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 29: lr: 7.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.98e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.88e-03, val/iit_loss: 4.22e-03, val/IIA: 99.90, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 30: lr: 7.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.87e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.37e-03, val/iit_loss: 2.45e-02, val/IIA: 99.06, val/accuracy: 99.89, val/strict_accuracy: 99.89\n",
      "Epoch 31: lr: 6.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.77e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.19e-03, val/iit_loss: 6.97e-03, val/IIA: 99.79, val/accuracy: 99.89, val/strict_accuracy: 99.89\n",
      "Epoch 32: lr: 6.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.24e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.31e-03, val/iit_loss: 1.17e-02, val/IIA: 99.59, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 33: lr: 6.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.82e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 5.69e-04, val/iit_loss: 1.32e-03, val/IIA: 99.97, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 34: lr: 6.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.39e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 6.89e-04, val/iit_loss: 2.27e-03, val/IIA: 99.95, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 35: lr: 6.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.82e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 4.99e-04, val/iit_loss: 2.13e-02, val/IIA: 99.37, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 36: lr: 6.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.35e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 6.17e-04, val/iit_loss: 5.24e-03, val/IIA: 99.80, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 37: lr: 6.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.20e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 5.23e-04, val/iit_loss: 7.58e-04, val/IIA: 99.99, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 38: lr: 6.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.97e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 6.21e-04, val/iit_loss: 4.14e-03, val/IIA: 99.82, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 39: lr: 6.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.55e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 4.22e-04, val/iit_loss: 1.36e-03, val/IIA: 99.98, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 40: lr: 6.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.94e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 5.18e-04, val/iit_loss: 1.11e-02, val/IIA: 99.56, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 41: lr: 5.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.88e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 4.09e-04, val/iit_loss: 6.94e-03, val/IIA: 99.66, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 42: lr: 5.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.47e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 8.54e-04, val/iit_loss: 5.81e-03, val/IIA: 99.86, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 43: lr: 5.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.84e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 8.57e-04, val/iit_loss: 2.75e-02, val/IIA: 98.91, val/accuracy: 99.93, val/strict_accuracy: 99.93\n",
      "Epoch 44: lr: 5.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.26e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 8.21e-04, val/iit_loss: 1.37e-03, val/IIA: 99.99, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 45: lr: 5.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.72e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 6.61e-04, val/iit_loss: 9.80e-04, val/IIA: 99.99, val/accuracy: 99.99, val/strict_accuracy: 99.99\n",
      "Epoch 46: lr: 5.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.76e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 3.38e-04, val/iit_loss: 4.15e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 47: lr: 5.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.12e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 2.37e-04, val/iit_loss: 1.69e-02, val/IIA: 99.25, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 48: lr: 5.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.80e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 5.74e-04, val/iit_loss: 1.47e-02, val/IIA: 99.40, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 49: lr: 5.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.50e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 2.67e-04, val/iit_loss: 8.17e-03, val/IIA: 99.74, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 50: lr: 5.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.12e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 7.23e-04, val/iit_loss: 6.10e-03, val/IIA: 99.80, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 51: lr: 4.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.54e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 2.33e-04, val/iit_loss: 4.94e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 52: lr: 4.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.13e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 3.64e-04, val/iit_loss: 1.00e-02, val/IIA: 99.47, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 53: lr: 4.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.35e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 5.39e-04, val/iit_loss: 3.13e-03, val/IIA: 99.92, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 54: lr: 4.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.71e-04, train/behavior_loss: 0.00e+00, train/strict_loss: 2.25e-04, val/iit_loss: 4.66e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 55: lr: 4.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.61e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 3.52e-04, val/iit_loss: 1.61e-02, val/IIA: 99.38, val/accuracy: 99.96, val/strict_accuracy: 99.96\n",
      "Epoch 56: lr: 4.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.01e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 4.12e-04, val/iit_loss: 6.91e-03, val/IIA: 99.75, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 57: lr: 4.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.44e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 2.07e-04, val/iit_loss: 1.60e-03, val/IIA: 99.94, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 58: lr: 4.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.13e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 4.52e-04, val/iit_loss: 3.00e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 59: lr: 4.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.73e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 2.91e-04, val/iit_loss: 5.87e-04, val/IIA: 99.98, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 60: lr: 4.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.24e-04, train/behavior_loss: 0.00e+00, train/strict_loss: 1.48e-04, val/iit_loss: 2.62e-03, val/IIA: 99.93, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 61: lr: 3.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.03e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.62e-04, val/iit_loss: 2.10e-03, val/IIA: 99.95, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 62: lr: 3.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.20e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.45e-04, val/iit_loss: 2.49e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 63: lr: 3.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.98e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 4.12e-04, val/iit_loss: 2.52e-03, val/IIA: 99.94, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 64: lr: 3.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.02e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.56e-04, val/iit_loss: 2.50e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 65: lr: 3.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.43e-04, train/behavior_loss: 0.00e+00, train/strict_loss: 1.31e-04, val/iit_loss: 2.45e-03, val/IIA: 99.93, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 66: lr: 3.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.94e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.49e-04, val/iit_loss: 3.58e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 67: lr: 3.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.63e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.32e-04, val/iit_loss: 6.10e-04, val/IIA: 99.99, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 68: lr: 3.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.21e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 2.03e-04, val/iit_loss: 5.54e-04, val/IIA: 99.99, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 69: lr: 3.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.76e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.79e-04, val/iit_loss: 3.59e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 70: lr: 3.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.00e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 3.06e-04, val/iit_loss: 2.26e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 71: lr: 2.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.32e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.36e-04, val/iit_loss: 4.28e-04, val/IIA: 99.99, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 72: lr: 2.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.39e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.64e-04, val/iit_loss: 1.68e-03, val/IIA: 99.94, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 73: lr: 2.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.91e-04, train/behavior_loss: 0.00e+00, train/strict_loss: 1.25e-04, val/iit_loss: 2.57e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 74: lr: 2.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.55e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.19e-04, val/iit_loss: 2.74e-03, val/IIA: 99.90, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 75: lr: 2.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.69e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.28e-04, val/iit_loss: 8.37e-04, val/IIA: 99.97, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 76: lr: 2.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.32e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.69e-04, val/iit_loss: 1.93e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 77: lr: 2.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.95e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.04e-04, val/iit_loss: 4.08e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 78: lr: 2.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.96e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.33e-04, val/iit_loss: 1.67e-03, val/IIA: 99.95, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 79: lr: 2.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.30e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 2.50e-04, val/iit_loss: 1.96e-03, val/IIA: 99.93, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 80: lr: 2.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.31e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.79e-04, val/iit_loss: 1.83e-03, val/IIA: 99.95, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 81: lr: 1.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.43e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.30e-04, val/iit_loss: 3.05e-03, val/IIA: 99.93, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 82: lr: 1.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.68e-04, train/behavior_loss: 0.00e+00, train/strict_loss: 1.24e-04, val/iit_loss: 1.70e-03, val/IIA: 99.97, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 83: lr: 1.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.42e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.22e-04, val/iit_loss: 3.25e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 84: lr: 1.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.14e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.20e-04, val/iit_loss: 2.68e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 85: lr: 1.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.60e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.05e-04, val/iit_loss: 2.52e-03, val/IIA: 99.96, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 86: lr: 1.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.58e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 9.73e-05, val/iit_loss: 1.58e-03, val/IIA: 99.97, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 87: lr: 1.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.12e-04, train/behavior_loss: 0.00e+00, train/strict_loss: 1.05e-04, val/iit_loss: 3.34e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 88: lr: 1.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.58e-04, train/behavior_loss: 0.00e+00, train/strict_loss: 9.85e-05, val/iit_loss: 4.02e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 89: lr: 1.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.48e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.03e-04, val/iit_loss: 2.23e-03, val/IIA: 99.93, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 90: lr: 1.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.27e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.00e-04, val/iit_loss: 1.77e-03, val/IIA: 99.97, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 91: lr: 9.00e-05, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.16e-04, train/behavior_loss: 0.00e+00, train/strict_loss: 9.83e-05, val/iit_loss: 1.32e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 92: lr: 8.00e-05, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.09e-04, train/behavior_loss: 0.00e+00, train/strict_loss: 9.62e-05, val/iit_loss: 1.74e-03, val/IIA: 99.97, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 93: lr: 7.00e-05, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.17e-04, train/behavior_loss: 0.00e+00, train/strict_loss: 9.54e-05, val/iit_loss: 1.93e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 94: lr: 6.00e-05, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.10e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 9.57e-05, val/iit_loss: 2.37e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 95: lr: 5.00e-05, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.41e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 9.29e-05, val/iit_loss: 1.52e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 96: lr: 4.00e-05, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.40e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 9.12e-05, val/iit_loss: 3.13e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 97: lr: 3.00e-05, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.07e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 9.63e-05, val/iit_loss: 1.66e-03, val/IIA: 99.97, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 98: lr: 2.00e-05, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.47e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 9.44e-05, val/iit_loss: 4.16e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 99: lr: 1.00e-05, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.34e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 9.43e-05, val/iit_loss: 3.02e-04, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 100: lr: 0.00e+00, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.65e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 9.41e-05, val/iit_loss: 1.55e-03, val/IIA: 99.97, val/accuracy: 100.00, val/strict_accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    "    optimizer_kwargs=dict(weight_decay=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left > Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "All left greater tests passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cases.left_greater import HighLevelLeftGreater, test_HL_left_greater_components, LeftGreaterDataset\n",
    "\n",
    "test_HL_left_greater_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "making IIT dataset\n",
      "{'input_hook': HookPoint(), 'paren_counts_hook': HookPoint(), 'mlp0_hook': HookPoint()}\n",
      "[input_hook, paren_counts_hook, mlp0_hook]\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelLeftGreater()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = LeftGreaterDataset(N_samples=1_000, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()\n",
    "print(hl_model.hook_dict)\n",
    "print(list(corr.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args={'batch_size': 256, 'lr': 0.001, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 0, 'detach_while_caching': True, 'iit_weight_schedule': <function <lambda> at 0x1041b6ca0>, 'strict_weight_schedule': <function <lambda> at 0x1041b68e0>, 'behavior_weight_schedule': <function <lambda> at 0x1677a6c00>, 'atol': 0.05, 'use_single_loss': False, 'iit_weight': 1.0, 'behavior_weight': 0.0, 'strict_weight': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a9be099c764a3a8ca48780f365cfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.25e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 1.23e+00, val/iit_loss: 9.13e-01, val/IIA: 57.05, val/accuracy: 52.19, val/strict_accuracy: 52.19\n",
      "Epoch 2: lr: 9.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.54e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 8.03e-01, val/iit_loss: 7.66e-01, val/IIA: 63.89, val/accuracy: 70.82, val/strict_accuracy: 70.82\n",
      "Epoch 3: lr: 9.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.00e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.53e-01, val/iit_loss: 6.86e-01, val/IIA: 67.87, val/accuracy: 80.80, val/strict_accuracy: 80.80\n",
      "Epoch 4: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.85e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.47e-01, val/iit_loss: 6.45e-01, val/IIA: 69.28, val/accuracy: 84.86, val/strict_accuracy: 84.86\n",
      "Epoch 5: lr: 9.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.51e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.69e-01, val/iit_loss: 4.32e-01, val/IIA: 88.01, val/accuracy: 87.40, val/strict_accuracy: 87.40\n",
      "Epoch 6: lr: 9.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.53e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.88e-01, val/iit_loss: 4.09e-01, val/IIA: 88.07, val/accuracy: 89.98, val/strict_accuracy: 89.98\n",
      "Epoch 7: lr: 9.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.13e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.36e-01, val/iit_loss: 3.41e-01, val/IIA: 92.80, val/accuracy: 93.47, val/strict_accuracy: 93.47\n",
      "Epoch 8: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.47e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.65e-01, val/iit_loss: 2.34e-01, val/IIA: 95.28, val/accuracy: 95.71, val/strict_accuracy: 95.71\n",
      "Epoch 9: lr: 9.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.94e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.07e-01, val/iit_loss: 2.20e-01, val/IIA: 96.11, val/accuracy: 97.29, val/strict_accuracy: 97.29\n",
      "Epoch 10: lr: 9.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.41e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.65e-01, val/iit_loss: 2.15e-01, val/IIA: 95.04, val/accuracy: 97.92, val/strict_accuracy: 97.92\n",
      "Epoch 11: lr: 8.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.47e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.34e-01, val/iit_loss: 1.80e-01, val/IIA: 95.91, val/accuracy: 98.93, val/strict_accuracy: 98.93\n",
      "Epoch 12: lr: 8.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.30e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.08e-01, val/iit_loss: 1.01e-01, val/IIA: 99.30, val/accuracy: 99.26, val/strict_accuracy: 99.26\n",
      "Epoch 13: lr: 8.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.28e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 8.86e-02, val/iit_loss: 1.11e-01, val/IIA: 98.66, val/accuracy: 99.50, val/strict_accuracy: 99.50\n",
      "Epoch 14: lr: 8.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.49e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 7.43e-02, val/iit_loss: 7.47e-02, val/IIA: 99.43, val/accuracy: 99.60, val/strict_accuracy: 99.60\n",
      "Epoch 15: lr: 8.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.58e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 6.69e-02, val/iit_loss: 8.89e-02, val/IIA: 99.13, val/accuracy: 99.70, val/strict_accuracy: 99.70\n",
      "Epoch 16: lr: 8.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.95e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.83e-02, val/iit_loss: 7.72e-02, val/IIA: 99.40, val/accuracy: 99.83, val/strict_accuracy: 99.83\n",
      "Epoch 17: lr: 8.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.51e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.09e-02, val/iit_loss: 7.20e-02, val/IIA: 99.46, val/accuracy: 99.83, val/strict_accuracy: 99.83\n",
      "Epoch 18: lr: 8.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.55e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 4.69e-02, val/iit_loss: 6.52e-02, val/IIA: 99.43, val/accuracy: 99.83, val/strict_accuracy: 99.83\n",
      "Epoch 19: lr: 8.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.03e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 4.27e-02, val/iit_loss: 4.36e-02, val/IIA: 99.83, val/accuracy: 99.93, val/strict_accuracy: 99.93\n",
      "Epoch 20: lr: 8.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.96e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.78e-02, val/iit_loss: 5.25e-02, val/IIA: 99.70, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 21: lr: 7.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.40e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.38e-02, val/iit_loss: 3.54e-02, val/IIA: 99.93, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 22: lr: 7.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.12e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.07e-02, val/iit_loss: 4.39e-02, val/IIA: 99.73, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 23: lr: 7.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.64e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.84e-02, val/iit_loss: 3.00e-02, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "ll_model = hl_model.get_ll_model()\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    "    optimizer_kwargs=dict(weight_decay=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate remover\n",
    "case 19 in circuits-bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 0, 0, 1, 2, 0, 1, 3, 3], [4, 0, 1, 2, 2, 2, 2, 2, 2], [4, 0, 1, 2, 3, 3, 3, 3, 3]]\n",
      "[[False, False, True, False, False, False, False, False, True], [False, False, False, False, True, True, True, True, True], [False, False, False, False, False, True, True, True, True]]\n",
      "here\n",
      "All DuplicateRemover tests passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cases.duplicate_remover import HighLevelDuplicateRemover, test_HL_duplicate_remover_components, DuplicateRemoverDataset\n",
    "test_HL_duplicate_remover_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "(1000, 15, 5)\n",
      "making IIT dataset\n",
      "{'input_hook': HookPoint(), 'prev_token_hook': HookPoint(), 'prev_equal_hook': HookPoint(), 'output_hook': HookPoint()}\n",
      "[input_hook, prev_token_hook, prev_equal_hook, output_hook]\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelDuplicateRemover()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = DuplicateRemoverDataset(N_samples=1_000, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()\n",
    "print(hl_model.hook_dict)\n",
    "print(list(corr.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args={'batch_size': 256, 'lr': 0.001, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 0, 'detach_while_caching': True, 'iit_weight_schedule': <function <lambda> at 0x1041b6ca0>, 'strict_weight_schedule': <function <lambda> at 0x1041b68e0>, 'behavior_weight_schedule': <function <lambda> at 0x1677a6c00>, 'atol': 0.05, 'use_single_loss': False, 'iit_weight': 1.0, 'behavior_weight': 0.0, 'strict_weight': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9dd9b3659f7449b801f658b6fc75485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.63e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 1.55e+00, val/iit_loss: 1.30e+00, val/IIA: 37.89, val/accuracy: 38.26, val/strict_accuracy: 38.26\n",
      "Epoch 2: lr: 9.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.37e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 1.18e+00, val/iit_loss: 1.32e+00, val/IIA: 42.28, val/accuracy: 60.10, val/strict_accuracy: 60.10\n",
      "Epoch 3: lr: 9.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.12e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 9.40e-01, val/iit_loss: 1.22e+00, val/IIA: 45.33, val/accuracy: 65.09, val/strict_accuracy: 65.09\n",
      "Epoch 4: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.58e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.70e-01, val/iit_loss: 1.19e+00, val/IIA: 45.59, val/accuracy: 72.83, val/strict_accuracy: 72.83\n",
      "Epoch 5: lr: 9.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.99e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.56e-01, val/iit_loss: 6.03e-01, val/IIA: 76.85, val/accuracy: 75.11, val/strict_accuracy: 75.11\n",
      "Epoch 6: lr: 9.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.08e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 5.94e-01, val/iit_loss: 8.80e-01, val/IIA: 58.29, val/accuracy: 75.61, val/strict_accuracy: 75.61\n",
      "Epoch 7: lr: 9.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.05e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.66e-01, val/iit_loss: 1.01e+00, val/IIA: 54.74, val/accuracy: 75.78, val/strict_accuracy: 75.78\n",
      "Epoch 8: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.76e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.32e-01, val/iit_loss: 6.31e-01, val/IIA: 70.25, val/accuracy: 77.72, val/strict_accuracy: 77.72\n",
      "Epoch 9: lr: 9.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.10e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.04e-01, val/iit_loss: 8.09e-01, val/IIA: 62.14, val/accuracy: 78.99, val/strict_accuracy: 78.99\n",
      "Epoch 10: lr: 9.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.82e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.79e-01, val/iit_loss: 6.00e-01, val/IIA: 72.70, val/accuracy: 79.83, val/strict_accuracy: 79.83\n",
      "Epoch 11: lr: 8.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.78e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.51e-01, val/iit_loss: 5.88e-01, val/IIA: 72.46, val/accuracy: 81.41, val/strict_accuracy: 81.41\n",
      "Epoch 12: lr: 8.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.59e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.18e-01, val/iit_loss: 4.06e-01, val/IIA: 83.05, val/accuracy: 83.45, val/strict_accuracy: 83.45\n",
      "Epoch 13: lr: 8.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.52e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.83e-01, val/iit_loss: 6.07e-01, val/IIA: 73.67, val/accuracy: 84.52, val/strict_accuracy: 84.52\n",
      "Epoch 14: lr: 8.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.45e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.38e-01, val/iit_loss: 3.39e-01, val/IIA: 86.50, val/accuracy: 85.36, val/strict_accuracy: 85.36\n",
      "Epoch 15: lr: 8.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.56e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.25e-01, val/iit_loss: 3.98e-01, val/IIA: 84.82, val/accuracy: 89.38, val/strict_accuracy: 89.38\n",
      "Epoch 16: lr: 8.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.70e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.87e-01, val/iit_loss: 3.51e-01, val/IIA: 86.83, val/accuracy: 89.65, val/strict_accuracy: 89.65\n",
      "Epoch 17: lr: 8.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.59e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.74e-01, val/iit_loss: 3.20e-01, val/IIA: 88.24, val/accuracy: 89.88, val/strict_accuracy: 89.88\n",
      "Epoch 18: lr: 8.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.67e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.48e-01, val/iit_loss: 3.53e-01, val/IIA: 86.33, val/accuracy: 91.73, val/strict_accuracy: 91.73\n",
      "Epoch 19: lr: 8.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.36e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.79e-01, val/iit_loss: 6.24e-01, val/IIA: 76.72, val/accuracy: 90.32, val/strict_accuracy: 90.32\n",
      "Epoch 20: lr: 8.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.74e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.12e-01, val/iit_loss: 4.65e-01, val/IIA: 79.33, val/accuracy: 93.23, val/strict_accuracy: 93.23\n",
      "Epoch 21: lr: 7.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.95e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.95e-01, val/iit_loss: 1.91e-01, val/IIA: 94.07, val/accuracy: 93.77, val/strict_accuracy: 93.77\n",
      "Epoch 22: lr: 7.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.42e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.84e-01, val/iit_loss: 2.59e-01, val/IIA: 91.39, val/accuracy: 94.41, val/strict_accuracy: 94.41\n",
      "Epoch 23: lr: 7.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.53e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.73e-01, val/iit_loss: 1.57e-01, val/IIA: 96.08, val/accuracy: 95.18, val/strict_accuracy: 95.18\n",
      "Epoch 24: lr: 7.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.83e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.47e-01, val/iit_loss: 2.15e-01, val/IIA: 94.04, val/accuracy: 95.78, val/strict_accuracy: 95.78\n",
      "Epoch 25: lr: 7.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.88e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.31e-01, val/iit_loss: 2.10e-01, val/IIA: 93.40, val/accuracy: 95.95, val/strict_accuracy: 95.95\n",
      "Epoch 26: lr: 7.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.88e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.19e-01, val/iit_loss: 1.76e-01, val/IIA: 95.31, val/accuracy: 96.82, val/strict_accuracy: 96.82\n",
      "Epoch 27: lr: 7.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.80e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.22e-01, val/iit_loss: 1.05e-01, val/IIA: 97.82, val/accuracy: 97.22, val/strict_accuracy: 97.22\n",
      "Epoch 28: lr: 7.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.06e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.06e-01, val/iit_loss: 9.37e-02, val/IIA: 98.56, val/accuracy: 98.26, val/strict_accuracy: 98.26\n",
      "Epoch 29: lr: 7.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.12e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 8.46e-02, val/iit_loss: 1.25e-01, val/IIA: 97.39, val/accuracy: 97.86, val/strict_accuracy: 97.86\n",
      "Epoch 30: lr: 7.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.06e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 8.33e-02, val/iit_loss: 6.57e-01, val/IIA: 80.50, val/accuracy: 98.59, val/strict_accuracy: 98.59\n",
      "Epoch 31: lr: 6.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.13e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.54e-02, val/iit_loss: 3.38e-01, val/IIA: 86.00, val/accuracy: 97.42, val/strict_accuracy: 97.42\n",
      "Epoch 32: lr: 6.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.11e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.43e-02, val/iit_loss: 5.95e-02, val/IIA: 98.89, val/accuracy: 99.10, val/strict_accuracy: 99.10\n",
      "Epoch 33: lr: 6.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.25e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.38e-02, val/iit_loss: 9.18e-02, val/IIA: 98.53, val/accuracy: 99.36, val/strict_accuracy: 99.36\n",
      "Epoch 34: lr: 6.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.91e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.79e-02, val/iit_loss: 4.71e-02, val/IIA: 99.30, val/accuracy: 99.23, val/strict_accuracy: 99.23\n",
      "Epoch 35: lr: 6.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.81e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.23e-02, val/iit_loss: 7.69e-02, val/IIA: 98.96, val/accuracy: 99.53, val/strict_accuracy: 99.53\n",
      "Epoch 36: lr: 6.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.45e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.86e-02, val/iit_loss: 4.64e-01, val/IIA: 86.43, val/accuracy: 99.77, val/strict_accuracy: 99.77\n",
      "Epoch 37: lr: 6.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.92e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.96e-02, val/iit_loss: 6.34e-02, val/IIA: 99.16, val/accuracy: 99.26, val/strict_accuracy: 99.26\n",
      "Epoch 38: lr: 6.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.23e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.75e-02, val/iit_loss: 4.66e-01, val/IIA: 86.77, val/accuracy: 99.70, val/strict_accuracy: 99.70\n",
      "Epoch 39: lr: 6.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.05e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.21e-02, val/iit_loss: 4.39e-01, val/IIA: 87.10, val/accuracy: 99.83, val/strict_accuracy: 99.83\n",
      "Epoch 40: lr: 6.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.16e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.01e-02, val/iit_loss: 2.03e-01, val/IIA: 92.46, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 41: lr: 5.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.16e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.96e-02, val/iit_loss: 2.04e-02, val/IIA: 99.97, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 42: lr: 5.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.90e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.82e-02, val/iit_loss: 1.72e-01, val/IIA: 93.97, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 43: lr: 5.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.06e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.70e-02, val/iit_loss: 5.02e-01, val/IIA: 86.37, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 44: lr: 5.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.82e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.63e-02, val/iit_loss: 4.29e-02, val/IIA: 99.77, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 45: lr: 5.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.74e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.59e-02, val/iit_loss: 5.55e-01, val/IIA: 85.59, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 46: lr: 5.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.20e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.63e-02, val/iit_loss: 5.15e-02, val/IIA: 99.53, val/accuracy: 99.73, val/strict_accuracy: 99.73\n",
      "Epoch 47: lr: 5.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.17e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.75e-02, val/iit_loss: 1.32e-01, val/IIA: 96.01, val/accuracy: 99.93, val/strict_accuracy: 99.93\n",
      "Epoch 48: lr: 5.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.59e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.65e-02, val/iit_loss: 5.11e-01, val/IIA: 86.90, val/accuracy: 99.80, val/strict_accuracy: 99.80\n",
      "Epoch 49: lr: 5.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.91e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.30e-02, val/iit_loss: 4.24e-02, val/IIA: 99.73, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 50: lr: 5.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.91e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.14e-02, val/iit_loss: 3.43e-02, val/IIA: 99.90, val/accuracy: 99.93, val/strict_accuracy: 99.93\n",
      "Epoch 51: lr: 4.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.68e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.06e-02, val/iit_loss: 4.63e-01, val/IIA: 87.84, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 52: lr: 4.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.99e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.29e-02, val/iit_loss: 3.15e-02, val/IIA: 99.97, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 53: lr: 4.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.51e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.12e-02, val/iit_loss: 3.43e-02, val/IIA: 99.70, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 54: lr: 4.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.19e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 9.93e-03, val/iit_loss: 2.93e-02, val/IIA: 99.93, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 55: lr: 4.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.51e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.05e-02, val/iit_loss: 3.97e-01, val/IIA: 89.65, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 56: lr: 4.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.53e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 9.34e-03, val/iit_loss: 3.85e-01, val/IIA: 89.78, val/accuracy: 99.93, val/strict_accuracy: 99.93\n",
      "Epoch 57: lr: 4.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.31e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 9.96e-03, val/iit_loss: 1.05e-02, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "ll_model = hl_model.get_ll_model()\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    "    optimizer_kwargs=dict(weight_decay=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique token extraction\n",
    "case 21 in circuits-bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2],\n",
      "        [2, 1],\n",
      "        [0, 0],\n",
      "        [1, 2],\n",
      "        [0, 2],\n",
      "        [2, 0],\n",
      "        [2, 2],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [2, 0]])\n",
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.randint(0, 3, (10, 2)))\n",
    "\n",
    "a = [1, 2, 3]\n",
    "a.remove(2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing / Decreasing detector\n",
    "case 13 in circuits-bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poly Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DuplicateRemover + LeftGreater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "\n",
      "blocks.0.mlp.hook_post [[prev_equal_hook], [mlp0_hook]]\n",
      "blocks.0.attn.hook_z.0 [[prev_token_hook], None]\n",
      "blocks.0.attn.hook_z.1 [None, [paren_counts_hook]]\n",
      "blocks.0.attn.hook_z.2 [None, None]\n",
      "blocks.0.attn.hook_z.3 [None, None]\n",
      "blocks.1.mlp.hook_post [[output_hook], None]\n",
      "blocks.1.attn.hook_z.0 [None, None]\n",
      "blocks.1.attn.hook_z.1 [None, None]\n",
      "blocks.1.attn.hook_z.2 [None, None]\n",
      "blocks.1.attn.hook_z.3 [None, None]\n"
     ]
    }
   ],
   "source": [
    "cases = [HighLevelDuplicateRemover, HighLevelLeftGreater]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=2)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "print()\n",
    "for k, v in poly_hl_model.corr_mapping.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 15, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evananders/far_cluster/circuits-benchmark-saes/poly_bench/cases/duplicate_remover.py:161: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  _, cache = hl_model.run_with_cache((t.tensor(sample).unsqueeze(0), None, None))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16, 5)\n",
      "tensor([[0, 4, 1,  ..., 0, 2, 1],\n",
      "        [0, 4, 0,  ..., 2, 2, 0],\n",
      "        [0, 4, 0,  ..., 0, 2, 2],\n",
      "        ...,\n",
      "        [1, 3, 1,  ..., 1, 0, 1],\n",
      "        [0, 4, 0,  ..., 2, 0, 1],\n",
      "        [1, 3, 0,  ..., 0, 1, 1]])\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evananders/far_cluster/circuits-benchmark-saes/poly_bench/poly_hl_model.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokens = torch.cat([torch.tensor(dataset.tokens) for dataset in datasets], dim=0)\n",
      "/Users/evananders/far_cluster/circuits-benchmark-saes/poly_bench/poly_hl_model.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.cat([torch.tensor(dataset.labels) for dataset in datasets], dim=0)\n",
      "/Users/evananders/far_cluster/circuits-benchmark-saes/poly_bench/cases/utils.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.inputs = t.tensor(inputs).to(int)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = DuplicateRemoverDataset(N_samples=1_000, n_ctx=15, seed=42)\n",
    "dataset2 = LeftGreaterDataset(N_samples=1_000, n_ctx=15, seed=42)\n",
    "dsets = [dataset1,dataset2]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)\n",
    "\n",
    "n_samples = 100\n",
    "input = poly_dataset.get_dataset()[:n_samples][0]\n",
    "output = poly_hl_model((input, None, None)).cpu()\n",
    "expected = poly_dataset.get_dataset()[:n_samples][1]\n",
    "print(input)\n",
    "print(torch.allclose(output, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "[LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'lr': 0.0003, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 0, 'detach_while_caching': True, 'iit_weight_schedule': <function <lambda> at 0x32bd2b9c0>, 'strict_weight_schedule': <function <lambda> at 0x32bd29e40>, 'behavior_weight_schedule': <function <lambda> at 0x37187f4c0>, 'atol': 0.05, 'use_single_loss': False, 'iit_weight': 1.0, 'behavior_weight': 1.0, 'strict_weight': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2890c3f825fc4ac38883f6333ff1c9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 2.97e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.33e+00, train/behavior_loss: 1.20e+00, train/strict_loss: 2.04e-01, val/iit_loss: 1.18e+00, val/IIA: 48.18, val/accuracy: 59.36, val/strict_accuracy: 57.45\n",
      "Epoch 2: lr: 2.94e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.02e+00, train/behavior_loss: 6.92e-01, train/strict_loss: 1.24e-01, val/iit_loss: 1.18e+00, val/IIA: 51.01, val/accuracy: 77.90, val/strict_accuracy: 75.74\n",
      "Epoch 3: lr: 2.91e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 5.70e-01, train/behavior_loss: 4.50e-01, train/strict_loss: 8.63e-02, val/iit_loss: 4.83e-01, val/IIA: 81.24, val/accuracy: 87.92, val/strict_accuracy: 84.16\n",
      "Epoch 4: lr: 2.88e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.04e+00, train/behavior_loss: 3.39e-01, train/strict_loss: 6.02e-02, val/iit_loss: 8.82e-01, val/IIA: 65.87, val/accuracy: 89.09, val/strict_accuracy: 86.10\n",
      "Epoch 5: lr: 2.85e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 7.05e-01, train/behavior_loss: 2.96e-01, train/strict_loss: 5.74e-02, val/iit_loss: 4.17e-01, val/IIA: 83.11, val/accuracy: 89.90, val/strict_accuracy: 85.92\n",
      "Epoch 6: lr: 2.82e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.28e+00, train/behavior_loss: 2.69e-01, train/strict_loss: 4.73e-02, val/iit_loss: 6.66e-01, val/IIA: 73.46, val/accuracy: 90.49, val/strict_accuracy: 87.68\n",
      "Epoch 7: lr: 2.79e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 6.94e-01, train/behavior_loss: 2.55e-01, train/strict_loss: 5.58e-02, val/iit_loss: 2.70e-01, val/IIA: 90.07, val/accuracy: 91.00, val/strict_accuracy: 87.98\n",
      "Epoch 8: lr: 2.76e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 8.07e-01, train/behavior_loss: 2.33e-01, train/strict_loss: 5.58e-02, val/iit_loss: 2.95e-01, val/IIA: 89.11, val/accuracy: 91.23, val/strict_accuracy: 88.84\n",
      "Epoch 9: lr: 2.73e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 5.63e-01, train/behavior_loss: 2.17e-01, train/strict_loss: 4.72e-02, val/iit_loss: 7.79e-01, val/IIA: 66.97, val/accuracy: 91.50, val/strict_accuracy: 89.18\n",
      "Epoch 10: lr: 2.70e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 5.53e-01, train/behavior_loss: 2.05e-01, train/strict_loss: 4.16e-02, val/iit_loss: 2.81e-01, val/IIA: 88.58, val/accuracy: 92.06, val/strict_accuracy: 89.71\n",
      "Epoch 11: lr: 2.67e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 7.64e-01, train/behavior_loss: 1.94e-01, train/strict_loss: 4.02e-02, val/iit_loss: 6.72e-01, val/IIA: 69.97, val/accuracy: 92.44, val/strict_accuracy: 89.74\n",
      "Epoch 12: lr: 2.64e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 5.87e-01, train/behavior_loss: 1.80e-01, train/strict_loss: 4.19e-02, val/iit_loss: 7.05e-01, val/IIA: 70.96, val/accuracy: 92.92, val/strict_accuracy: 90.40\n",
      "Epoch 13: lr: 2.61e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 6.22e-01, train/behavior_loss: 1.63e-01, train/strict_loss: 3.70e-02, val/iit_loss: 3.95e-01, val/IIA: 83.20, val/accuracy: 93.80, val/strict_accuracy: 90.58\n",
      "Epoch 14: lr: 2.58e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 5.60e-01, train/behavior_loss: 1.50e-01, train/strict_loss: 3.84e-02, val/iit_loss: 1.96e-01, val/IIA: 92.46, val/accuracy: 94.36, val/strict_accuracy: 91.23\n",
      "Epoch 15: lr: 2.55e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 5.47e-01, train/behavior_loss: 1.36e-01, train/strict_loss: 3.96e-02, val/iit_loss: 1.79e-01, val/IIA: 93.52, val/accuracy: 94.78, val/strict_accuracy: 91.06\n",
      "Epoch 16: lr: 2.52e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 6.14e-01, train/behavior_loss: 1.25e-01, train/strict_loss: 3.20e-02, val/iit_loss: 8.37e-01, val/IIA: 63.41, val/accuracy: 95.78, val/strict_accuracy: 92.05\n",
      "Epoch 17: lr: 2.49e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 4.19e-01, train/behavior_loss: 1.18e-01, train/strict_loss: 3.76e-02, val/iit_loss: 2.94e-01, val/IIA: 87.59, val/accuracy: 96.19, val/strict_accuracy: 92.49\n",
      "Epoch 18: lr: 2.46e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.80e-01, train/behavior_loss: 1.07e-01, train/strict_loss: 2.98e-02, val/iit_loss: 3.10e-01, val/IIA: 88.52, val/accuracy: 96.78, val/strict_accuracy: 92.98\n",
      "Epoch 19: lr: 2.43e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.43e-01, train/behavior_loss: 9.28e-02, train/strict_loss: 3.57e-02, val/iit_loss: 2.04e-01, val/IIA: 92.34, val/accuracy: 97.33, val/strict_accuracy: 93.00\n",
      "Epoch 20: lr: 2.40e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.37e-01, train/behavior_loss: 7.74e-02, train/strict_loss: 2.80e-02, val/iit_loss: 1.90e-01, val/IIA: 92.80, val/accuracy: 97.69, val/strict_accuracy: 93.69\n",
      "Epoch 21: lr: 2.37e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.79e-01, train/behavior_loss: 7.16e-02, train/strict_loss: 2.37e-02, val/iit_loss: 3.28e-01, val/IIA: 87.33, val/accuracy: 98.26, val/strict_accuracy: 94.06\n",
      "Epoch 22: lr: 2.34e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.70e-01, train/behavior_loss: 6.11e-02, train/strict_loss: 2.35e-02, val/iit_loss: 6.04e-01, val/IIA: 75.56, val/accuracy: 98.35, val/strict_accuracy: 94.06\n",
      "Epoch 23: lr: 2.31e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.20e-01, train/behavior_loss: 5.48e-02, train/strict_loss: 2.12e-02, val/iit_loss: 2.89e-01, val/IIA: 89.22, val/accuracy: 98.76, val/strict_accuracy: 94.23\n",
      "Epoch 24: lr: 2.28e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.74e-01, train/behavior_loss: 5.11e-02, train/strict_loss: 3.10e-02, val/iit_loss: 3.21e-01, val/IIA: 87.84, val/accuracy: 98.72, val/strict_accuracy: 93.94\n",
      "Epoch 25: lr: 2.25e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.00e-01, train/behavior_loss: 4.62e-02, train/strict_loss: 2.83e-02, val/iit_loss: 1.42e-01, val/IIA: 94.99, val/accuracy: 98.96, val/strict_accuracy: 94.96\n",
      "Epoch 26: lr: 2.22e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.90e-01, train/behavior_loss: 4.21e-02, train/strict_loss: 2.49e-02, val/iit_loss: 4.92e-02, val/IIA: 99.00, val/accuracy: 98.82, val/strict_accuracy: 95.28\n",
      "Epoch 27: lr: 2.19e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.91e-01, train/behavior_loss: 3.84e-02, train/strict_loss: 2.79e-02, val/iit_loss: 4.49e-01, val/IIA: 81.58, val/accuracy: 99.18, val/strict_accuracy: 95.42\n",
      "Epoch 28: lr: 2.16e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.06e-01, train/behavior_loss: 3.48e-02, train/strict_loss: 2.39e-02, val/iit_loss: 4.26e-02, val/IIA: 99.01, val/accuracy: 99.29, val/strict_accuracy: 95.40\n",
      "Epoch 29: lr: 2.13e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.99e-01, train/behavior_loss: 3.22e-02, train/strict_loss: 1.90e-02, val/iit_loss: 1.41e-01, val/IIA: 94.73, val/accuracy: 99.31, val/strict_accuracy: 95.73\n",
      "Epoch 30: lr: 2.10e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.64e-01, train/behavior_loss: 3.10e-02, train/strict_loss: 2.64e-02, val/iit_loss: 2.32e-01, val/IIA: 91.70, val/accuracy: 99.24, val/strict_accuracy: 96.05\n",
      "Epoch 31: lr: 2.07e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.32e-01, train/behavior_loss: 2.88e-02, train/strict_loss: 1.83e-02, val/iit_loss: 3.00e-01, val/IIA: 89.02, val/accuracy: 99.42, val/strict_accuracy: 95.90\n",
      "Epoch 32: lr: 2.04e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.63e-01, train/behavior_loss: 2.45e-02, train/strict_loss: 1.69e-02, val/iit_loss: 1.50e-01, val/IIA: 94.72, val/accuracy: 99.57, val/strict_accuracy: 95.85\n",
      "Epoch 33: lr: 2.01e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.71e-01, train/behavior_loss: 2.16e-02, train/strict_loss: 1.50e-02, val/iit_loss: 3.92e-01, val/IIA: 84.59, val/accuracy: 99.44, val/strict_accuracy: 95.83\n",
      "Epoch 34: lr: 1.98e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.56e-01, train/behavior_loss: 2.21e-02, train/strict_loss: 2.44e-02, val/iit_loss: 4.21e-01, val/IIA: 83.38, val/accuracy: 99.50, val/strict_accuracy: 96.48\n",
      "Epoch 35: lr: 1.95e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.23e-01, train/behavior_loss: 1.96e-02, train/strict_loss: 1.72e-02, val/iit_loss: 2.27e-01, val/IIA: 91.95, val/accuracy: 99.60, val/strict_accuracy: 96.45\n",
      "Epoch 36: lr: 1.92e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.37e-01, train/behavior_loss: 1.86e-02, train/strict_loss: 1.25e-02, val/iit_loss: 3.77e-01, val/IIA: 85.21, val/accuracy: 99.72, val/strict_accuracy: 96.41\n",
      "Epoch 37: lr: 1.89e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.10e-01, train/behavior_loss: 1.74e-02, train/strict_loss: 2.48e-02, val/iit_loss: 2.75e-01, val/IIA: 89.02, val/accuracy: 99.64, val/strict_accuracy: 96.63\n",
      "Epoch 38: lr: 1.86e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.32e-01, train/behavior_loss: 1.69e-02, train/strict_loss: 1.93e-02, val/iit_loss: 2.00e-01, val/IIA: 92.76, val/accuracy: 99.60, val/strict_accuracy: 96.75\n",
      "Epoch 39: lr: 1.83e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.43e-01, train/behavior_loss: 1.51e-02, train/strict_loss: 1.60e-02, val/iit_loss: 2.73e-01, val/IIA: 88.96, val/accuracy: 99.76, val/strict_accuracy: 97.02\n",
      "Epoch 40: lr: 1.80e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.91e-01, train/behavior_loss: 1.47e-02, train/strict_loss: 1.83e-02, val/iit_loss: 3.44e-01, val/IIA: 87.38, val/accuracy: 99.64, val/strict_accuracy: 97.15\n",
      "Epoch 41: lr: 1.77e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.25e-01, train/behavior_loss: 1.42e-02, train/strict_loss: 1.85e-02, val/iit_loss: 3.45e-01, val/IIA: 87.41, val/accuracy: 99.75, val/strict_accuracy: 96.95\n",
      "Epoch 42: lr: 1.74e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.66e-01, train/behavior_loss: 1.35e-02, train/strict_loss: 2.29e-02, val/iit_loss: 2.54e-01, val/IIA: 91.06, val/accuracy: 99.78, val/strict_accuracy: 97.08\n",
      "Epoch 43: lr: 1.71e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.78e-01, train/behavior_loss: 1.25e-02, train/strict_loss: 1.47e-02, val/iit_loss: 2.26e-01, val/IIA: 91.65, val/accuracy: 99.83, val/strict_accuracy: 97.10\n",
      "Epoch 44: lr: 1.68e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.63e-01, train/behavior_loss: 1.14e-02, train/strict_loss: 1.31e-02, val/iit_loss: 1.34e-02, val/IIA: 99.86, val/accuracy: 99.83, val/strict_accuracy: 97.24\n",
      "Epoch 45: lr: 1.65e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.50e-01, train/behavior_loss: 1.10e-02, train/strict_loss: 1.27e-02, val/iit_loss: 3.00e-01, val/IIA: 88.33, val/accuracy: 99.86, val/strict_accuracy: 97.30\n",
      "Epoch 46: lr: 1.62e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.88e-01, train/behavior_loss: 1.15e-02, train/strict_loss: 1.97e-02, val/iit_loss: 2.35e-01, val/IIA: 91.21, val/accuracy: 99.72, val/strict_accuracy: 96.99\n",
      "Epoch 47: lr: 1.59e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.97e-01, train/behavior_loss: 1.15e-02, train/strict_loss: 1.29e-02, val/iit_loss: 1.38e-01, val/IIA: 95.36, val/accuracy: 99.74, val/strict_accuracy: 97.19\n",
      "Epoch 48: lr: 1.56e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.27e-01, train/behavior_loss: 1.09e-02, train/strict_loss: 2.22e-02, val/iit_loss: 1.20e-02, val/IIA: 99.89, val/accuracy: 99.86, val/strict_accuracy: 97.49\n",
      "Epoch 49: lr: 1.53e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.16e-01, train/behavior_loss: 9.68e-03, train/strict_loss: 9.06e-03, val/iit_loss: 2.63e-01, val/IIA: 90.42, val/accuracy: 99.83, val/strict_accuracy: 97.41\n",
      "Epoch 50: lr: 1.50e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.70e-01, train/behavior_loss: 8.84e-03, train/strict_loss: 1.75e-02, val/iit_loss: 2.22e-01, val/IIA: 91.77, val/accuracy: 99.88, val/strict_accuracy: 97.53\n",
      "Epoch 51: lr: 1.47e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.88e-01, train/behavior_loss: 9.46e-03, train/strict_loss: 1.52e-02, val/iit_loss: 2.03e-01, val/IIA: 92.66, val/accuracy: 99.79, val/strict_accuracy: 97.45\n",
      "Epoch 52: lr: 1.44e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.92e-01, train/behavior_loss: 8.50e-03, train/strict_loss: 1.40e-02, val/iit_loss: 2.02e-01, val/IIA: 92.14, val/accuracy: 99.86, val/strict_accuracy: 97.48\n",
      "Epoch 53: lr: 1.41e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.37e-01, train/behavior_loss: 7.76e-03, train/strict_loss: 7.73e-03, val/iit_loss: 2.76e-01, val/IIA: 89.21, val/accuracy: 99.90, val/strict_accuracy: 97.48\n",
      "Epoch 54: lr: 1.38e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.98e-01, train/behavior_loss: 7.27e-03, train/strict_loss: 1.27e-02, val/iit_loss: 9.95e-02, val/IIA: 96.45, val/accuracy: 99.80, val/strict_accuracy: 97.69\n",
      "Epoch 55: lr: 1.35e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.78e-01, train/behavior_loss: 6.99e-03, train/strict_loss: 7.20e-03, val/iit_loss: 1.49e-01, val/IIA: 94.52, val/accuracy: 99.83, val/strict_accuracy: 97.54\n",
      "Epoch 56: lr: 1.32e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.59e-01, train/behavior_loss: 6.89e-03, train/strict_loss: 1.30e-02, val/iit_loss: 1.76e-01, val/IIA: 93.78, val/accuracy: 99.86, val/strict_accuracy: 97.48\n",
      "Epoch 57: lr: 1.29e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.89e-01, train/behavior_loss: 6.62e-03, train/strict_loss: 1.19e-02, val/iit_loss: 8.67e-02, val/IIA: 96.65, val/accuracy: 99.93, val/strict_accuracy: 97.45\n",
      "Epoch 58: lr: 1.26e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.35e-01, train/behavior_loss: 6.81e-03, train/strict_loss: 2.34e-02, val/iit_loss: 1.49e-01, val/IIA: 94.76, val/accuracy: 99.89, val/strict_accuracy: 97.61\n",
      "Epoch 59: lr: 1.23e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.23e-01, train/behavior_loss: 6.37e-03, train/strict_loss: 1.45e-02, val/iit_loss: 6.44e-02, val/IIA: 97.53, val/accuracy: 99.85, val/strict_accuracy: 97.72\n",
      "Epoch 60: lr: 1.20e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.25e-01, train/behavior_loss: 6.32e-03, train/strict_loss: 1.51e-02, val/iit_loss: 2.27e-01, val/IIA: 91.85, val/accuracy: 99.95, val/strict_accuracy: 97.72\n",
      "Epoch 61: lr: 1.17e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.53e-01, train/behavior_loss: 6.44e-03, train/strict_loss: 7.53e-03, val/iit_loss: 6.70e-02, val/IIA: 97.39, val/accuracy: 99.89, val/strict_accuracy: 97.40\n",
      "Epoch 62: lr: 1.14e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.63e-01, train/behavior_loss: 6.13e-03, train/strict_loss: 6.23e-03, val/iit_loss: 2.04e-01, val/IIA: 92.18, val/accuracy: 99.93, val/strict_accuracy: 97.62\n",
      "Epoch 63: lr: 1.11e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.32e-01, train/behavior_loss: 5.61e-03, train/strict_loss: 1.29e-02, val/iit_loss: 1.09e-01, val/IIA: 96.15, val/accuracy: 99.89, val/strict_accuracy: 97.73\n",
      "Epoch 64: lr: 1.08e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.13e-01, train/behavior_loss: 5.59e-03, train/strict_loss: 1.78e-02, val/iit_loss: 2.89e-02, val/IIA: 99.07, val/accuracy: 99.95, val/strict_accuracy: 97.80\n",
      "Epoch 65: lr: 1.05e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.66e-01, train/behavior_loss: 5.59e-03, train/strict_loss: 6.67e-03, val/iit_loss: 1.28e-01, val/IIA: 95.41, val/accuracy: 99.90, val/strict_accuracy: 97.74\n",
      "Epoch 66: lr: 1.02e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.48e-01, train/behavior_loss: 5.22e-03, train/strict_loss: 1.52e-02, val/iit_loss: 1.91e-01, val/IIA: 93.36, val/accuracy: 99.92, val/strict_accuracy: 97.72\n",
      "Epoch 67: lr: 9.90e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.39e-01, train/behavior_loss: 4.82e-03, train/strict_loss: 1.19e-02, val/iit_loss: 1.13e-01, val/IIA: 96.04, val/accuracy: 99.93, val/strict_accuracy: 97.65\n",
      "Epoch 68: lr: 9.60e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 4.80e-02, train/behavior_loss: 4.68e-03, train/strict_loss: 1.22e-02, val/iit_loss: 7.12e-02, val/IIA: 97.54, val/accuracy: 99.95, val/strict_accuracy: 97.81\n",
      "Epoch 69: lr: 9.30e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.84e-01, train/behavior_loss: 4.73e-03, train/strict_loss: 1.12e-02, val/iit_loss: 7.71e-02, val/IIA: 97.28, val/accuracy: 99.84, val/strict_accuracy: 97.75\n",
      "Epoch 70: lr: 9.00e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 9.23e-02, train/behavior_loss: 4.79e-03, train/strict_loss: 4.48e-03, val/iit_loss: 5.78e-02, val/IIA: 97.85, val/accuracy: 99.90, val/strict_accuracy: 97.71\n",
      "Epoch 71: lr: 8.70e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.07e-01, train/behavior_loss: 4.58e-03, train/strict_loss: 2.62e-02, val/iit_loss: 3.10e-02, val/IIA: 99.00, val/accuracy: 99.88, val/strict_accuracy: 97.65\n",
      "Epoch 72: lr: 8.40e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 8.95e-02, train/behavior_loss: 4.54e-03, train/strict_loss: 1.04e-02, val/iit_loss: 1.89e-01, val/IIA: 93.32, val/accuracy: 99.93, val/strict_accuracy: 97.80\n",
      "Epoch 73: lr: 8.10e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.23e-01, train/behavior_loss: 4.48e-03, train/strict_loss: 1.09e-02, val/iit_loss: 6.70e-02, val/IIA: 97.60, val/accuracy: 99.90, val/strict_accuracy: 97.65\n",
      "Epoch 74: lr: 7.80e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.66e-01, train/behavior_loss: 4.25e-03, train/strict_loss: 1.63e-02, val/iit_loss: 1.55e-01, val/IIA: 94.37, val/accuracy: 99.89, val/strict_accuracy: 97.80\n",
      "Epoch 75: lr: 7.50e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.02e-01, train/behavior_loss: 4.15e-03, train/strict_loss: 5.89e-03, val/iit_loss: 1.20e-01, val/IIA: 95.91, val/accuracy: 100.00, val/strict_accuracy: 97.77\n",
      "Epoch 76: lr: 7.20e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 8.74e-02, train/behavior_loss: 4.18e-03, train/strict_loss: 1.49e-02, val/iit_loss: 2.11e-01, val/IIA: 92.40, val/accuracy: 99.82, val/strict_accuracy: 97.78\n",
      "Epoch 77: lr: 6.90e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.22e-01, train/behavior_loss: 4.07e-03, train/strict_loss: 1.91e-02, val/iit_loss: 1.59e-01, val/IIA: 94.27, val/accuracy: 99.94, val/strict_accuracy: 97.97\n",
      "Epoch 78: lr: 6.60e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.01e-01, train/behavior_loss: 4.04e-03, train/strict_loss: 1.54e-02, val/iit_loss: 1.15e-01, val/IIA: 96.00, val/accuracy: 99.95, val/strict_accuracy: 97.86\n",
      "Epoch 79: lr: 6.30e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.50e-01, train/behavior_loss: 3.82e-03, train/strict_loss: 9.15e-03, val/iit_loss: 1.52e-01, val/IIA: 94.42, val/accuracy: 99.88, val/strict_accuracy: 97.87\n",
      "Epoch 80: lr: 6.00e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.60e-01, train/behavior_loss: 3.81e-03, train/strict_loss: 1.37e-02, val/iit_loss: 1.26e-01, val/IIA: 95.51, val/accuracy: 99.95, val/strict_accuracy: 98.03\n",
      "Epoch 81: lr: 5.70e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.36e-01, train/behavior_loss: 3.76e-03, train/strict_loss: 1.00e-02, val/iit_loss: 1.20e-01, val/IIA: 96.11, val/accuracy: 99.89, val/strict_accuracy: 97.92\n",
      "Epoch 82: lr: 5.40e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.45e-01, train/behavior_loss: 3.66e-03, train/strict_loss: 9.62e-03, val/iit_loss: 2.33e-01, val/IIA: 91.39, val/accuracy: 100.00, val/strict_accuracy: 97.87\n",
      "Epoch 83: lr: 5.10e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 9.25e-02, train/behavior_loss: 3.64e-03, train/strict_loss: 1.89e-02, val/iit_loss: 6.67e-02, val/IIA: 97.69, val/accuracy: 99.95, val/strict_accuracy: 97.63\n",
      "Epoch 84: lr: 4.80e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 9.33e-02, train/behavior_loss: 3.58e-03, train/strict_loss: 9.61e-03, val/iit_loss: 1.15e-01, val/IIA: 95.97, val/accuracy: 99.88, val/strict_accuracy: 97.80\n",
      "Epoch 85: lr: 4.50e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.31e-01, train/behavior_loss: 3.65e-03, train/strict_loss: 1.89e-02, val/iit_loss: 1.84e-01, val/IIA: 93.76, val/accuracy: 99.92, val/strict_accuracy: 97.79\n",
      "Epoch 86: lr: 4.20e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 7.25e-02, train/behavior_loss: 3.57e-03, train/strict_loss: 1.37e-02, val/iit_loss: 1.45e-01, val/IIA: 94.69, val/accuracy: 99.89, val/strict_accuracy: 97.79\n",
      "Epoch 87: lr: 3.90e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.68e-01, train/behavior_loss: 3.52e-03, train/strict_loss: 9.74e-03, val/iit_loss: 1.20e-01, val/IIA: 95.88, val/accuracy: 99.94, val/strict_accuracy: 97.94\n",
      "Epoch 88: lr: 3.60e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.05e-01, train/behavior_loss: 3.42e-03, train/strict_loss: 9.92e-03, val/iit_loss: 1.38e-01, val/IIA: 95.04, val/accuracy: 99.90, val/strict_accuracy: 97.94\n",
      "Epoch 89: lr: 3.30e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.67e-01, train/behavior_loss: 3.23e-03, train/strict_loss: 1.51e-02, val/iit_loss: 3.92e-02, val/IIA: 98.51, val/accuracy: 99.86, val/strict_accuracy: 97.99\n",
      "Epoch 90: lr: 3.00e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.59e-01, train/behavior_loss: 3.63e-03, train/strict_loss: 6.73e-03, val/iit_loss: 8.23e-02, val/IIA: 97.29, val/accuracy: 99.94, val/strict_accuracy: 98.08\n",
      "Epoch 91: lr: 2.70e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.23e-01, train/behavior_loss: 3.22e-03, train/strict_loss: 1.33e-02, val/iit_loss: 1.14e-01, val/IIA: 95.96, val/accuracy: 99.93, val/strict_accuracy: 97.85\n",
      "Epoch 92: lr: 2.40e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 7.22e-02, train/behavior_loss: 3.31e-03, train/strict_loss: 5.33e-03, val/iit_loss: 6.62e-02, val/IIA: 97.68, val/accuracy: 99.87, val/strict_accuracy: 97.84\n",
      "Epoch 93: lr: 2.10e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.16e-01, train/behavior_loss: 3.31e-03, train/strict_loss: 9.65e-03, val/iit_loss: 1.13e-01, val/IIA: 96.23, val/accuracy: 99.86, val/strict_accuracy: 97.86\n",
      "Epoch 94: lr: 1.80e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 6.94e-02, train/behavior_loss: 3.20e-03, train/strict_loss: 1.60e-02, val/iit_loss: 1.59e-01, val/IIA: 94.61, val/accuracy: 100.00, val/strict_accuracy: 97.85\n",
      "Epoch 95: lr: 1.50e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.39e-01, train/behavior_loss: 3.29e-03, train/strict_loss: 1.03e-02, val/iit_loss: 1.13e-01, val/IIA: 95.97, val/accuracy: 99.86, val/strict_accuracy: 97.87\n",
      "Epoch 96: lr: 1.20e-05, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.22e-01, train/behavior_loss: 3.19e-03, train/strict_loss: 1.59e-02, val/iit_loss: 1.55e-01, val/IIA: 94.36, val/accuracy: 99.94, val/strict_accuracy: 97.96\n",
      "Epoch 97: lr: 9.00e-06, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.36e-01, train/behavior_loss: 3.28e-03, train/strict_loss: 9.63e-03, val/iit_loss: 7.89e-02, val/IIA: 97.40, val/accuracy: 99.88, val/strict_accuracy: 97.96\n",
      "Epoch 98: lr: 6.00e-06, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.20e-01, train/behavior_loss: 3.16e-03, train/strict_loss: 2.43e-02, val/iit_loss: 1.87e-01, val/IIA: 93.34, val/accuracy: 99.93, val/strict_accuracy: 97.93\n",
      "Epoch 99: lr: 3.00e-06, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 8.64e-02, train/behavior_loss: 3.09e-03, train/strict_loss: 4.13e-03, val/iit_loss: 6.03e-02, val/IIA: 97.65, val/accuracy: 99.93, val/strict_accuracy: 97.99\n",
      "Epoch 100: lr: 0.00e+00, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 6.62e-02, train/behavior_loss: 3.08e-03, train/strict_loss: 8.88e-03, val/iit_loss: 2.08e-01, val/IIA: 92.79, val/accuracy: 99.91, val/strict_accuracy: 97.92\n"
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model()\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "n_epochs = 100\n",
    "training_args = {\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 3e-4,\n",
    "    \"num_workers\": 0,\n",
    "    \"use_single_loss\": False,\n",
    "    \"behavior_weight\": 1., #basically doubles the strict weight's job.\n",
    "    \"iit_weight\": 1.,\n",
    "    \"strict_weight\": 0.4,\n",
    "    \"clip_grad_norm\": 1.0,\n",
    "    \"iit_weight_schedule\" : lambda s, i: s,\n",
    "    \"strict_weight_schedule\" : lambda s, i: s,\n",
    "    \"behavior_weight_schedule\" : lambda s, i: s, #0.955*s if 0.955**i > 0.01 else s, #have behavior weight decay over time\n",
    "    \"early_stop\" : True,\n",
    "    \"lr_scheduler\": torch.optim.lr_scheduler.LinearLR,\n",
    "    \"scheduler_kwargs\": dict(start_factor=1, end_factor=0, total_iters=n_epochs),\n",
    "    \"scheduler_val_metric\": [\"val/accuracy\", \"val/IIA\"], #for ReduceLRonPlateau\n",
    "    \"scheduler_mode\": \"max\", #for ReduceLRonPlateau\n",
    "}\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    "    optimizer_kwargs=dict(weight_decay=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Remover + LeftGreater + ParensBalancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 15, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evananders/far_cluster/circuits-benchmark-saes/poly_bench/cases/duplicate_remover.py:161: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  _, cache = hl_model.run_with_cache((t.tensor(sample).unsqueeze(0), None, None))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evananders/far_cluster/circuits-benchmark-saes/poly_bench/poly_hl_model.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokens = torch.cat([torch.tensor(dataset.tokens) for dataset in datasets], dim=0)\n",
      "/Users/evananders/far_cluster/circuits-benchmark-saes/poly_bench/poly_hl_model.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.cat([torch.tensor(dataset.labels) for dataset in datasets], dim=0)\n",
      "/Users/evananders/far_cluster/circuits-benchmark-saes/poly_bench/cases/utils.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.inputs = t.tensor(inputs).to(int)\n"
     ]
    }
   ],
   "source": [
    "cases = [HighLevelDuplicateRemover, HighLevelLeftGreater, HighLevelParensBalanceChecker]\n",
    "poly_hl_model = PolyHLModel(hl_classes=cases, size_expansion=2)\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "\n",
    "dataset1 = DuplicateRemoverDataset(N_samples=1_000, n_ctx=15, seed=42)\n",
    "dataset2 = LeftGreaterDataset(N_samples=1_000, n_ctx=15, seed=42)\n",
    "dataset3 = BalancedParensDataset(N_samples=1_000, n_ctx=15, seed=42)\n",
    "dsets = [dataset1,dataset2, dataset3]\n",
    "poly_dataset = PolyModelDataset(dsets, n_ctx=poly_hl_model.cfg.n_ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_hook {LLNode(name='blocks.0.hook_resid_pre', index=[:], subspace=None)}\n",
      "mlp_hooks.0 {LLNode(name='blocks.0.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.0.0 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 0, :], subspace=None)}\n",
      "attn_hooks.0.1 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 1, :], subspace=None)}\n",
      "task_hook {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 2, :], subspace=None)}\n",
      "attn_hooks.0.3 {LLNode(name='blocks.0.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "mlp_hooks.1 {LLNode(name='blocks.1.mlp.hook_post', index=[:], subspace=None)}\n",
      "mlp_hooks.2 {LLNode(name='blocks.2.mlp.hook_post', index=[:], subspace=None)}\n",
      "attn_hooks.2.3 {LLNode(name='blocks.2.attn.hook_z', index=[:, :, 3, :], subspace=None)}\n",
      "[LLNode(name='blocks.1.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 2, :], subspace=None), LLNode(name='blocks.1.attn.hook_z', index=[:, :, 3, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 0, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 1, :], subspace=None), LLNode(name='blocks.2.attn.hook_z', index=[:, :, 2, :], subspace=None)]\n",
      "training_args={'batch_size': 256, 'lr': 0.001, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 0, 'detach_while_caching': True, 'iit_weight_schedule': <function <lambda> at 0x37d373ec0>, 'strict_weight_schedule': <function <lambda> at 0x37d370b80>, 'behavior_weight_schedule': <function <lambda> at 0x37d372020>, 'atol': 0.05, 'use_single_loss': False, 'iit_weight': 1.0, 'behavior_weight': 1.0, 'strict_weight': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520be702669f4492a1c811b9c12fb1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.90e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 8.93e-01, train/behavior_loss: 6.24e-01, train/strict_loss: 1.07e-01, val/iit_loss: 5.74e-01, val/IIA: 77.00, val/accuracy: 90.65, val/strict_accuracy: 88.72\n",
      "Epoch 2: lr: 9.80e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 6.71e-01, train/behavior_loss: 2.23e-01, train/strict_loss: 4.12e-02, val/iit_loss: 7.05e-01, val/IIA: 74.95, val/accuracy: 91.16, val/strict_accuracy: 89.50\n",
      "Epoch 3: lr: 9.70e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 5.56e-01, train/behavior_loss: 1.80e-01, train/strict_loss: 3.09e-02, val/iit_loss: 4.37e-01, val/IIA: 82.31, val/accuracy: 93.75, val/strict_accuracy: 92.17\n",
      "Epoch 4: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.65e-01, train/behavior_loss: 1.58e-01, train/strict_loss: 3.26e-02, val/iit_loss: 2.24e-01, val/IIA: 91.10, val/accuracy: 94.94, val/strict_accuracy: 93.64\n",
      "Epoch 5: lr: 9.50e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.01e-01, train/behavior_loss: 1.29e-01, train/strict_loss: 3.28e-02, val/iit_loss: 3.34e-01, val/IIA: 86.13, val/accuracy: 95.99, val/strict_accuracy: 94.55\n",
      "Epoch 6: lr: 9.40e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 4.80e-01, train/behavior_loss: 1.04e-01, train/strict_loss: 1.87e-02, val/iit_loss: 1.62e-01, val/IIA: 93.56, val/accuracy: 97.86, val/strict_accuracy: 96.21\n",
      "Epoch 7: lr: 9.30e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.47e-01, train/behavior_loss: 7.90e-02, train/strict_loss: 1.76e-02, val/iit_loss: 2.60e-01, val/IIA: 90.32, val/accuracy: 98.54, val/strict_accuracy: 96.58\n",
      "Epoch 8: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 3.69e-01, train/behavior_loss: 5.28e-02, train/strict_loss: 2.25e-02, val/iit_loss: 1.63e-01, val/IIA: 93.63, val/accuracy: 99.18, val/strict_accuracy: 97.45\n",
      "Epoch 9: lr: 9.10e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.39e-01, train/behavior_loss: 3.92e-02, train/strict_loss: 1.28e-02, val/iit_loss: 2.97e-01, val/IIA: 89.87, val/accuracy: 99.09, val/strict_accuracy: 97.24\n",
      "Epoch 10: lr: 9.00e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.77e-01, train/behavior_loss: 3.50e-02, train/strict_loss: 1.17e-02, val/iit_loss: 1.30e-01, val/IIA: 94.09, val/accuracy: 99.05, val/strict_accuracy: 97.72\n",
      "Epoch 11: lr: 8.90e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.84e-01, train/behavior_loss: 2.46e-02, train/strict_loss: 1.03e-02, val/iit_loss: 2.46e-01, val/IIA: 91.59, val/accuracy: 99.65, val/strict_accuracy: 98.40\n",
      "Epoch 12: lr: 8.80e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.96e-01, train/behavior_loss: 2.35e-02, train/strict_loss: 8.22e-03, val/iit_loss: 1.25e-01, val/IIA: 96.23, val/accuracy: 99.64, val/strict_accuracy: 98.12\n",
      "Epoch 13: lr: 8.70e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 9.96e-02, train/behavior_loss: 2.36e-02, train/strict_loss: 8.65e-03, val/iit_loss: 1.19e-01, val/IIA: 95.95, val/accuracy: 99.74, val/strict_accuracy: 98.17\n",
      "Epoch 14: lr: 8.60e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.52e-01, train/behavior_loss: 2.01e-02, train/strict_loss: 7.66e-03, val/iit_loss: 1.71e-01, val/IIA: 93.30, val/accuracy: 99.86, val/strict_accuracy: 98.66\n",
      "Epoch 15: lr: 8.50e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 2.15e-01, train/behavior_loss: 2.54e-02, train/strict_loss: 9.10e-03, val/iit_loss: 1.36e-01, val/IIA: 94.54, val/accuracy: 98.94, val/strict_accuracy: 97.77\n",
      "Epoch 16: lr: 8.40e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.84e-01, train/behavior_loss: 1.79e-02, train/strict_loss: 9.13e-03, val/iit_loss: 2.57e-01, val/IIA: 90.03, val/accuracy: 99.98, val/strict_accuracy: 99.30\n",
      "Epoch 17: lr: 8.30e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.28e-01, train/behavior_loss: 1.35e-02, train/strict_loss: 6.46e-03, val/iit_loss: 1.62e-01, val/IIA: 93.39, val/accuracy: 99.94, val/strict_accuracy: 99.00\n",
      "Epoch 18: lr: 8.20e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.61e-01, train/behavior_loss: 1.46e-02, train/strict_loss: 5.99e-03, val/iit_loss: 8.93e-02, val/IIA: 96.97, val/accuracy: 99.97, val/strict_accuracy: 99.04\n",
      "Epoch 19: lr: 8.10e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.43e-01, train/behavior_loss: 1.72e-02, train/strict_loss: 6.97e-03, val/iit_loss: 1.15e-01, val/IIA: 95.50, val/accuracy: 99.98, val/strict_accuracy: 98.74\n",
      "Epoch 20: lr: 8.00e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.67e-01, train/behavior_loss: 1.66e-02, train/strict_loss: 6.04e-03, val/iit_loss: 1.81e-01, val/IIA: 93.69, val/accuracy: 99.60, val/strict_accuracy: 98.89\n",
      "Epoch 21: lr: 7.90e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.42e-01, train/behavior_loss: 1.68e-02, train/strict_loss: 6.73e-03, val/iit_loss: 2.41e-01, val/IIA: 91.07, val/accuracy: 99.89, val/strict_accuracy: 99.25\n",
      "Epoch 22: lr: 7.80e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.12e-01, train/behavior_loss: 1.40e-02, train/strict_loss: 5.91e-03, val/iit_loss: 7.06e-02, val/IIA: 97.29, val/accuracy: 99.97, val/strict_accuracy: 98.99\n",
      "Epoch 23: lr: 7.70e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.06e-01, train/behavior_loss: 1.77e-02, train/strict_loss: 5.16e-03, val/iit_loss: 1.17e-01, val/IIA: 95.51, val/accuracy: 99.91, val/strict_accuracy: 99.36\n",
      "Epoch 24: lr: 7.60e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.72e-01, train/behavior_loss: 1.38e-02, train/strict_loss: 6.34e-03, val/iit_loss: 9.16e-02, val/IIA: 96.75, val/accuracy: 99.98, val/strict_accuracy: 99.25\n",
      "Epoch 25: lr: 7.50e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.53e-01, train/behavior_loss: 1.79e-02, train/strict_loss: 6.37e-03, val/iit_loss: 5.78e-02, val/IIA: 97.35, val/accuracy: 100.00, val/strict_accuracy: 98.95\n",
      "Epoch 26: lr: 7.40e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.19e-01, train/behavior_loss: 1.69e-02, train/strict_loss: 5.43e-03, val/iit_loss: 7.87e-02, val/IIA: 96.44, val/accuracy: 99.89, val/strict_accuracy: 99.19\n",
      "Epoch 27: lr: 7.30e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.20e-01, train/behavior_loss: 1.19e-02, train/strict_loss: 4.50e-03, val/iit_loss: 8.12e-02, val/IIA: 96.97, val/accuracy: 99.98, val/strict_accuracy: 99.11\n",
      "Epoch 28: lr: 7.20e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.18e-01, train/behavior_loss: 1.11e-02, train/strict_loss: 5.01e-03, val/iit_loss: 1.34e-01, val/IIA: 95.24, val/accuracy: 99.93, val/strict_accuracy: 99.53\n",
      "Epoch 29: lr: 7.10e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 6.56e-02, train/behavior_loss: 1.22e-02, train/strict_loss: 3.45e-03, val/iit_loss: 1.11e-01, val/IIA: 95.58, val/accuracy: 99.96, val/strict_accuracy: 99.12\n",
      "Epoch 30: lr: 7.00e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 7.71e-02, train/behavior_loss: 1.46e-02, train/strict_loss: 3.26e-03, val/iit_loss: 5.88e-02, val/IIA: 97.50, val/accuracy: 99.99, val/strict_accuracy: 99.03\n",
      "Epoch 31: lr: 6.90e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 6.48e-02, train/behavior_loss: 1.29e-02, train/strict_loss: 3.57e-03, val/iit_loss: 1.19e-01, val/IIA: 95.30, val/accuracy: 100.00, val/strict_accuracy: 99.19\n",
      "Epoch 32: lr: 6.80e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 8.61e-02, train/behavior_loss: 1.13e-02, train/strict_loss: 3.61e-03, val/iit_loss: 8.29e-02, val/IIA: 97.01, val/accuracy: 95.94, val/strict_accuracy: 96.59\n",
      "Epoch 33: lr: 6.70e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.18e-01, train/behavior_loss: 1.55e-02, train/strict_loss: 5.54e-03, val/iit_loss: 9.64e-02, val/IIA: 96.47, val/accuracy: 99.90, val/strict_accuracy: 98.87\n",
      "Epoch 34: lr: 6.60e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 1.06e-01, train/behavior_loss: 1.34e-02, train/strict_loss: 3.43e-03, val/iit_loss: 1.03e-01, val/IIA: 96.37, val/accuracy: 99.99, val/strict_accuracy: 99.53\n",
      "Epoch 35: lr: 6.50e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 7.00e-02, train/behavior_loss: 1.26e-02, train/strict_loss: 3.51e-03, val/iit_loss: 4.03e-02, val/IIA: 98.42, val/accuracy: 100.00, val/strict_accuracy: 99.40\n",
      "Epoch 36: lr: 6.40e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 6.45e-02, train/behavior_loss: 1.41e-02, train/strict_loss: 6.16e-03, val/iit_loss: 8.72e-02, val/IIA: 96.57, val/accuracy: 100.00, val/strict_accuracy: 99.39\n",
      "Epoch 37: lr: 6.30e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 8.41e-02, train/behavior_loss: 1.27e-02, train/strict_loss: 4.80e-03, val/iit_loss: 1.12e-01, val/IIA: 95.76, val/accuracy: 99.55, val/strict_accuracy: 98.74\n",
      "Epoch 38: lr: 6.20e-04, iit_weight: 1.00e+00, behavior_weight: 1.00e+00, strict_weight: 4.00e-01, train/iit_loss: 6.39e-02, train/behavior_loss: 1.10e-02, train/strict_loss: 3.48e-03, val/iit_loss: 9.64e-02, val/IIA: 96.50, val/accuracy: 100.00, val/strict_accuracy: 99.55\n"
     ]
    }
   ],
   "source": [
    "ll_model = poly_hl_model.get_ll_model()\n",
    "corr = poly_hl_model.get_correspondence()\n",
    "for k, v in corr.items():\n",
    "    print(k, v)\n",
    "\n",
    "n_epochs = 100\n",
    "training_args = {\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 1e-3,\n",
    "    \"num_workers\": 0,\n",
    "    \"use_single_loss\": False,\n",
    "    \"behavior_weight\": 1., #basically doubles the strict weight's job.\n",
    "    \"iit_weight\": 1.,\n",
    "    \"strict_weight\": 0.4,\n",
    "    \"clip_grad_norm\": 1.0,\n",
    "    \"iit_weight_schedule\" : lambda s, i: s,\n",
    "    \"strict_weight_schedule\" : lambda s, i: s,\n",
    "    \"behavior_weight_schedule\" : lambda s, i: s, #0.955*s if 0.955**i > 0.01 else s, #have behavior weight decay over time\n",
    "    \"early_stop\" : True,\n",
    "    \"lr_scheduler\": torch.optim.lr_scheduler.LinearLR,\n",
    "    \"scheduler_kwargs\": dict(start_factor=1, end_factor=0, total_iters=n_epochs),\n",
    "    \"scheduler_val_metric\": [\"val/accuracy\", \"val/IIA\"], #for ReduceLRonPlateau\n",
    "    \"scheduler_mode\": \"max\", #for ReduceLRonPlateau\n",
    "}\n",
    "train_set, test_set = poly_dataset.get_IIT_train_test_set()\n",
    "model_pair = StrictIITModelPair(hl_model=poly_hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "print(model_pair.nodes_not_in_circuit)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    "    optimizer_kwargs=dict(weight_decay=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
