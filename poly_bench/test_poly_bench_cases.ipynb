{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paren Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import torch\n",
    "from cases.paren_checker import HighLevelParensBalanceChecker, test_HL_parens_balancer_components, BalancedParensDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Balance tests passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_HL_parens_balancer_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making IIT dataset\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelParensBalanceChecker()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = BalancedParensDataset(N_samples=5_000, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 4)\n",
      "[[3, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 2], [3, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2], [3, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2], [3, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 2], [3, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2], [3, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 2], [3, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 2], [3, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 2], [3, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 2], [3, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2]]\n",
      "[[[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]], [[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.get_dataset().shape)\n",
    "print(dataset.get_dataset()[:10]['tokens'])\n",
    "print(dataset.get_dataset()[:10]['labels'])\n",
    "for i in range(10):\n",
    "    tokens, labels, hl_outputs = dataset.get_dataset()[i]['tokens'], dataset.get_dataset()[i]['labels'], hl_model((torch.tensor(dataset.get_dataset()[i]['tokens'])[None,:], None, None))\n",
    "    nonzero = (torch.tensor(labels) - hl_outputs[0]).nonzero()\n",
    "    if nonzero.numel() > 0:\n",
    "        print(tokens, torch.unique(nonzero[:,0]))\n",
    "        bad_indices = torch.unique(nonzero[:,0]).tolist()\n",
    "        for idx in bad_indices:\n",
    "            print(labels[idx], hl_outputs[0,idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iit.model_pairs.strict_iit_model_pair import StrictIITModelPair\n",
    "from iit.utils.index import Ix\n",
    "import torch\n",
    "\n",
    "n_epochs = 100\n",
    "training_args = {\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "    \"use_single_loss\": False,\n",
    "    \"behavior_weight\": 0., #basically doubles the strict weight's job.\n",
    "    \"iit_weight\": 1.,\n",
    "    \"strict_weight\": 1.0,\n",
    "    \"clip_grad_norm\": 1.0,\n",
    "    \"iit_weight_schedule\" : lambda s, i: s,\n",
    "    \"strict_weight_schedule\" : lambda s, i: s,\n",
    "    \"behavior_weight_schedule\" : lambda s, i: s, #0.955*s if 0.955**i > 0.01 else s, #have behavior weight decay over time\n",
    "    \"early_stop\" : True,\n",
    "    \"lr_scheduler\": torch.optim.lr_scheduler.LinearLR,\n",
    "    \"scheduler_kwargs\": dict(start_factor=1, end_factor=0, total_iters=n_epochs),\n",
    "    \"scheduler_val_metric\": [\"val/accuracy\", \"val/IIA\"], #for ReduceLRonPlateau\n",
    "    \"scheduler_mode\": \"max\", #for ReduceLRonPlateau\n",
    "}\n",
    "\n",
    "class LastTokenStrictIITModelPair(StrictIITModelPair):\n",
    "    def get_label_idxs(self):\n",
    "        return Ix[[None,-1]]\n",
    "\n",
    "    # def loss_fn(self) -> Callable[[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "    #     return torch.nn.CrossEntropyLoss()\n",
    "\n",
    "ll_model = hl_model.get_ll_model()\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args={'batch_size': 256, 'lr': 0.001, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 0, 'detach_while_caching': True, 'iit_weight_schedule': <function <lambda> at 0x17f69c220>, 'strict_weight_schedule': <function <lambda> at 0x17f7580e0>, 'behavior_weight_schedule': <function <lambda> at 0x17f758ae0>, 'atol': 0.05, 'use_single_loss': False, 'iit_weight': 1.0, 'behavior_weight': 0.0, 'strict_weight': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07251fac2616462fbfdcc0cc40036b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.66e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.96e-01, val/iit_loss: 1.70e-01, val/IIA: 95.48, val/accuracy: 95.57, val/strict_accuracy: 95.57\n",
      "Epoch 2: lr: 9.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.61e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 9.22e-02, val/iit_loss: 1.43e-01, val/IIA: 95.29, val/accuracy: 99.07, val/strict_accuracy: 99.07\n",
      "Epoch 3: lr: 9.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.67e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.08e-02, val/iit_loss: 9.62e-02, val/IIA: 97.06, val/accuracy: 98.95, val/strict_accuracy: 98.95\n",
      "Epoch 4: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.81e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.27e-02, val/iit_loss: 6.82e-02, val/IIA: 97.95, val/accuracy: 99.84, val/strict_accuracy: 99.84\n",
      "Epoch 5: lr: 9.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.24e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.73e-02, val/iit_loss: 9.16e-02, val/IIA: 97.22, val/accuracy: 99.45, val/strict_accuracy: 99.45\n",
      "Epoch 6: lr: 9.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.80e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.02e-02, val/iit_loss: 1.98e-02, val/IIA: 99.74, val/accuracy: 99.88, val/strict_accuracy: 99.88\n",
      "Epoch 7: lr: 9.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.62e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.15e-02, val/iit_loss: 1.23e-01, val/IIA: 95.72, val/accuracy: 99.73, val/strict_accuracy: 99.73\n",
      "Epoch 8: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.81e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 9.23e-03, val/iit_loss: 1.33e-02, val/IIA: 99.87, val/accuracy: 99.90, val/strict_accuracy: 99.90\n",
      "Epoch 9: lr: 9.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.00e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.09e-02, val/iit_loss: 1.21e-02, val/IIA: 99.67, val/accuracy: 99.95, val/strict_accuracy: 99.95\n",
      "Epoch 10: lr: 9.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.55e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 6.54e-03, val/iit_loss: 3.23e-02, val/IIA: 98.96, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 11: lr: 8.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.80e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.50e-02, val/iit_loss: 2.82e-02, val/IIA: 99.12, val/accuracy: 99.95, val/strict_accuracy: 99.95\n",
      "Epoch 12: lr: 8.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.16e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.59e-03, val/iit_loss: 6.52e-02, val/IIA: 97.55, val/accuracy: 99.44, val/strict_accuracy: 99.44\n",
      "Epoch 13: lr: 8.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.34e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 6.77e-03, val/iit_loss: 1.05e-01, val/IIA: 97.08, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 14: lr: 8.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.56e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.91e-03, val/iit_loss: 2.96e-02, val/IIA: 98.99, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 15: lr: 8.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.97e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.53e-03, val/iit_loss: 3.05e-02, val/IIA: 99.17, val/accuracy: 99.89, val/strict_accuracy: 99.89\n",
      "Epoch 16: lr: 8.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.12e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 6.44e-03, val/iit_loss: 5.38e-02, val/IIA: 98.01, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 17: lr: 8.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.96e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.53e-02, val/iit_loss: 3.84e-02, val/IIA: 98.29, val/accuracy: 98.97, val/strict_accuracy: 98.97\n",
      "Epoch 18: lr: 8.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.75e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.05e-03, val/iit_loss: 3.95e-03, val/IIA: 100.00, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 19: lr: 8.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.69e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.24e-03, val/iit_loss: 1.82e-02, val/IIA: 99.40, val/accuracy: 99.85, val/strict_accuracy: 99.85\n",
      "Epoch 20: lr: 8.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.29e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 8.92e-03, val/iit_loss: 3.62e-02, val/IIA: 98.64, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 21: lr: 7.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.98e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.13e-03, val/iit_loss: 2.42e-02, val/IIA: 99.10, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 22: lr: 7.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.87e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.39e-03, val/iit_loss: 2.98e-02, val/IIA: 98.80, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 23: lr: 7.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.24e-03, train/behavior_loss: 0.00e+00, train/strict_loss: 1.87e-03, val/iit_loss: 1.57e-03, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    "    optimizer_kwargs=dict(weight_decay=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left > Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All left greater tests passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cases.left_greater import HighLevelLeftGreater, test_HL_left_greater_components, LeftGreaterDataset\n",
    "\n",
    "test_HL_left_greater_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making IIT dataset\n",
      "{'input_hook': HookPoint(), 'paren_counts_hook': HookPoint(), 'mlp0_hook': HookPoint()}\n",
      "[input_hook, paren_counts_hook, mlp0_hook]\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelLeftGreater()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = LeftGreaterDataset(N_samples=1_000, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()\n",
    "print(hl_model.hook_dict)\n",
    "print(list(corr.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args={'batch_size': 256, 'lr': 0.001, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 0, 'detach_while_caching': True, 'iit_weight_schedule': <function <lambda> at 0x17f69c220>, 'strict_weight_schedule': <function <lambda> at 0x17f7580e0>, 'behavior_weight_schedule': <function <lambda> at 0x17f758ae0>, 'atol': 0.05, 'use_single_loss': False, 'iit_weight': 1.0, 'behavior_weight': 0.0, 'strict_weight': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f66dc23b41a45c6b4f0d4ffaf49992b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.32e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 1.27e+00, val/iit_loss: 1.08e+00, val/IIA: 55.73, val/accuracy: 55.80, val/strict_accuracy: 55.80\n",
      "Epoch 2: lr: 9.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.92e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 9.35e-01, val/iit_loss: 1.02e+00, val/IIA: 46.99, val/accuracy: 65.12, val/strict_accuracy: 65.12\n",
      "Epoch 3: lr: 9.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.96e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.78e-01, val/iit_loss: 9.46e-01, val/IIA: 46.30, val/accuracy: 67.11, val/strict_accuracy: 67.11\n",
      "Epoch 4: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.17e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.05e-01, val/iit_loss: 9.20e-01, val/IIA: 47.86, val/accuracy: 70.96, val/strict_accuracy: 70.96\n",
      "Epoch 5: lr: 9.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.71e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.20e-01, val/iit_loss: 5.97e-01, val/IIA: 74.69, val/accuracy: 74.26, val/strict_accuracy: 74.26\n",
      "Epoch 6: lr: 9.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.96e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.42e-01, val/iit_loss: 5.69e-01, val/IIA: 82.12, val/accuracy: 85.32, val/strict_accuracy: 85.32\n",
      "Epoch 7: lr: 9.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.94e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.84e-01, val/iit_loss: 5.08e-01, val/IIA: 85.61, val/accuracy: 88.18, val/strict_accuracy: 88.18\n",
      "Epoch 8: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.29e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.19e-01, val/iit_loss: 3.98e-01, val/IIA: 91.84, val/accuracy: 92.20, val/strict_accuracy: 92.20\n",
      "Epoch 9: lr: 9.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.57e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.49e-01, val/iit_loss: 3.78e-01, val/IIA: 90.14, val/accuracy: 92.42, val/strict_accuracy: 92.42\n",
      "Epoch 10: lr: 9.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.37e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.85e-01, val/iit_loss: 7.17e-01, val/IIA: 66.57, val/accuracy: 95.94, val/strict_accuracy: 95.94\n",
      "Epoch 11: lr: 8.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.46e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.35e-01, val/iit_loss: 7.47e-01, val/IIA: 65.88, val/accuracy: 96.99, val/strict_accuracy: 96.99\n",
      "Epoch 12: lr: 8.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.09e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.85e-01, val/iit_loss: 1.67e-01, val/IIA: 97.79, val/accuracy: 97.57, val/strict_accuracy: 97.57\n",
      "Epoch 13: lr: 8.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.38e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.43e-01, val/iit_loss: 1.61e-01, val/IIA: 98.59, val/accuracy: 99.09, val/strict_accuracy: 99.09\n",
      "Epoch 14: lr: 8.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.09e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.16e-01, val/iit_loss: 1.08e-01, val/IIA: 99.64, val/accuracy: 99.49, val/strict_accuracy: 99.49\n",
      "Epoch 15: lr: 8.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.86e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 9.89e-02, val/iit_loss: 1.18e-01, val/IIA: 99.06, val/accuracy: 99.60, val/strict_accuracy: 99.60\n",
      "Epoch 16: lr: 8.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.87e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 8.47e-02, val/iit_loss: 1.04e-01, val/IIA: 99.13, val/accuracy: 99.75, val/strict_accuracy: 99.75\n",
      "Epoch 17: lr: 8.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.84e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.80e-02, val/iit_loss: 1.00e-01, val/IIA: 99.24, val/accuracy: 99.78, val/strict_accuracy: 99.78\n",
      "Epoch 18: lr: 8.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.88e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.27e-02, val/iit_loss: 9.32e-02, val/IIA: 99.20, val/accuracy: 99.64, val/strict_accuracy: 99.64\n",
      "Epoch 19: lr: 8.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.41e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.79e-02, val/iit_loss: 6.84e-02, val/IIA: 99.78, val/accuracy: 99.75, val/strict_accuracy: 99.75\n",
      "Epoch 20: lr: 8.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.45e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 5.89e-02, val/iit_loss: 7.93e-02, val/IIA: 99.17, val/accuracy: 99.96, val/strict_accuracy: 99.96\n",
      "Epoch 21: lr: 7.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.25e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 4.94e-02, val/iit_loss: 5.14e-02, val/IIA: 99.93, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 22: lr: 7.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.67e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 4.59e-02, val/iit_loss: 6.39e-02, val/IIA: 99.53, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 23: lr: 7.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.17e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.19e-02, val/iit_loss: 4.09e-02, val/IIA: 99.93, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 24: lr: 7.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.50e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.71e-02, val/iit_loss: 5.27e-02, val/IIA: 99.82, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 25: lr: 7.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.79e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.76e-02, val/iit_loss: 5.33e-02, val/IIA: 99.67, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 26: lr: 7.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.71e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 3.44e-02, val/iit_loss: 5.21e-02, val/IIA: 99.56, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 27: lr: 7.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.25e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.19e-02, val/iit_loss: 3.32e-02, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "ll_model = hl_model.get_ll_model()\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    "    optimizer_kwargs=dict(weight_decay=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate remover\n",
    "case 19 in circuits-bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 0, 0, 1, 2, 0, 1, 3, 3], [4, 0, 1, 2, 2, 2, 2, 2, 2], [4, 0, 1, 2, 3, 3, 3, 3, 3]]\n",
      "[[False, False, True, False, False, False, False, False, True], [False, False, False, False, True, True, True, True, True], [False, False, False, False, False, True, True, True, True]]\n",
      "All DuplicateRemover tests passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cases.duplicate_remover import HighLevelDuplicateRemover, test_HL_duplicate_remover_components, DuplicateRemoverDataset\n",
    "test_HL_duplicate_remover_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 15, 5)\n",
      "making IIT dataset\n",
      "{'input_hook': HookPoint(), 'prev_token_hook': HookPoint(), 'prev_equal_hook': HookPoint(), 'output_hook': HookPoint()}\n",
      "[input_hook, prev_token_hook, prev_equal_hook, output_hook]\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelDuplicateRemover()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = DuplicateRemoverDataset(N_samples=1_000, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()\n",
    "print(hl_model.hook_dict)\n",
    "print(list(corr.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args={'batch_size': 256, 'lr': 0.001, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 100}, 'clip_grad_norm': 1.0, 'seed': 0, 'detach_while_caching': True, 'iit_weight_schedule': <function <lambda> at 0x17f69c220>, 'strict_weight_schedule': <function <lambda> at 0x17f7580e0>, 'behavior_weight_schedule': <function <lambda> at 0x17f758ae0>, 'atol': 0.05, 'use_single_loss': False, 'iit_weight': 1.0, 'behavior_weight': 0.0, 'strict_weight': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b5e835bb594f3fb7b6a06f9cfd8b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Training Epochs:   0%|          | 0/100 [00:00<?, ?it/s],))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: lr: 9.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.62e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 1.55e+00, val/iit_loss: 1.33e+00, val/IIA: 43.05, val/accuracy: 44.02, val/strict_accuracy: 44.02\n",
      "Epoch 2: lr: 9.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.42e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 1.20e+00, val/iit_loss: 1.42e+00, val/IIA: 35.78, val/accuracy: 61.51, val/strict_accuracy: 61.51\n",
      "Epoch 3: lr: 9.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.18e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 9.54e-01, val/iit_loss: 1.39e+00, val/IIA: 35.54, val/accuracy: 69.45, val/strict_accuracy: 69.45\n",
      "Epoch 4: lr: 9.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.01e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 7.84e-01, val/iit_loss: 1.40e+00, val/IIA: 37.15, val/accuracy: 72.76, val/strict_accuracy: 72.76\n",
      "Epoch 5: lr: 9.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.15e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.90e-01, val/iit_loss: 6.36e-01, val/IIA: 74.51, val/accuracy: 74.47, val/strict_accuracy: 74.47\n",
      "Epoch 6: lr: 9.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.22e+00, train/behavior_loss: 0.00e+00, train/strict_loss: 6.30e-01, val/iit_loss: 8.91e-01, val/IIA: 56.58, val/accuracy: 75.88, val/strict_accuracy: 75.88\n",
      "Epoch 7: lr: 9.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.19e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.02e-01, val/iit_loss: 1.23e+00, val/IIA: 46.83, val/accuracy: 78.36, val/strict_accuracy: 78.36\n",
      "Epoch 8: lr: 9.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 9.06e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.62e-01, val/iit_loss: 6.61e-01, val/IIA: 70.25, val/accuracy: 80.30, val/strict_accuracy: 80.30\n",
      "Epoch 9: lr: 9.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.29e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.31e-01, val/iit_loss: 1.03e+00, val/IIA: 53.94, val/accuracy: 80.50, val/strict_accuracy: 80.50\n",
      "Epoch 10: lr: 9.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 8.10e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.12e-01, val/iit_loss: 6.38e-01, val/IIA: 70.15, val/accuracy: 81.14, val/strict_accuracy: 81.14\n",
      "Epoch 11: lr: 8.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.64e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.95e-01, val/iit_loss: 6.19e-01, val/IIA: 70.62, val/accuracy: 82.81, val/strict_accuracy: 82.81\n",
      "Epoch 12: lr: 8.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.22e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.64e-01, val/iit_loss: 4.38e-01, val/IIA: 83.05, val/accuracy: 84.46, val/strict_accuracy: 84.46\n",
      "Epoch 13: lr: 8.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.93e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.34e-01, val/iit_loss: 7.60e-01, val/IIA: 65.39, val/accuracy: 85.06, val/strict_accuracy: 85.06\n",
      "Epoch 14: lr: 8.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.87e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.05e-01, val/iit_loss: 3.79e-01, val/IIA: 85.76, val/accuracy: 85.09, val/strict_accuracy: 85.09\n",
      "Epoch 15: lr: 8.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.36e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.77e-01, val/iit_loss: 4.43e-01, val/IIA: 84.12, val/accuracy: 86.06, val/strict_accuracy: 86.06\n",
      "Epoch 16: lr: 8.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.74e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.42e-01, val/iit_loss: 4.16e-01, val/IIA: 84.99, val/accuracy: 88.51, val/strict_accuracy: 88.51\n",
      "Epoch 17: lr: 8.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.26e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.47e-01, val/iit_loss: 4.06e-01, val/IIA: 85.66, val/accuracy: 89.25, val/strict_accuracy: 89.25\n",
      "Epoch 18: lr: 8.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.72e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.07e-01, val/iit_loss: 3.95e-01, val/IIA: 85.39, val/accuracy: 89.08, val/strict_accuracy: 89.08\n",
      "Epoch 19: lr: 8.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.98e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.99e-01, val/iit_loss: 6.44e-01, val/IIA: 70.05, val/accuracy: 89.65, val/strict_accuracy: 89.65\n",
      "Epoch 20: lr: 8.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.69e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.81e-01, val/iit_loss: 5.85e-01, val/IIA: 73.87, val/accuracy: 89.75, val/strict_accuracy: 89.75\n",
      "Epoch 21: lr: 7.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.77e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.56e-01, val/iit_loss: 2.58e-01, val/IIA: 90.79, val/accuracy: 89.95, val/strict_accuracy: 89.95\n",
      "Epoch 22: lr: 7.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.82e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.41e-01, val/iit_loss: 2.80e-01, val/IIA: 91.09, val/accuracy: 90.79, val/strict_accuracy: 90.79\n",
      "Epoch 23: lr: 7.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.04e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.07e-01, val/iit_loss: 2.05e-01, val/IIA: 94.94, val/accuracy: 93.40, val/strict_accuracy: 93.40\n",
      "Epoch 24: lr: 7.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.60e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.93e-01, val/iit_loss: 2.40e-01, val/IIA: 93.94, val/accuracy: 94.30, val/strict_accuracy: 94.30\n",
      "Epoch 25: lr: 7.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.70e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.83e-01, val/iit_loss: 2.24e-01, val/IIA: 94.47, val/accuracy: 94.24, val/strict_accuracy: 94.24\n",
      "Epoch 26: lr: 7.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.39e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.51e-01, val/iit_loss: 1.95e-01, val/IIA: 95.51, val/accuracy: 95.88, val/strict_accuracy: 95.88\n",
      "Epoch 27: lr: 7.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.29e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.42e-01, val/iit_loss: 1.40e-01, val/IIA: 97.25, val/accuracy: 96.48, val/strict_accuracy: 96.48\n",
      "Epoch 28: lr: 7.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.35e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.30e-01, val/iit_loss: 1.26e-01, val/IIA: 97.82, val/accuracy: 97.32, val/strict_accuracy: 97.32\n",
      "Epoch 29: lr: 7.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.26e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.05e-01, val/iit_loss: 1.53e-01, val/IIA: 97.65, val/accuracy: 98.32, val/strict_accuracy: 98.32\n",
      "Epoch 30: lr: 7.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.29e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 8.35e-02, val/iit_loss: 8.53e-01, val/IIA: 70.49, val/accuracy: 98.49, val/strict_accuracy: 98.49\n",
      "Epoch 31: lr: 6.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.65e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 8.37e-02, val/iit_loss: 3.56e-01, val/IIA: 84.89, val/accuracy: 99.06, val/strict_accuracy: 99.06\n",
      "Epoch 32: lr: 6.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.12e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 7.69e-02, val/iit_loss: 7.77e-02, val/IIA: 99.16, val/accuracy: 98.66, val/strict_accuracy: 98.66\n",
      "Epoch 33: lr: 6.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.72e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.90e-02, val/iit_loss: 1.28e-01, val/IIA: 98.12, val/accuracy: 98.22, val/strict_accuracy: 98.22\n",
      "Epoch 34: lr: 6.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 4.71e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.74e-02, val/iit_loss: 6.32e-02, val/IIA: 99.53, val/accuracy: 99.33, val/strict_accuracy: 99.33\n",
      "Epoch 35: lr: 6.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.92e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 6.38e-02, val/iit_loss: 9.26e-02, val/IIA: 98.96, val/accuracy: 99.43, val/strict_accuracy: 99.43\n",
      "Epoch 36: lr: 6.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.57e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.70e-02, val/iit_loss: 8.49e-01, val/IIA: 72.93, val/accuracy: 99.50, val/strict_accuracy: 99.50\n",
      "Epoch 37: lr: 6.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.25e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.28e-02, val/iit_loss: 8.64e-02, val/IIA: 98.83, val/accuracy: 99.66, val/strict_accuracy: 99.66\n",
      "Epoch 38: lr: 6.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.08e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 5.36e-02, val/iit_loss: 7.40e-01, val/IIA: 72.80, val/accuracy: 99.60, val/strict_accuracy: 99.60\n",
      "Epoch 39: lr: 6.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.70e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.53e-02, val/iit_loss: 8.03e-01, val/IIA: 72.19, val/accuracy: 99.40, val/strict_accuracy: 99.40\n",
      "Epoch 40: lr: 6.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.26e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 4.06e-02, val/iit_loss: 2.52e-01, val/IIA: 90.49, val/accuracy: 99.60, val/strict_accuracy: 99.60\n",
      "Epoch 41: lr: 5.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.52e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 3.24e-02, val/iit_loss: 3.28e-02, val/IIA: 99.90, val/accuracy: 99.83, val/strict_accuracy: 99.83\n",
      "Epoch 42: lr: 5.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.13e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.97e-02, val/iit_loss: 2.18e-01, val/IIA: 92.93, val/accuracy: 99.87, val/strict_accuracy: 99.87\n",
      "Epoch 43: lr: 5.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.40e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.76e-02, val/iit_loss: 8.92e-01, val/IIA: 71.59, val/accuracy: 99.90, val/strict_accuracy: 99.90\n",
      "Epoch 44: lr: 5.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 7.95e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 2.42e-02, val/iit_loss: 4.94e-02, val/IIA: 99.66, val/accuracy: 99.90, val/strict_accuracy: 99.90\n",
      "Epoch 45: lr: 5.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.27e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.29e-02, val/iit_loss: 9.66e-01, val/IIA: 71.56, val/accuracy: 99.83, val/strict_accuracy: 99.83\n",
      "Epoch 46: lr: 5.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 1.47e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.08e-02, val/iit_loss: 4.36e-02, val/IIA: 99.70, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 47: lr: 5.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.67e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.13e-02, val/iit_loss: 1.59e-01, val/IIA: 95.71, val/accuracy: 99.93, val/strict_accuracy: 99.93\n",
      "Epoch 48: lr: 5.20e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.14e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.11e-02, val/iit_loss: 9.25e-01, val/IIA: 71.69, val/accuracy: 99.97, val/strict_accuracy: 99.97\n",
      "Epoch 49: lr: 5.10e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 6.22e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.94e-02, val/iit_loss: 4.06e-02, val/IIA: 99.70, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 50: lr: 5.00e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.21e-02, train/behavior_loss: 0.00e+00, train/strict_loss: 1.65e-02, val/iit_loss: 3.67e-02, val/IIA: 99.90, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 51: lr: 4.90e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 3.15e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.53e-02, val/iit_loss: 9.93e-01, val/IIA: 70.79, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 52: lr: 4.80e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 5.63e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.81e-02, val/iit_loss: 4.16e-02, val/IIA: 99.80, val/accuracy: 99.90, val/strict_accuracy: 99.90\n",
      "Epoch 53: lr: 4.70e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.78e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 2.04e-02, val/iit_loss: 3.69e-02, val/IIA: 99.83, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 54: lr: 4.60e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.37e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.88e-02, val/iit_loss: 3.64e-02, val/IIA: 99.87, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 55: lr: 4.50e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.70e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.57e-02, val/iit_loss: 8.38e-01, val/IIA: 74.51, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 56: lr: 4.40e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.36e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.48e-02, val/iit_loss: 8.32e-01, val/IIA: 73.50, val/accuracy: 100.00, val/strict_accuracy: 100.00\n",
      "Epoch 57: lr: 4.30e-04, iit_weight: 1.00e+00, behavior_weight: 0.00e+00, strict_weight: 1.00e+00, train/iit_loss: 2.59e-01, train/behavior_loss: 0.00e+00, train/strict_loss: 1.68e-02, val/iit_loss: 1.77e-02, val/IIA: 100.00, val/accuracy: 100.00, val/strict_accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "ll_model = hl_model.get_ll_model()\n",
    "model_pair = StrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)\n",
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    "    optimizer_kwargs=dict(weight_decay=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique token extraction\n",
    "case 21 in circuits-bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2],\n",
      "        [2, 1],\n",
      "        [0, 0],\n",
      "        [1, 2],\n",
      "        [0, 2],\n",
      "        [2, 0],\n",
      "        [2, 2],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [2, 0]])\n",
      "[1, 3]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.randint(0, 3, (10, 2)))\n",
    "\n",
    "a = [1, 2, 3]\n",
    "a.remove(2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing / Decreasing detector\n",
    "case 13 in circuits-bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
