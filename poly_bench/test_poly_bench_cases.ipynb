{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paren Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from cases.paren_checker import HighLevelParensBalanceChecker, test_HL_parens_balancer_components, BalancedParensDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Balance tests passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_HL_parens_balancer_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making IIT dataset\n"
     ]
    }
   ],
   "source": [
    "hl_model = HighLevelParensBalanceChecker()\n",
    "ll_model = hl_model.get_ll_model()\n",
    "corr = hl_model.get_correspondence()\n",
    "dataset = BalancedParensDataset(N_samples=10_000, n_ctx=hl_model.get_ll_model_cfg().n_ctx, seed=42)\n",
    "train_set, test_set = dataset.get_IIT_train_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n",
      "[[3, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2], [3, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 2], [3, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2], [3, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 2], [3, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2], [3, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2], [3, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 2], [3, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 2], [3, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2], [3, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 2]]\n",
      "[[0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.get_dataset().shape)\n",
    "print(dataset.get_dataset()[:10]['tokens'])\n",
    "print(dataset.get_dataset()[:10]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HookedTransformerConfig:\n",
      "{'act_fn': 'relu',\n",
      " 'attention_dir': 'causal',\n",
      " 'attn_only': False,\n",
      " 'attn_types': None,\n",
      " 'checkpoint_index': None,\n",
      " 'checkpoint_label_type': None,\n",
      " 'checkpoint_value': None,\n",
      " 'd_head': 8,\n",
      " 'd_mlp': 128,\n",
      " 'd_model': 32,\n",
      " 'd_vocab': 4,\n",
      " 'd_vocab_out': 4,\n",
      " 'default_prepend_bos': True,\n",
      " 'device': device(type='mps'),\n",
      " 'dtype': torch.float32,\n",
      " 'eps': 1e-05,\n",
      " 'experts_per_token': None,\n",
      " 'final_rms': False,\n",
      " 'from_checkpoint': False,\n",
      " 'gated_mlp': False,\n",
      " 'init_mode': 'gpt2',\n",
      " 'init_weights': True,\n",
      " 'initializer_range': 0.1414213562373095,\n",
      " 'load_in_4bit': False,\n",
      " 'model_name': 'custom',\n",
      " 'n_ctx': 22,\n",
      " 'n_devices': 1,\n",
      " 'n_heads': 4,\n",
      " 'n_key_value_heads': None,\n",
      " 'n_layers': 3,\n",
      " 'n_params': 36864,\n",
      " 'normalization_type': 'LN',\n",
      " 'num_experts': None,\n",
      " 'original_architecture': None,\n",
      " 'parallel_attn_mlp': False,\n",
      " 'positional_embedding_type': 'standard',\n",
      " 'post_embedding_ln': False,\n",
      " 'rotary_adjacent_pairs': False,\n",
      " 'rotary_base': 10000,\n",
      " 'rotary_dim': None,\n",
      " 'scale_attn_by_inverse_layer_idx': False,\n",
      " 'seed': None,\n",
      " 'tokenizer_name': None,\n",
      " 'tokenizer_prepends_bos': None,\n",
      " 'trust_remote_code': False,\n",
      " 'use_attn_in': False,\n",
      " 'use_attn_result': False,\n",
      " 'use_attn_scale': True,\n",
      " 'use_hook_mlp_in': False,\n",
      " 'use_hook_tokens': False,\n",
      " 'use_local_attn': False,\n",
      " 'use_split_qkv_input': False,\n",
      " 'window_size': None}\n"
     ]
    }
   ],
   "source": [
    "print(hl_model.get_ll_model_cfg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iit.model_pairs.strict_iit_model_pair import StrictIITModelPair\n",
    "from iit.utils.index import Ix\n",
    "import torch\n",
    "\n",
    "n_epochs = 1000\n",
    "training_args = {\n",
    "    \"batch_size\": 256,\n",
    "    \"lr\": 0.001,\n",
    "    \"num_workers\": 0,\n",
    "    \"use_single_loss\": False,\n",
    "    \"behavior_weight\": 1.,\n",
    "    \"iit_weight\": 0., #TODO: Debug IIT loss.\n",
    "    \"strict_weight\": 0.5,\n",
    "    \"clip_grad_norm\": 1.0,\n",
    "    \"iit_weight_schedule\" : lambda s, i: s,\n",
    "    \"strict_weight_schedule\" : lambda s, i: s,\n",
    "    \"behavior_weight_schedule\" : lambda s, i: s, #0.955*s if 0.955**i > 0.01 else s, #have behavior weight decay over time\n",
    "    \"early_stop\" : True,\n",
    "    \"lr_scheduler\": torch.optim.lr_scheduler.LinearLR,\n",
    "    \"scheduler_kwargs\": dict(start_factor=1, end_factor=0, total_iters=n_epochs),\n",
    "    \"scheduler_val_metric\": [\"val/accuracy\", \"val/IIA\"], #for ReduceLRonPlateau\n",
    "    \"scheduler_mode\": \"max\", #for ReduceLRonPlateau\n",
    "}\n",
    "\n",
    "class LastTokenStrictIITModelPair(StrictIITModelPair):\n",
    "    def get_label_idxs(self):\n",
    "        return Ix[[None,-1]]\n",
    "\n",
    "model_pair = LastTokenStrictIITModelPair(hl_model=hl_model, ll_model=ll_model, corr=corr, training_args=training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_args={'batch_size': 256, 'lr': 0.001, 'num_workers': 0, 'early_stop': True, 'lr_scheduler': <class 'torch.optim.lr_scheduler.LinearLR'>, 'scheduler_val_metric': ['val/accuracy', 'val/IIA'], 'scheduler_mode': 'max', 'scheduler_kwargs': {'start_factor': 1, 'end_factor': 0, 'total_iters': 1000}, 'clip_grad_norm': 1.0, 'seed': 0, 'detach_while_caching': True, 'iit_weight_schedule': <function <lambda> at 0x3496e1800>, 'strict_weight_schedule': <function <lambda> at 0x3496e0860>, 'behavior_weight_schedule': <function <lambda> at 0x3496e11c0>, 'atol': 0.05, 'use_single_loss': False, 'iit_weight': 0.0, 'behavior_weight': 1.0, 'strict_weight': 0.5}\n",
      "Epoch 1: lr: 9.99e-04, iit_weight: 0.00e+00, behavior_weight: 1.00e+00, strict_weight: 5.00e-01, train/iit_loss: 0.00e+00, train/behavior_loss: 8.50e-02, train/strict_loss: 1.61e-02, val/iit_loss: -6.44e+04, val/IIA: 84.10, val/accuracy: 83.90, val/strict_accuracy: 99.90\n",
      "Epoch 2: lr: 9.98e-04, iit_weight: 0.00e+00, behavior_weight: 1.00e+00, strict_weight: 5.00e-01, train/iit_loss: 0.00e+00, train/behavior_loss: 1.03e-06, train/strict_loss: 4.18e-07, val/iit_loss: -6.46e+04, val/IIA: 83.24, val/accuracy: 83.46, val/strict_accuracy: 100.00\n",
      "Epoch 3: lr: 9.97e-04, iit_weight: 0.00e+00, behavior_weight: 1.00e+00, strict_weight: 5.00e-01, train/iit_loss: 0.00e+00, train/behavior_loss: 5.52e-08, train/strict_loss: 1.38e-08, val/iit_loss: -6.87e+04, val/IIA: 80.70, val/accuracy: 83.34, val/strict_accuracy: 100.00\n",
      "Epoch 4: lr: 9.96e-04, iit_weight: 0.00e+00, behavior_weight: 1.00e+00, strict_weight: 5.00e-01, train/iit_loss: 0.00e+00, train/behavior_loss: 5.26e-08, train/strict_loss: 1.32e-08, val/iit_loss: -6.49e+04, val/IIA: 84.75, val/accuracy: 83.40, val/strict_accuracy: 100.00\n",
      "Epoch 5: lr: 9.95e-04, iit_weight: 0.00e+00, behavior_weight: 1.00e+00, strict_weight: 5.00e-01, train/iit_loss: 0.00e+00, train/behavior_loss: 4.91e-08, train/strict_loss: 1.23e-08, val/iit_loss: -6.69e+04, val/IIA: 78.18, val/accuracy: 83.48, val/strict_accuracy: 100.00\n",
      "Epoch 6: lr: 9.94e-04, iit_weight: 0.00e+00, behavior_weight: 1.00e+00, strict_weight: 5.00e-01, train/iit_loss: 0.00e+00, train/behavior_loss: 4.52e-08, train/strict_loss: 1.13e-08, val/iit_loss: -6.50e+04, val/IIA: 87.83, val/accuracy: 83.41, val/strict_accuracy: 100.00\n",
      "Epoch 7: lr: 9.93e-04, iit_weight: 0.00e+00, behavior_weight: 1.00e+00, strict_weight: 5.00e-01, train/iit_loss: 0.00e+00, train/behavior_loss: 4.13e-08, train/strict_loss: 1.03e-08, val/iit_loss: -6.40e+04, val/IIA: 85.94, val/accuracy: 83.46, val/strict_accuracy: 100.00\n",
      "Epoch 8: lr: 9.92e-04, iit_weight: 0.00e+00, behavior_weight: 1.00e+00, strict_weight: 5.00e-01, train/iit_loss: 0.00e+00, train/behavior_loss: 3.70e-08, train/strict_loss: 9.27e-09, val/iit_loss: -6.67e+04, val/IIA: 85.25, val/accuracy: 83.28, val/strict_accuracy: 100.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_pair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:294\u001b[0m, in \u001b[0;36mBaseModelPair.train\u001b[0;34m(self, train_set, test_set, optimizer_cls, epochs, use_wandb, wandb_name_suffix, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    292\u001b[0m     batch_pbar\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 294\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m     test_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval_epoch(test_loader, loss_fn)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler_cls:\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/base_model_pair.py:348\u001b[0m, in \u001b[0;36mBaseModelPair._run_train_epoch\u001b[0;34m(self, loader, loss_fn, optimizer, pbar)\u001b[0m\n\u001b[1;32m    345\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_metrics()\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (base_input, ablation_input) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    347\u001b[0m     train_metrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 348\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mablation_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_metrics\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/strict_iit_model_pair.py:95\u001b[0m, in \u001b[0;36mStrictIITModelPair.run_train_step\u001b[0;34m(self, base_input, ablation_input, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     90\u001b[0m iit_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_IIT_loss_over_batch(base_input, ablation_input, hl_node, loss_fn)\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miit_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     93\u001b[0m )\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_single_loss:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_on_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43miit_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# loss for nodes that are not in the circuit\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# should not have causal effect on the high-level output\u001b[39;00m\n\u001b[1;32m     99\u001b[0m siit_loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_SIIT_loss_over_batch(base_input, ablation_input, loss_fn)\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    102\u001b[0m )\n",
      "File \u001b[0;32m~/far_cluster/iit/iit/model_pairs/iit_behavior_model_pair.py:65\u001b[0m, in \u001b[0;36mIITBehaviorModelPair.step_on_loss\u001b[0;34m(self, loss, optimizer)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_on_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss: Tensor, optimizer: t\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grad_fn()\n\u001b[1;32m     67\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/circuits_bench/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/circuits_bench/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/circuits_bench/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_pair.train(\n",
    "    train_set=train_set,\n",
    "    test_set=test_set,\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    epochs=n_epochs,\n",
    "    optimizer_kwargs=dict(weight_decay=1e-4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuits_bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
